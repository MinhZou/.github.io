<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Minh&#39;s Blog</title>
  
  <subtitle>æˆé•¿çš„è·¯ä¸Šæ¯ä¸€æ­¥éƒ½ç®—æ•°</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://minhzou.top/"/>
  <updated>2019-04-14T15:27:17.668Z</updated>
  <id>http://minhzou.top/</id>
  
  <author>
    <name>Minh</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>æœºå™¨å­¦ä¹ çš„æ•°å­¦åŸºç¡€</title>
    <link href="http://minhzou.top/2019/04/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    <id>http://minhzou.top/2019/04/14/æœºå™¨å­¦ä¹ çš„æ•°å­¦åŸºç¡€/</id>
    <published>2019-04-14T09:15:42.691Z</published>
    <updated>2019-04-14T15:27:17.668Z</updated>
    
    <content type="html"><![CDATA[<p>é¢„å¤‡äº†ä¸€ä¸‹å­¦ä¹ æœºå™¨å­¦ä¹ éœ€è¦çš„æ•°å­¦åŸºç¡€çŸ¥è¯†ï¼Œè¡¥å……äº†ä¸€äº›ä¸æ¸…æ¥šçš„æ•°å­¦çŸ¥è¯†</p><h5 id="æ¦‚è§ˆ"><a href="#æ¦‚è§ˆ" class="headerlink" title="æ¦‚è§ˆ"></a>æ¦‚è§ˆ</h5><div class="table-container"><table><thead><tr><th>ç®—æ³•æˆ–ç†è®º</th><th>ç”¨åˆ°çš„æ•°å­¦çŸ¥è¯†</th></tr></thead><tbody><tr><td>è´å¶æ–¯åˆ†ç±»å™¨</td><td>éšæœºå˜é‡ï¼Œè´å¶æ–¯å…¬å¼ï¼Œéšæœºå˜é‡ç‹¬ç«‹æ€§ï¼Œæ­£å¤ªåˆ†å¸ƒï¼Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡</td></tr><tr><td>å†³ç­–æ ‘</td><td>æ¦‚ç‡ï¼Œç†µï¼ŒGiniç³»æ•°</td></tr><tr><td>KNNç®—æ³•</td><td>è·ç¦»å‡½æ•°</td></tr><tr><td>ä¸»æˆåˆ†åˆ†æ</td><td>åæ–¹å·®çŸ©é˜µï¼Œæ•£å¸ƒçŸ©é˜µï¼Œæ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼Œç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡</td></tr><tr><td>æµå½¢å­¦ä¹ </td><td>æµå½¢ï¼Œæœ€ä¼˜åŒ–ï¼Œæµ‹åœ°çº¿ï¼Œæµ‹åœ°è·ç¦»ï¼Œå›¾ï¼Œç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡</td></tr><tr><td>çº¿æ€§åˆ¤åˆ«åˆ†æ</td><td>æ•£åº¦çŸ©é˜µï¼Œé€†çŸ©é˜µï¼Œæ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼Œç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡</td></tr><tr><td>æ”¯æŒå‘é‡æœº</td><td>ç‚¹åˆ°å¹³é¢çš„è·ç¦»ï¼ŒSlateræ¡ä»¶ï¼Œå¼ºå¯¹å¶ï¼Œæ‹‰æ ¼æœ—æ—¥å¯¹å¶ï¼ŒKKTæ¡ä»¶ï¼Œå‡¸ä¼˜åŒ–ï¼Œæ ¸å‡½æ•°ï¼ŒMerceræ¡ä»¶</td></tr><tr><td>]logisticså›å½’</td><td>æ¦‚ç‡ã€éšæœºå˜é‡ï¼Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œæ¢¯åº¦ä¸‹é™æ³•ï¼Œå‡¸ä¼˜åŒ–ï¼Œç‰›é¡¿æ³•</td></tr><tr><td>éšæœºæ£®æ—</td><td>æŠ½æ ·ï¼Œæ–¹å·®</td></tr><tr><td>AdaBoostç®—æ³•</td><td>æ¦‚ç‡ï¼Œéšæœºå˜é‡ï¼Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œæ¢¯åº¦ä¸‹é™æ³•ï¼Œå‡¸ä¼˜åŒ–ï¼Œç‰›é¡¿æ³•</td></tr><tr><td>éšé©¬å°”ç§‘å¤«é“¾</td><td>æ¦‚ç‡ï¼Œç¦»æ•£å‹éšæœºå˜é‡ï¼Œæ¡ä»¶æ¦‚ç‡ï¼Œéšæœºå˜é‡ç‹¬ç«‹æ€§ï¼Œæ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•ï¼Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡</td></tr><tr><td>æ¡ä»¶éšæœºåœº</td><td>æ¡ä»¶æ¦‚ç‡ï¼Œæ•°å­¦æœŸæœ›ï¼Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡</td></tr><tr><td>é«˜æ–¯æ··åˆæ¨¡å‹</td><td>æ­£æ€åˆ†å¸ƒï¼Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ŒJensenä¸ç­‰å¼</td></tr><tr><td>äººå·¥ç¥ç»ç½‘ç»œ</td><td>æ¢¯åº¦ä¸‹é™æ³•ï¼Œé“¾å¼æ³•åˆ™</td></tr><tr><td>å·ç§¯ç¥ç»ç½‘ç»œ</td><td>æ¢¯åº¦ä¸‹é™æ³•ï¼Œé“¾å¼æ³•åˆ™</td></tr><tr><td>å¾ªç¯ç¥ç»ç½‘ç»œ</td><td>æ¢¯åº¦ä¸‹é™æ³•ï¼Œé“¾å¼æ³•åˆ™</td></tr><tr><td>ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ</td><td>æ¢¯åº¦ä¸‹é™æ³•ï¼Œé“¾å¼æ³•åˆ™ï¼Œæå€¼å®šç†ï¼ŒKullback-Leibleræ•£åº¦ï¼ŒJensen-Shannonæ•£åº¦ï¼Œæµ‹åœ°è·ç¦»ï¼Œæ¡ä»¶åˆ†å¸ƒï¼Œäº’ä¿¡æ¯</td></tr><tr><td>K-meansç®—æ³•</td><td>è·ç¦»å‡½æ•°</td></tr><tr><td>å¼ºåŒ–å­¦ä¹ </td><td>æ•°å­¦æœŸæœ›ï¼Œè´å°”æ›¼æ–¹ç¨‹</td></tr><tr><td>è´å¶æ–¯ç½‘ç»œ</td><td>æ¡ä»¶æ¦‚ç‡ï¼Œè´å¶æ–¯å…¬å¼ï¼Œå›¾</td></tr><tr><td>VCç»´</td><td>Hoeffdingä¸ç­‰å¼</td></tr></tbody></table></div><h5 id="å¾®ç§¯åˆ†"><a href="#å¾®ç§¯åˆ†" class="headerlink" title="å¾®ç§¯åˆ†"></a>å¾®ç§¯åˆ†</h5><ul><li>å¯¼æ•°ä¸æ±‚å¯¼å…¬å¼</li><li>ä¸€é˜¶å¯¼æ•°ä¸å‡½æ•°çš„å•è°ƒæ€§</li><li>ä¸€å…ƒå‡½æ•°æå€¼åˆ¤å®šæ³•åˆ™</li><li>é«˜é˜¶å¯¼æ•°</li><li>äºŒé˜¶å¯¼æ•°ä¸å‡½æ•°çš„å‡¹å‡¸æ€§</li><li>ä¸€å…ƒå‡½æ•°æ³°å‹’å±•å¼€</li><li>åå¯¼æ•°</li><li>æ¢¯åº¦<br>$\nabla f(\mathrm{x})=\left(\frac{\partial f}{\partial x_{1}}, \ldots, \frac{\partial f}{\partial x_{n}}\right)^{\mathrm{T}}$</li><li>é›…å¯æ¯”çŸ©é˜µ<br>å¤šå…ƒå‡½æ•°çš„ä¸€é˜¶åå¯¼æ•°ç»„æˆ<br>$\left[ \begin{array}{cccc}{\frac{\partial y_{1}}{\partial x_{1}}} &amp; {\frac{\partial y_{1}}{\partial x_{2}}} &amp; {\dots} &amp; {\frac{\partial y_{1}}{\partial x_{n}}} \\ {\frac{\partial y_{2}}{\partial x_{1}}} &amp; {\frac{\partial y_{2}}{\partial x_{2}}} &amp; {\dots} &amp; {\frac{\partial y_{2}}{\partial x_{n}}} \\ {\cdots} &amp; {\cdots} &amp; {\cdots} &amp; {\cdots} \\ {\frac{\partial y_{m}}{\partial x_{1}}} &amp; {\frac{\partial y_{m}}{\partial x_{2}}} &amp; {\ldots} &amp; {\frac{\partial y_{m}}{\partial x_{n}}}\end{array}\right]$</li><li>HessiançŸ©é˜µ<br>å¤šå…ƒå‡½æ•°çš„äºŒé˜¶å¯¼æ•°ç»„æˆ<br>$\left[ \begin{array}{cccc}{\frac{\partial^{2} f}{\partial x_{1}^{2}}} &amp; {\frac{\partial^{2} f}{\partial x_{1} \partial x_{2}}} &amp; {\dots} &amp; {\frac{\partial^{2} f}{\partial x_{1} \partial x_{n}}} \\ {\frac{\partial^{2} f}{\partial x_{2} \partial x_{1}}} &amp; {\frac{\partial^{2} f}{\partial x_{2}^{2}}} &amp; {\dots} &amp; {\frac{\partial^{2} f}{\partial x_{2} \partial x_{n}}}\\ {\cdots} &amp; {\cdots} &amp; {\cdots} &amp; {\cdots}\\ {\frac{\partial^{2} f}{\partial x_{n} \partial x_{1}}} &amp; {\frac{\partial^{2} f}{\partial x_{n} \partial x_{2}}} &amp; {\cdots} &amp; {\frac{\partial^{2} f}{\partial x_{n}^{2}}}\end{array}\right]$</li><li><p>å¤šå…ƒå‡½æ•°æ³°å‹’å±•å¼€<br>$f(\mathrm{x})=f\left(\mathrm{x}_{0}\right)+\left(\nabla f\left(\mathrm{x}_{0}\right)\right)^{\mathrm{T}}\left(\mathrm{x}-\mathrm{x}_{0}\right)+\frac{1}{2}\left(\mathrm{x}-\mathrm{x}_{0}\right)^{\mathrm{T}} \mathrm{H}\left(\mathrm{x}-\mathrm{x}_{0}\right)+o\left(\left\Vert \mathrm{x}-\mathrm{x}_{0}\right\Vert^{2}\right)$</p></li><li><p>å¤šå…ƒå‡½æ•°æå€¼åˆ¤æ–­æ³•åˆ™</p><ul><li>å¦‚æœHessiançŸ©é˜µæ­£å®šï¼Œå‡½æ•°åœ¨è¯¥ç‚¹æœ‰æå°å€¼</li><li>å¦‚æœHessiançŸ©é˜µè´Ÿå®šï¼Œå‡½æ•°åœ¨è¯¥ç‚¹æœ‰æå¤§å€¼</li><li>å¦‚æœHessiançŸ©é˜µä¸å®šï¼Œè¿˜éœ€è¦çœ‹æ›´é«˜é˜¶çš„å¯¼æ•°</li></ul></li></ul><h5 id="çº¿æ€§ä»£æ•°"><a href="#çº¿æ€§ä»£æ•°" class="headerlink" title="çº¿æ€§ä»£æ•°"></a>çº¿æ€§ä»£æ•°</h5><ul><li>å‘é‡åŠå…¶è¿ç®—<ul><li>å‘é‡çš„èŒƒæ•°<br>$\Vert\mathrm{x}\Vert_{p}=\left(\sum_{i=1}^{n}\left|x_{i}\right|^{p}\right)^{\frac{1}{p}}$<br>$\Vert\mathrm{x}\Vert_{1}=\sum_{i=1}^{n}\left|x_{i}\right|$<br>$\Vert\mathrm{x}\Vert_{2}=\sqrt{\sum_{i=1}^{n}\left(x_{i}\right)^{2}}$</li></ul></li><li>çŸ©é˜µåŠå…¶è¿ç®—</li><li>å¼ é‡</li><li>è¡Œåˆ—å¼<ul><li>$|\mathrm{A}|=\sum_{\sigma \in S_{n}} \operatorname{sgn}(\sigma) \prod_{i=1}^{n} a_{i, \sigma(i)}$</li><li>é€†åºæ•°</li></ul></li><li>äºŒæ¬¡å‹</li><li>ç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡</li><li>å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰<br>$\mathrm{A}=\mathrm{U} \Sigma \mathrm{V}^{\mathrm{T}}$<br>Uï¼š$AA^{T}$ æ­£äº¤çŸ©é˜µ mxm<br>Vï¼š$A^{T}A$ æ­£äº¤çŸ©é˜µ nxn<br>$\Sigma$ å¯¹è§’é˜µ mxn</li><li>å¸¸ç”¨çš„çŸ©é˜µä¸å‘é‡æ±‚å¯¼å…¬å¼<br>$\nabla \mathrm{w}^{\mathrm{T}} \mathrm{x}=\mathrm{w}$<br>$\nabla \mathrm{x}^{\mathrm{T}} \mathrm{Ax}=\left(\mathrm{A}+\mathrm{A}^{\mathrm{T}}\right) \mathrm{x}$<br>$\nabla^{2} \mathrm{x}^{\mathrm{T}} \mathrm{Ax}=\mathrm{A}+\mathrm{A}^{\mathrm{T}}$ ï¼ˆ$\nabla^{2}$ ç›¸å½“äºH ï¼‰</li></ul><h5 id="æ¦‚ç‡è®º"><a href="#æ¦‚ç‡è®º" class="headerlink" title="æ¦‚ç‡è®º"></a>æ¦‚ç‡è®º</h5><ul><li>éšæœºäº‹ä»¶ä¸æ¦‚ç‡</li><li>æ¡ä»¶æ¦‚ç‡ä¸è´å¶æ–¯å…¬å¼</li><li>éšæœºå˜é‡</li><li>æ•°å­¦æœŸæœ›ä¸æ–¹å·®</li><li>å¸¸ç”¨æ¦‚ç‡åˆ†å¸ƒ</li><li>éšæœºå‘é‡</li><li>åæ–¹å·®ä¸åæ–¹å·®çŸ©é˜µ<br>åæ–¹å·®ååº”éšæœºå˜é‡çº¿æ€§ç›¸å…³çš„ç¨‹åº¦<ul><li>$\operatorname{cov}\left(x_{1}, x_{2}\right)=\mathrm{E}\left(\left(x_{1}-\mathrm{E}\left(x_{1}\right)\right)\left(x_{2}-\mathrm{E}\left(x_{2}\right)\right)\right)$</li><li>$\operatorname{cov}\left(x_{1}, x_{2}\right)=\mathrm{E}\left(x_{1} x_{2}\right)-\mathrm{E}\left(x_{1}\right) \mathrm{E}\left(x_{2}\right)$</li></ul></li><li>æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰<br>ç”¨æ¥ä¼°è®¡æ¦‚ç‡å¯†åº¦çš„å‚æ•°</li></ul><h5 id="æœ€ä¼˜åŒ–æ–¹æ³•"><a href="#æœ€ä¼˜åŒ–æ–¹æ³•" class="headerlink" title="æœ€ä¼˜åŒ–æ–¹æ³•"></a>æœ€ä¼˜åŒ–æ–¹æ³•</h5><ul><li>æœ€ä¼˜åŒ–çš„åŸºæœ¬æ¦‚å¿µ<ul><li>æœ€ä¼˜åŒ–é—®é¢˜</li><li>ç›®æ ‡å‡½æ•°</li><li>ä¼˜åŒ–å˜é‡</li><li>å¯è¡ŒåŸŸ</li><li>ç­‰å¼çº¦æŸ</li><li>ä¸ç­‰å¼çº¦æŸ</li><li>å±€éƒ¨æœ€å°å€¼</li><li>å…¨å±€æœ€å°å€¼</li></ul></li><li>è¿­ä»£æ³•<ul><li>$\lim _{k \rightarrow+\infty} \nabla f\left(\mathrm{x}_{k}\right)=0$</li><li>$\mathrm{x}_{k+1}=h\left(\mathrm{x}_{k}\right)$</li></ul></li><li>æ¢¯åº¦ä¸‹é™æ³•<br>$\mathrm{x}_{k+1}=\mathrm{x}_{k}-\gamma \nabla f\left(\mathrm{x}_{k}\right)$</li><li>ç‰›é¡¿æ³•<br>$\mathrm{x}_{k+1}=\mathrm{x}_{k}-\mathrm{H}_{k}^{-1} \mathrm{g}_{k}$</li><li>åæ ‡ä¸‹é™æ³•<br>$\min f(x), x=\left(x_{1}, x_{2}, \ldots, x_{n}\right)$<br>$\min _{x_{i}} f(x)$</li><li>ä¼˜åŒ–ç®—æ³•é¢ä¸´çš„é—®é¢˜<ul><li>å±€éƒ¨æå€¼ç‚¹é—®é¢˜</li><li>éç‚¹é—®é¢˜ï¼ˆHä¸å®šï¼‰</li></ul></li><li>æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•</li><li>å‡¸ä¼˜åŒ–ç®€ä»‹<ul><li>å‡¸é›†<br>$\theta \mathrm{x}+(1-\theta) \mathrm{y} \in C$</li><li>å‡¸å‡½æ•°<ul><li>å‡¸å‡½æ•°å®šä¹‰<br>$f(\theta \mathrm{x}+(1-\theta) \mathrm{y})&lt;\theta f(\mathrm{x})+(1-\theta) f(\mathrm{y})$</li><li>ä¸€é˜¶åˆ¤åˆ«æ³•</li><li>äºŒé˜¶åˆ¤åˆ«æ³•ï¼ˆHåŠæ­£å®šï¼Œæ­£å®šä¸¥æ ¼å‡¸å‡½æ•°ï¼‰</li></ul></li></ul></li><li>å‡¸ä¼˜åŒ–çš„æ€§è´¨<ul><li>å±€éƒ¨æœ€ä¼˜è§£ä¸€å®šæ˜¯å…¨å±€æœ€ä¼˜è§£<br>$\mathrm{z}=\theta \mathrm{y}+(1-\theta) \mathrm{x} \quad \theta=\frac{\delta}{2\Vert\mathrm{x}-\mathrm{y}\Vert_{2}}$<br>$\begin{aligned}\Vert\mathrm{x}-\mathrm{z}\Vert_{2} &amp;=\Vert \mathrm{x}-\left(\frac{\delta}{2\Vert\mathrm{x}-\mathrm{y}\Vert_{2}} \mathrm{y}+\left(1-\frac{\delta}{2\Vert\mathrm{x}-\mathrm{y}\Vert_{2}}\right) \mathrm{x}\left\Vert_{2}\right.\right.\\ &amp;=\left\Vert\frac{\delta}{2\Vert\mathrm{x}-\mathrm{y}\Vert_{2}}(\mathrm{x}-\mathrm{y})\right\Vert_{2} \\ &amp;=\frac{\delta}{2} \leq \delta \end{aligned}$<br>$f(z)=f(\theta y+(1-\theta) x) \leq \theta f(y)+(1-\theta) f(x)&lt;f(x)$</li></ul></li><li>æ‹‰æ ¼æœ—æ—¥å¯¹å¶<br>  $\min f(\mathrm{x})$<br>$\mathrm{g}_{i}(\mathrm{x}) \leq 0 \quad \mathrm{i}=1, \ldots, m$<br>$h_{i}(\mathrm{x})=0 \quad \mathrm{i}=1, \ldots, p$<br>  $L(\mathrm{x}, \lambda, v)=f(\mathrm{x})+\sum_{i=1}^{m} \lambda_{1} g_{i}(\mathrm{x})+\sum_{i=1}^{p} v_{i} h_{i}(\mathrm{x})$<ul><li>åŸé—®é¢˜<br>$\begin{aligned} p^{ \ast } &amp;=\min _{x} \max _{\lambda, v, \lambda_{i} \geq 0} L(\mathrm{x}, \lambda, v) &amp; \min _{\mathrm{x}} \theta_{P}(\mathrm{x})=\min _{\mathrm{x}} \max _{\lambda, v, \lambda_{i} \geq 0} L(\mathrm{x}, \lambda, v) \\ &amp;=\min _{\mathrm{x}} \theta_{P}(x) \end{aligned}$</li><li>å¯¹å¶é—®é¢˜<br>$d^{ \ast }=\max _{\lambda, v, \lambda_{i} \geq 0} \min _{x} L(\mathrm{x}, \lambda, v)=\max _{\lambda, v, \lambda_{i} \geq 0} \theta_{D}(\lambda, v)$</li><li>å¼±å¯¹å¶é—®é¢˜<br>$d^{ \ast }=\max _{\lambda, v, \lambda_{i} \geq 0} \min _{x} L(\mathrm{x}, \lambda, v) \leq \min _{x} \max _{\lambda, v, \lambda_{i} \geq 0} L(\mathrm{x}, \lambda, v)=p^{ \ast }$</li><li>å¼ºå¯¹å¶<br>Slateræ¡ä»¶<ul><li>å‡¸å‡½æ•°</li><li>ä¸ç­‰å¼ä¸¥æ ¼æˆç«‹ï¼ˆä¸å–ç­‰å·ï¼‰</li></ul></li></ul></li><li>KKTæ¡ä»¶<br>$\min f(\mathrm{x})$<br>$g_{i}(\mathrm{x}) \leq 0 \quad \mathrm{i}=1, \ldots, q$<br>$h_{i}(\mathrm{x})=0 \quad \mathrm{i}=1, \ldots, p$</li></ul><p>$L(\mathrm{x}, \lambda, \mu)=f(\mathrm{x})+\sum_{j=1}^{p} \lambda_{i} h_{j}(\mathrm{x})+\sum_{k=1}^{q} \mu_{i} g_{k}(\mathrm{x})$</p><p>$\nabla_{\mathrm{x}} L\left(\mathrm{x}^{\ast}\right)=0$<br>$\mu_{k} \geq 0$<br>$\mu_{k} g_{k}\left(\mathrm{x}^{\ast}\right)=0$<br>$h_{j}\left(\mathrm{x}^{\ast}\right)=0$<br>$g_{k}\left(\mathrm{x}^{\ast}\right) \leq 0$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;é¢„å¤‡äº†ä¸€ä¸‹å­¦ä¹ æœºå™¨å­¦ä¹ éœ€è¦çš„æ•°å­¦åŸºç¡€çŸ¥è¯†ï¼Œè¡¥å……äº†ä¸€äº›ä¸æ¸…æ¥šçš„æ•°å­¦çŸ¥è¯†&lt;/p&gt;
&lt;h5 id=&quot;æ¦‚è§ˆ&quot;&gt;&lt;a href=&quot;#æ¦‚è§ˆ&quot; class=&quot;headerlink&quot; title=&quot;æ¦‚è§ˆ&quot;&gt;&lt;/a&gt;æ¦‚è§ˆ&lt;/h5&gt;&lt;div class=&quot;table-container&quot;&gt;
&lt;
      
    
    </summary>
    
      <category term="å­¦ä¹ ç¬”è®°" scheme="http://minhzou.top/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="åŸºç¡€" scheme="http://minhzou.top/tags/%E5%9F%BA%E7%A1%80/"/>
    
      <category term="å­¦ä¹ ç¬”è®°" scheme="http://minhzou.top/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="æœºå™¨å­¦ä¹ " scheme="http://minhzou.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>ç¬¬äºŒå‘¨ Logisticå›å½’ã€SVM</title>
    <link href="http://minhzou.top/2019/04/06/%E7%AC%AC%E4%BA%8C%E5%91%A8%20Logistic%E5%9B%9E%E5%BD%92%E3%80%81SVM/"/>
    <id>http://minhzou.top/2019/04/06/ç¬¬äºŒå‘¨ Logisticå›å½’ã€SVM/</id>
    <published>2019-04-06T12:37:26.028Z</published>
    <updated>2019-04-13T09:12:47.667Z</updated>
    
    <content type="html"><![CDATA[<h5 id="1ã€Logisticå›å½’åŸºæœ¬åŸç†"><a href="#1ã€Logisticå›å½’åŸºæœ¬åŸç†" class="headerlink" title="1ã€Logisticå›å½’åŸºæœ¬åŸç†"></a>1ã€Logisticå›å½’åŸºæœ¬åŸç†</h5><ul><li>åˆ†ç±»<ul><li>ç»™å®šè®­ç»ƒæ•°æ®$D =\{\mathbf x_i, y_i\}^N_{i=1}$ï¼Œåˆ†ç±»ä»»åŠ¡å­¦ä¹ ä¸€ä¸ªä»è¾“å…¥xåˆ°è¾“å‡ºyçš„æ˜ å°„f ï¼š<br>$\hat y = f(\mathbf x) = \underset{c}{arg\ max}\ p(y = c \mid \mathbf x, D)$</li><li>å…¶ä¸­yä¸ºç¦»æ•£å€¼ï¼Œå…¶å–å€¼èŒƒå›´ç§°ä¸ºæ ‡ç­¾ç©ºé—´:$Y =\{1,2,â€¦,C\}$</li><li>å½“C=2æ—¶ï¼Œä¸ºä¸¤ç±»åˆ†ç±»é—®é¢˜ï¼Œè®¡ç®—å‡º$p(y = 1 \mid \mathbf x)$å³å¯ã€‚æ­¤æ—¶åˆ†å¸ƒä¸ºBernoulliåˆ†å¸ƒ: <script type="math/tex; mode=display">p(y \mid \mathbf x) = Ber(y \mid \mu (\mathbf x))</script>å…¶ä¸­$\mu (\mathbf x) = \mathbb{E}(y \mid \mathbf x) = p(y = 1 \mid \mathbf x)$<a id="more"></a></li></ul></li><li>Recall:Bernouiliåˆ†å¸ƒ<ul><li>Bernoulliåˆ†å¸ƒåˆåä¸¤ç‚¹åˆ†å¸ƒæˆ–è€…0-1åˆ†å¸ƒã€‚è‹¥Bernoulliè¯•éªŒæˆåŠŸï¼Œåˆ™Bernoulliéšæœºå˜é‡Xå–å€¼ä¸º1ï¼Œå¦åˆ™Xä¸º0ã€‚è®°è¯•éªŒæˆåŠŸæ¦‚ç‡ä¸ºÎ¸ï¼Œ æˆ‘ä»¬ç§°Xæœä»å‚æ•°ä¸ºÎ¸çš„Bernoulliåˆ†å¸ƒï¼Œè®°ä¸º: ğ‘‹~ğµğ‘’ğ‘Ÿ(Î¸), æ¦‚ç‡å‡½æ•°ï¼ˆpmfï¼‰ä¸ºï¼š<script type="math/tex; mode=display">p(x) = \theta ^x(1- \theta)^{1-x} = \begin{cases} \theta & if\ x = 1\\ 1 - \theta & if\ x = 0 \end{cases}</script></li><li>Bernoulliåˆ†å¸ƒçš„å‡å€¼ï¼š$\mu = \theta $</li><li>æ–¹å·®ï¼š$\sigma^2 = \theta \times (1-\theta)$</li></ul></li><li>Logisticå›å½’æ¨¡å‹<ul><li>Logisticå›å½’æ¨¡å‹åŒçº¿æ€§å›å½’æ¨¡å‹ç±»ä¼¼ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªçº¿æ€§æ¨¡å‹ï¼Œåªæ˜¯æ¡ä»¶æ¦‚ç‡ğ‘(ğ‘¦|ğ±)çš„å½¢å¼ä¸åŒï¼š<script type="math/tex; mode=display">p(y \mid \mathbf x) = Ber(y \mid \mu (\mathbf  x))</script><script type="math/tex; mode=display">\mu (\mathbf x) = \sigma(\mathbf w^T\mathbf x)</script></li><li>å…¶ä¸­sigmoidå‡½æ•°ï¼ˆSå½¢å‡½æ•°ï¼‰å®šä¹‰ä¸º<script type="math/tex; mode=display">\sigma(a) = \frac{1}{1+exp(-a)} = \frac{exp(-a)}{exp(-a)+1}</script></li><li>äº¦è¢«ç§°ä¸ºlogisticå‡½æ•°æˆ–logitå‡½æ•°ï¼Œå°†å®æ•°aå˜æ¢åˆ°[0,1]åŒºé—´ã€‚<ul><li>å› ä¸ºæ¦‚ç‡å–å€¼åœ¨[0,1]åŒºé—´</li><li>Logisticå›å½’äº¦è¢«ç§°ä¸ºlogitå›å½’</li></ul></li></ul></li><li>ä¸ºä»€ä¹ˆç”¨logisticå‡½æ•°ï¼Ÿ<ul><li>åœ¨ç¥ç»ç§‘å­¦ä¸­<ul><li>ç¥ç»å…ƒå¯¹å…¶è¾“å…¥è¿›è¡ŒåŠ æƒå’Œï¼š$f(x) = w^Tx$</li><li>å¦‚æœè¯¥å’Œå¤§äºæŸé˜ˆå€¼ $f(x) &gt; \tau $ï¼Œç¥ç»å…ƒå‘æ”¾è„‰å†²</li></ul></li><li>åœ¨Logisticå›å½’ï¼Œå®šä¹‰Log Odds Ratio:<script type="math/tex; mode=display">\begin{eqnarray} LOR(x) &=& log \frac {p(y=1 \mid \mathbf  x, \mathbf f w)}{p(y = 0 \mid \mathbf x, \mathbf w)}   &=& log [\frac{1}{1+exp(-\mathbf  w^T\mathbf x)} \frac {1+exp(-\mathbf w^T\mathbf x)}{exp(-\mathbf w^T\mathbf x)}] \\  &=& log [exp(\mathbf w^T \mathbf x)]\\  &=& \mathbf w^T\mathbf x \end{eqnarray}</script></li><li>å› æ­¤ï¼Œ$iff LOR(\mathbf x) = \mathbf w^T \mathbf x &gt; 0$ç¥ç»å…ƒå‘æ”¾è„‰å†²ï¼Œå³<br>$p(y=1 \mid \mathbf x, \mathbf w) &gt; p(y=0 \mid \mathbf x, \mathbf w)$</li></ul></li><li>çº¿æ€§å†³ç­–å‡½æ•°<ul><li>åœ¨Logisticå›å½’ä¸­<ul><li>$LOR(\bf x) = w^Tx &gt; 0, \hat y = 1$</li><li>$LOR(\bf x) = w^Tx &lt;0, \hat y = 0$</li><li>$\bf w^T \bf x = 0$:å†³ç­–é¢</li></ul></li><li>å› æ­¤$a(\bf x) = w^Tx$åˆ†ç±»å†³ç­–é¢<ul><li>å› æ­¤Logisticå›å½’æ˜¯ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨</li></ul></li></ul></li><li>æå¤§ä¼¼ç„¶ä¼°è®¡<ul><li>Logisticå›å½’ï¼š$p(y \mid \mathbf {x,w}) = Ber(y \mid \mu (x)),  \mu (\mathbf x) = \sigma (\mathbf w^T\mathbf x)$</li><li>ä»¤$\mu_i = \mu(\mathbf x_i)$ï¼Œåˆ™è´Ÿlogä¼¼ç„¶ä¸º<br>$\begin{eqnarray} J(w) = NLL(\mathbf w) &amp;=&amp; - \sum_{i=1}^N log \left[(\mu_i)^{y_i} \times (1-\mu_i)^{1-y_i}\right]\\<br>  &amp;=&amp; \sum_{i=1}^N- \left[y_i log(\mu_i)+(1-y_i)log(1-u_i) \right]<br>  \end{eqnarray}$</li><li>æå¤§ä¼¼ç„¶ä¼°è®¡ç­‰ä»·äºæœ€å°LogisticæŸå¤±</li><li>ä¼˜åŒ–æ±‚è§£ï¼šæ¢¯åº¦ä¸‹é™ï¼ç‰›é¡¿æ³•</li></ul></li><li>æ¢¯åº¦<ul><li>ç›®æ ‡å‡½æ•°ä¸º<br>$J(\mathbf w) = \sum_{i=1}^N-[y_i log(\mu_i)+(1-y_i)log(1-u_i)]$</li><li>æ¢¯åº¦ä¸º<br>$\begin{eqnarray} g(\bf w) &amp;=&amp; \frac{\partial J(\bf w)}{\partial \bf w} = \frac{\partial}{\partial \bf w}[\sum_{i=1}^N-[y_i log(\mu_i)+(1-y_i)log(1-u_i)]]\\<br>&amp;=&amp; \sum_{i=1}^N[\mu(\mathbf x_i) - y_i] \mathbf x_i \\<br>&amp;=&amp; \bf X^T(\mu - y)<br>\end{eqnarray}$</li><li>äºŒé˜¶HessiançŸ©é˜µä¸º<br>$\begin{eqnarray} H(w) &amp;=&amp; \frac{\partial}{\partial \mathbf w}[\mathbf g( \mathbf w)^T] = \sum_{i=1}^N(\frac {\partial}{\partial \mathbf w}\mu_i) \mathbf x_i^T\\<br>&amp;=&amp; \sum_{i=1}{N}\mu_i(1-\mu_i)\bf x_ix_i^T = X^T\underset{S}{ \underbrace{diag(\mu_i(1-\mu_i)}}X = X^TSX<br>\end{eqnarray}$</li></ul></li><li>ç‰›é¡¿æ³•<ul><li>äº¦ç§°ç‰›é¡¿-æ‹‰å¤«é€Šï¼ˆ Newton-Raphson ï¼‰æ–¹æ³•<ul><li>ç‰›é¡¿åœ¨17ä¸–çºªæå‡ºçš„ä¸€ç§è¿‘ä¼¼æ±‚è§£æ–¹ç¨‹çš„æ–¹æ³•</li><li>ä½¿ç”¨å‡½æ•°f(x)çš„æ³°å‹’çº§æ•°çš„å‰é¢å‡ é¡¹æ¥å¯»æ‰¾æ–¹ç¨‹f(x) = 0çš„æ ¹</li></ul></li><li>åœ¨æ±‚æå€¼é—®é¢˜ä¸­ï¼Œæ±‚$g(\mathbf w) = \frac {\partial J(\mathbf w)}{\partial w} = 0$çš„æ ¹<ul><li>å¯¹åº”$J(\mathbf w)$å¤„å–æå€¼</li></ul></li><li>å°†å¯¼æ•°$g(\mathbf w)$åœ¨ $w^t$å¤„è¿›è¡ŒTaylorå±•å¼€ï¼š<br>$0 = \bf g(\hat w) = g(w^t)+(\hat w - w^t)H(w^t) + Op(\hat w - w^t)$</li><li>å»æ‰é«˜é˜¶æ— ç©·å°$Op(\bf \hat w - w^t)$ï¼Œä»è€Œå¾—åˆ°<br>$g(\bf w^t)+(\hat w - w^t)H(w^t) = 0 \Rightarrow \hat w = w^t - H^{-1}(w^t)g(w^t)$</li><li>å› æ­¤è¿­ä»£æœºåˆ¶ä¸ºï¼š<br>$\bf w^{t+1} = w^t - H^{-1}(w^t)g(w^t)$<ul><li>ä¹Ÿè¢«ç§°ä¸ºäºŒé˜¶æ¢¯åº¦ä¸‹é™æ³•ï¼Œç§»åŠ¨æ–¹å‘:$\bf d = -(H(w^t))^{-1}g(w^t)$</li><li>Vs. ä¸€é˜¶æ¢¯åº¦æ³•ï¼Œç§»åŠ¨æ–¹å‘:$\bf d = -g(w^t)$ç§»åŠ¨</li></ul></li></ul></li><li>Iteratively Reweighted Least Squaresï¼ˆIRLSï¼‰<ul><li>å¼•å…¥è®°å·ï¼š<br>$\bf g^t(w) = X^T(\mu^t - y), \mu_i^t = \sigma((w^t)^Tx_i)$<br>$\bf H^t(w) = X^TS^tX$,$ S^t:diag(\mu_i^t(1-\mu_1^t),â€¦,\mu_N^t(1-\mu_N^t))$</li><li>æ ¹æ®ç‰›é¡¿æ³•çš„ç»“æœï¼š<br>$w^{t+1} = w^t - (H^t)^{-1}g^t = (X^TS^tX)^{-1}X^TS^tz$</li><li>å›å¿†æœ€å°äºŒä¹˜é—®é¢˜ï¼š<ul><li>ç›®æ ‡å‡½æ•°ï¼š$J(\bf w) = \sum_{i=1}^N(y_i - w^Tx)^2 = (y - Xw)^T(y - Xw)$</li><li>è§£ï¼š$\hat w = (X^TX)^{-1}X^Ty$</li></ul></li><li>å›å¿†åŠ æƒæœ€å°äºŒä¹˜é—®é¢˜ï¼š<ul><li>ç›®æ ‡å‡½æ•°:$J(\bf w) = \sum_{i=1}^N(y_i - w^Tx)^2 = (y - Xw)^T\Sigma^{-1}(y - Xw)$</li><li>è§£ï¼š$\hat w = (X^T\Sigma^{-1}X)^{-1}X^T\Sigma^{-1}y$</li></ul></li><li>IRLSä¸­ï¼Œ$\bf w^{t+1} = (X^TS^tX)^{-1}X^TS^t[Xw^t + (S^t)^{-1}(y - \mu ^t)]$<ul><li>ç›¸å½“äºæƒé‡çŸ©é˜µä¸º $\Sigma^{-1} = \bf S^t$</li><li>ç”±äº$S^t$æ˜¯å¯¹è§’é˜µï¼Œ$S^t$ç›¸å½“äºç»™æ¯ä¸ªæ ·æœ¬çš„æƒé‡$S_{ii}^t = \mu_i^t(1-\mu_i^t), \mathbf z_i^t = (\mathbf w^t)^T\mathbf x_i + \frac {y_i - \mu_i^t}{S_{ii}^t}$</li></ul></li></ul></li><li>æ‹Ÿç‰›é¡¿æ³•<ul><li>ç‰›é¡¿æ³•æ¯”ä¸€èˆ¬çš„æ¢¯åº¦ä¸‹é™æ³•æ”¶æ•›é€Ÿåº¦å¿«ï¼Œä½†æ˜¯åœ¨é«˜ç»´æƒ…å†µä¸‹ï¼Œè®¡ç®—ç›®æ ‡å‡½æ•°çš„äºŒé˜¶åå¯¼æ•°çš„å¤æ‚åº¦å¾ˆå¤§ï¼Œè€Œä¸”æœ‰æ—¶å€™ç›®æ ‡å‡½æ•°çš„æµ·æ£®çŸ©é˜µæ— æ³•ä¿æŒæ­£å®šï¼Œä¸å­˜åœ¨é€†çŸ©é˜µï¼Œæ­¤æ—¶ç‰›é¡¿æ³•å°†ä¸å†èƒ½ä½¿ç”¨ã€‚</li><li>å› æ­¤ï¼Œäººä»¬æå‡ºäº†æ‹Ÿç‰›é¡¿æ³•ã€‚å…¶åŸºæœ¬æ€æƒ³æ˜¯ï¼šä¸ç”¨äºŒé˜¶åå¯¼æ•°è€Œæ„é€ å‡ºå¯ä»¥è¿‘ä¼¼HessiançŸ©é˜µ(æˆ–HessiançŸ©é˜µçš„é€†çŸ©é˜µ)çš„æ­£å®šå¯¹ç§°çŸ©é˜µï¼Œè¿›è€Œå†é€æ­¥ä¼˜åŒ–ç›®æ ‡å‡½æ•°ã€‚ä¸åŒçš„æ„é€ æ–¹æ³•å°±äº§ç”Ÿäº†ä¸åŒçš„æ‹Ÿç‰›é¡¿æ³•ï¼ˆQuasi-Newton Methodsï¼‰<ul><li>BFGSï¼LBFGSï¼Newton-CG</li></ul></li></ul></li><li>æ­£åˆ™åŒ–çš„Logisticå›å½’<ul><li>è‹¥æŸå¤±å‡½æ•°å–logisticæŸå¤±ï¼Œåˆ™Logisticå›å½’çš„ç›®æ ‡å‡½æ•°ä¸º<br>$J(\mathbf w) = \sum_{i=1}^N-[y_i log(\mu_i)+(1-y_i)log(1-u_i)]$</li><li>åŒçº¿æ€§å›å½’ç±»ä¼¼ï¼ŒLogisticå›å½’äº¦å¯åŠ ä¸ŠL2æ­£åˆ™<br>$J(\mathbf w) = \sum_{i=1}^N-[y_i log(\mu_i)+(1-y_i)log(1-u_i)]+\lambda \Vert \mathbf w\Vert ^2_2$</li><li>æˆ–L1æ­£åˆ™<br>$J(\mathbf w) = \sum_{i=1}^N-[y_i log(\mu_i)+(1-y_i)log(1-u_i)]+\lambda \vert \mathbf w\vert $</li><li>L2æ­£åˆ™çš„Logisticå›å½’æ±‚è§£<ul><li>æ¢¯åº¦ä¸º:<br>$g_{I 2}(\mathbf{w})=g(\mathbf{w})+\lambda \mathbf{w}=\sum_{i=1}^{N}\left(\mu\left(\mathbf{x}_{i}\right)-y_{i}\right) \mathbf{x}_{i}+\lambda \mathbf{w}=\mathbf{X}^{T}(\mathbf{\mu}-\mathbf{y})+\lambda \mathbf{w}$</li><li>HessiançŸ©é˜µä¸ºï¼š$\mathbf{H}_{L 2}(\mathbf{w})=\mathbf{H}(\mathbf{w})+\lambda \mathbf{I}=\mathbf{X}^{T} \mathbf{S} \mathbf{X}+\lambda \mathbf{I}$</li><li>ç±»ä¼¼ä¸å¸¦æ­£åˆ™çš„Logisticå›å½’ï¼Œå¯é‡‡ç”¨ï¼ˆéšæœºï¼‰æ¢¯åº¦ä¸‹é™ã€ç‰›é¡¿æ³•æˆ–æ‹Ÿç‰›é¡¿æ³•æ±‚è§£ã€‚</li></ul></li><li>L1æ­£åˆ™çš„Logisticå›å½’æ±‚è§£<ul><li>L1æ­£åˆ™é¡¹çš„åœ¨0å¤„ä¸å¯å¯¼</li><li>åœ¨æ­¤æˆ‘ä»¬L1æ­£åˆ™çš„Logisticå›å½’çš„ç‰›é¡¿æ³•ï¼ˆIRLSï¼‰æ±‚è§£<ul><li>éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆåœ¨çº¿å­¦ä¹ ï¼‰åœ¨CTRé¢„ä¼°éƒ¨åˆ†è®²è§£</li></ul></li><li>Recallï¼šIRLS<script type="math/tex; mode=display">\mathbf{w}^{t+1}=\left(\mathbf{X}^{T} \mathbf{S}^{t} \mathbf{X}\right)^{-1} \mathbf{X}^{T} \mathbf{S}^{t} \mathbf{z}=\underset{\mathbf{w}}{\arg \min }\left\|\left(\mathbf{S}^{t}\right)^{1 / 2} \mathbf{X} \mathbf{w}-\left(\mathbf{S}^{t}\right)^{1 / 2} \mathbf{z}\right\|_{2}^{2}</script></li><li>L1æ­£åˆ™çš„Logisticå›å½’åœ¨æ¯æ¬¡è¿­ä»£ä¸­å¯è§†ä¸ºä¸€ä¸ªå†åŠ æƒçš„Lassoé—®é¢˜ï¼š<script type="math/tex; mode=display">\mathbf{w}^{t+1}=\underset{\mathbf{w}}{\arg \min }\left\|\left(\mathbf{S}^{t}\right)^{1 / 2} \mathbf{X} \mathbf{w}-\left(\mathbf{S}^{t}\right)^{1 / 2} \mathbf{z}\right\|_{2}^{2}, s . t .\|\mathbf{w}\|_{1}<t</script></li></ul></li></ul></li><li>å°ç»“<ul><li>Logisticå›å½’ï¼š<ul><li>æŸå¤±å‡½æ•°ï¼šè´Ÿlogä¼¼ç„¶æŸå¤±</li><li>æ­£åˆ™ï¼šL2/L1æ­£åˆ™</li><li>ä¼˜åŒ–ï¼šæ¢¯åº¦ä¸‹é™ï¼ç‰›é¡¿æ³•ï¼æ‹Ÿç‰›é¡¿æ³•</li></ul></li></ul></li></ul><h5 id="2ã€Softmaxåˆ†ç±»å™¨"><a href="#2ã€Softmaxåˆ†ç±»å™¨" class="headerlink" title="2ã€Softmaxåˆ†ç±»å™¨"></a>2ã€Softmaxåˆ†ç±»å™¨</h5><ul><li>å¤šç±»åˆ†ç±»ä»»åŠ¡<ul><li>ä¸€å¯¹æ‰€æœ‰(One-vs-all /One-vs-rest)ï¼š<br>$f_{w}^{c}(x) = p(y=c \mid \mathbf x, \mathbf W), c =1, 2, 3$<br>å¦‚æœæ˜¯æ­£åˆ™LRï¼Œæ¯ç±»çš„æ¨¡å‹éƒ½æœ‰è‡ªå·±æ­£åˆ™å‚æ•°</li><li>One-vs-all<ul><li>å¯¹æ¯ä¸ªç±»åˆ«cï¼Œè®­ç»ƒä¸€ä¸ªlogisticå›å½’åˆ†ç±»å™¨$f_w^c(x)$ï¼Œé¢„æµ‹æ¦‚ç‡$y=c$</li><li>å¯¹æ–°çš„è¾“å…¥xï¼Œé€‰æ‹©ä½¿å¾—$f_w^c(x)$æœ€å¤§çš„ç±»åˆ«ä½œä¸ºå…¶é¢„æµ‹ï¼š$\underset{c}{max} f_w^c(\mathbf x)$</li></ul></li></ul></li><li>Softmaxåˆ†ç±»å™¨<ul><li>ä»sigmoidï¼ˆå¯¹åº”äºŒé¡¹åˆ†å¸ƒï¼‰æ‰©å±•ä¸ºsoftmaxå‡½æ•°ï¼ˆå¯¹åº”å¤šé¡¹åˆ†å¸ƒCatï¼‰ï¼š<br>$p(y=c \mid \mathbf x, \mathbf W) = Cat(y \mid S(\bf W^Tx))$</li><li>Softmax å‡½æ•°ç±»ä¼¼å–æœ€å¤§å‡½æ•°ï¼š<br>$S(\mathbf \eta)_c = \frac {exp(\eta_c)}{\sum^C_{c\prime = 1}\  exp(\eta_{c\prime})}$</li><li>ç»¼åˆèµ·æ¥ï¼š<br>$p(y = c \mid \mathbf x, \mathbf W) = \frac {exp(\mathbf w_c^T\mathbf x)}{\sum^C_{c\prime = 1}\  exp(\mathbf w_{c\prime}^T\mathbf x)}$</li></ul></li><li>Softmaxå›å½’<ul><li>å¼•å…¥è®°å·ï¼š<br>$\mu_{ic} = p(y_i = c \mid \mathbf x_i, \mathbf W) = S(\eta_i)_c$<br>$\eta_i = \mathbf W^T\mathbf x_i$  C $\times$ vector<br>$y_{ic} = \prod (y_i =c)$</li><li>åˆ™è´Ÿä¼¼ç„¶å‡½æ•°ä¸ºï¼š$ \begin{eqnarray}J(\mathbf W)<br>&amp;=&amp;NLL(\mathbf W) \\<br>&amp;=&amp; -l(\mathbf W) \\<br>&amp;=&amp; -log\prod_{i=1}^N \prod_{c=1}^C \mu_{ic}^{y_{ic}} \\<br>&amp;=&amp; - \sum_{i=1}^N\sum_{c=1}^Cy_{ic}log \mu_{ic}\\<br>&amp;=&amp; -\sum_{i=1}^N[(\sum_{c=1}^Cy_{ic}\mathbf w_c^T \mathbf x_i) - log(\sum_{c \prime = 1}^C exp(\mathbf w^T_{c \prime} \mathbf x_i))]<br>\end{eqnarray}$<ul><li>æ¢¯åº¦:$g = [\nabla J(\mathbf w_i),â€¦,\nabla J(\mathbf w_c)] = [\mathbf g_1,â€¦,\mathbf g_c]$<br>$\mathbf g_c = \sum_{i=1}^N(\mu_{ic}-y_{ic})\mathbf x_i$</li><li>HessiançŸ©é˜µä¸ºæ­£å®šï¼š$\mathbf H = \sum_{i=1}^N(diag(\mathbf \mu_i)-\mathbf \mu_i \mathbf \mu_i^T)\otimes \mathbf x_i \mathbf x_i^T$</li></ul></li></ul></li><li>å°ç»“ï¼šSoftmaxåˆ†ç±»å™¨Logisticå›å½’<ul><li>Softmaxåˆ†ç±»å™¨èƒ½å®ç°å¤šç±»åˆ†ç±»ï¼Œæ˜¯å¯¹Logisticå›å½’åœ¨ä¸¤ç±»åˆ†ç±»ä»»åŠ¡ä¸Šçš„æ‰©å±•</li><li>ä¼˜åŒ–ç®—æ³•å’Œæ­£åˆ™ä¸ä¸¤ç±»åˆ†ç±»Logisticå›å½’ç±»ä¼¼</li></ul></li></ul><h5 id="3ã€Scikit-learnä¸­çš„Logisticå›å½’å®ç°"><a href="#3ã€Scikit-learnä¸­çš„Logisticå›å½’å®ç°" class="headerlink" title="3ã€Scikit learnä¸­çš„Logisticå›å½’å®ç°"></a>3ã€Scikit learnä¸­çš„Logisticå›å½’å®ç°</h5><ul><li>Scikit learn ä¸­çš„LogisticRegressionå®ç°<ul><li>Scikit learnæä¾›çš„LogisticRegressionå®ç°ä¸ºï¼š<br>LogisticRegression(penalty=â€™l2â€™, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver=â€™liblinearâ€™, max_iter=100, multi_class=â€™ovrâ€™, verbose=0, warm_start=False, n_jobs=1)<ul><li>Logisticå›å½’çš„æ­£åˆ™å‚æ•°ï¼špenaltyã€C</li><li>ä¼˜åŒ–æ±‚è§£å‚æ•°ï¼š dualã€solverã€max_iterã€tolã€warm_start</li><li>æ¨¡å‹å‚æ•°ï¼š multi_classã€fit_interceptã€intercept_scaling</li><li>æ ·æœ¬å‡è¡¡å‚æ•°ï¼šclass_weight</li></ul></li></ul></li><li>LogisticRegressionå‚æ•°åˆ—è¡¨</li></ul><div class="table-container"><table><thead><tr><th>å‚æ•°</th><th>è¯´æ˜</th></tr></thead><tbody><tr><td>penalty</td><td>æƒ©ç½šå‡½æ•°ï¼æ­£åˆ™å‡½æ•°ï¼Œæ”¯æŒL2æ­£åˆ™å’ŒL1æ­£åˆ™ï¼Œç¼ºçœï¼šL2</td></tr><tr><td>dual</td><td>åŸé—®é¢˜ï¼ˆprimalï¼‰è¿˜æ˜¯å¯¹å¶é—®é¢˜æ±‚è§£ã€‚å¯¹å¶åªæ”¯æŒL2æ­£åˆ™å’Œliblinear solverã€‚å½“æ ·æœ¬æ•°n_samples&gt;ç‰¹å¾æ•°ç›®n_featuresæ—¶ï¼Œç¼ºçœï¼šFalse</td></tr><tr><td>tol</td><td>è¿­ä»£ç»ˆæ­¢åˆ¤æ®çš„è¯¯å·®èŒƒå›´ã€‚ç¼ºçœ:1e-4</td></tr><tr><td>C</td><td>C=1/$\lambda$ , ç¼ºçœï¼š1</td></tr><tr><td>fit_intercept</td><td>æ˜¯å¦åœ¨å†³ç­–å‡½æ•°ä¸­åŠ å…¥æˆªè·é¡¹ã€‚å¦‚æœæ•°æ®å·²ç»ä¸­å¿ƒåŒ–ï¼Œå¯ä»¥ä¸ç”¨ã€‚ç¼ºçœï¼šTrue</td></tr><tr><td>intercept_scaling</td><td>æˆªè·ç¼©æ”¾å› å­ï¼Œå½“fit_interceptä¸ºTrueä¸”liblinear solveræœ‰æ•ˆæ‰€ä»¥è¿˜æ˜¯å¯¹yåšæ ‡å‡†åŒ–é¢„å¤„ç†</td></tr><tr><td>class_weight</td><td>ä¸åŒç±»åˆ«æ ·æœ¬çš„æƒé‡ï¼Œç”¨æˆ·æŒ‡å®šæ¯ç±»æ ·æœ¬æƒé‡æˆ–â€˜balancedâ€™ï¼ˆæ¯ç±»æ ·æœ¬æƒé‡ä¸è¯¥ç±»æ ·æœ¬å‡ºç°æ¯”ä¾‹æˆåæ¯”ï¼‰ã€‚ç¼ºçœï¼šNone</td></tr><tr><td>random_state</td><td>æ··åˆæ•°æ®çš„ä¼ªéšæœºæ•°ã€‚ç¼ºçœï¼šNone</td></tr><tr><td>solver</td><td>ä¼˜åŒ–æ±‚è§£ç®—æ³•ï¼Œå¯ä¸ºâ€˜newton-cgâ€™, â€˜lbfgsâ€™, â€˜liblinearâ€™, â€˜sagâ€™, â€˜sagaâ€™ã€‚ç¼ºçœï¼šliblinear</td></tr><tr><td>max_iter</td><td>æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå½“newton-cg, sag and lbfgs solversæ—¶æœ‰æ•ˆã€‚ç¼ºçœï¼š100</td></tr><tr><td>multi_class</td><td>å¤šç±»åˆ†ç±»å¤„ç†ç­–ç•¥ï¼Œå¯ä¸ºâ€˜ovrâ€™, â€˜multinomialâ€™ã€‚â€˜ovrâ€™ä¸º1å¯¹å¤šï¼Œå°†å¤šç±»åˆ†ç±»è½¬åŒ–ä¸ºå¤šä¸ªä¸¤ç±»åˆ†ç±»é—®é¢˜ï¼Œmultinomialä¸ºsoftmaxåˆ†ç±»ã€‚ç¼ºçœï¼šâ€˜ovrâ€™</td></tr><tr><td>verbose</td><td>æ˜¯å¦è¯¦ç»†è¾“å‡º</td></tr><tr><td>warm_start</td><td>æ˜¯å¦çƒ­å¯åŠ¨ï¼ˆç”¨ä¹‹å‰çš„ç»“æœä½œä¸ºåˆå§‹åŒ–ï¼‰ï¼Œå¯¹liblinear solveræ— æ•ˆã€‚ç¼ºçœï¼šFalse</td></tr><tr><td>n_jobs</td><td>å¤šçº¿ç¨‹æ§åˆ¶ã€‚ç¼ºçœå€¼-1ï¼Œç®—æ³•è‡ªåŠ¨æ£€æµ‹å¯ç”¨CPUæ ¸ï¼Œå¹¶ä½¿ç”¨å…¨éƒ¨æ ¸</td></tr></tbody></table></div><ul><li>å¤šåˆ†ç±»é—®é¢˜<ul><li>multi_classå‚æ•°å†³å®šäº†å¤šç±»åˆ†ç±»çš„å®ç°æ–¹å¼</li><li>â€˜ovrâ€™ ï¼šå³1å¯¹å…¶ä»–ï¼ˆone-vs-restï¼ŒOvRï¼‰ï¼Œå°†å¤šç±»åˆ†ç±»è½¬åŒ–ä¸ºå¤šä¸ªäºŒç±»åˆ†ç±»ä»»åŠ¡ã€‚ä¸ºäº†å®Œæˆç¬¬cç±»çš„åˆ†ç±»å†³ç­–ï¼Œå°†æ‰€æœ‰ç¬¬cç±»çš„æ ·æœ¬ä½œä¸ºæ­£ä¾‹ï¼Œé™¤äº†ç¬¬cç±»æ ·æœ¬ä»¥å¤–çš„æ‰€æœ‰æ ·æœ¬éƒ½ä½œä¸ºè´Ÿä¾‹ã€‚</li><li>â€˜multinomialâ€™ ï¼šå¤šå¯¹å¤šï¼ˆmany-vs-manyï¼ŒMvMï¼‰ï¼Œå³softmaxå›å½’æ¨¡å‹ã€‚</li><li>OvRç›¸å¯¹ç®€å•ï¼Œä½†åˆ†ç±»æ•ˆæœç›¸å¯¹ç•¥å·®<ul><li>å¤§å¤šæ•°æƒ…å†µï¼Œä¸æ’é™¤æŸäº›æƒ…å†µä¸‹OvRæ›´å¥½</li></ul></li><li>MvMåˆ†ç±»ç›¸å¯¹ç²¾ç¡®ï¼Œä½†åˆ†ç±»é€Ÿåº¦è¾ƒOvRæ…¢</li><li>multi_classé€‰æ‹©ä¼šå½±å“ä¼˜åŒ–ç®—æ³•solverå‚æ•°çš„é€‰æ‹©<ul><li>OvRï¼šå¯ç”¨æ‰€æœ‰çš„slover</li><li>Multinomialï¼š åªèƒ½é€‰æ‹©newton-cg, lbfgså’Œsagï¼saga</li></ul></li></ul></li><li>ä¼˜åŒ–æ±‚è§£ç®—æ³•solver<ul><li>liblinearï¼šä½¿ç”¨äº†å¼€æºçš„liblinearåº“å®ç°ï¼Œä½¿ç”¨åæ ‡è½´ä¸‹é™æ³•æ¥è¿­ä»£ä¼˜åŒ–æŸå¤±å‡½æ•°</li><li>sagï¼šéšæœºå¹³å‡æ¢¯åº¦ä¸‹é™ï¼ˆStochastic Average Gradientï¼‰ï¼Œæ˜¯æ¢¯åº¦ä¸‹é™æ³•çš„å˜ç§ï¼Œæ¯æ¬¡è¿­ä»£ä»…ç”¨ä¸€éƒ¨åˆ†çš„æ ·æœ¬æ¥è®¡ç®—æ¢¯åº¦ï¼Œé€‚åˆäºæ ·æœ¬å¤šçš„æƒ…å†µ</li><li>sagaï¼š sagçš„å¢å¼ºç‰ˆæœ¬</li><li>lbfgsï¼šæ‹Ÿç‰›é¡¿æ³•çš„ä¸€ç§ï¼Œåˆ©ç”¨æŸå¤±å‡½æ•°äºŒé˜¶å¯¼æ•°çŸ©é˜µï¼ˆHessiançŸ©é˜µï¼‰æ¥è¿­ä»£ä¼˜åŒ–æŸå¤±å‡½æ•°</li><li>newton-cgï¼šç‰›é¡¿æ³•å®¶æ—çš„ä¸€ç§ï¼ˆ å…±è½­æ¢¯åº¦ï¼‰</li><li>å¯¹å°æ•°æ®é›†ï¼Œâ€˜liblinearâ€™ æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é€‰æ‹©ï¼Œè€Œâ€˜sagâ€™ å’Œâ€˜sagaâ€™ å¯¹å¤§æ•°æ®é›†æ›´å¿«</li><li>å¯¹å¤šç±»åˆ†ç±»é—®é¢˜ï¼Œåªæœ‰â€˜newton-cgâ€™, â€˜sagâ€™, â€˜sagaâ€™ å’Œâ€˜lbfgsâ€™æ”¯æŒMvMï¼ˆmultinomialï¼‰ï¼Œ â€˜liblinearâ€™ åªæ”¯æŒOvRï¼ˆone-versus-restï¼‰ çš„æ–¹å¼</li><li>â€˜newton-cgâ€™, â€˜lbfgsâ€™ å’Œâ€˜sagâ€™ æ”¯æŒL2æ­£åˆ™ï¼Œè€Œâ€˜liblinearâ€™ å’Œâ€˜sagaâ€™ æ”¯æŒL1æ­£åˆ™</li><li>æ³¨æ„ï¼š â€˜sagâ€™ å’Œâ€˜sagaâ€™ åªæœ‰å½“ç‰¹å¾æœ‰ç±»ä¼¼çš„å°ºåº¦ï¼ˆscaleï¼‰æ—¶èƒ½ä¿è¯å¿«é€Ÿæ”¶æ•›ã€‚ï¼ˆå¯¹æ•°æ®åšæ ‡å‡†åŒ–é¢„å¤„ç†ï¼‰</li></ul></li><li>ä¼˜åŒ–æ±‚è§£ç®—æ³•solveré€‰æ‹©</li></ul><div class="table-container"><table><thead><tr><th>æ­£åˆ™</th><th>æ±‚è§£ç®—æ³•</th><th>åº”ç”¨åœºæ™¯</th></tr></thead><tbody><tr><td>L1</td><td>liblinear</td><td>å¦‚æœæ¨¡å‹çš„ç‰¹å¾éå¸¸å¤šï¼Œå¸Œæœ›ä¸€äº›ä¸é‡è¦çš„ç‰¹å¾ç³»æ•°å½’é›¶ï¼Œä»è€Œè®©æ¨¡å‹ç³»æ•°ç¨€ç–çš„è¯ï¼Œå¯ä»¥ä½¿ç”¨L1æ­£åˆ™åŒ–ã€‚liblinearé€‚ç”¨äºå°æ•°æ®é›†</td></tr><tr><td>L1</td><td>saga</td><td>å½“æ•°æ®é‡è¾ƒå¤§ï¼Œä¸”é€‰æ‹©L1ï¼Œåªèƒ½é‡‡ç”¨saga</td></tr><tr><td>L2</td><td>liblinear</td><td>libniearåªæ”¯æŒå¤šå…ƒé€»è¾‘å›å½’çš„OvRï¼Œä¸æ”¯æŒå¤šé¡¹åˆ†å¸ƒæŸå¤±ï¼ˆMvMï¼‰ï¼Œä½†MVMç›¸å¯¹ç²¾ç¡®</td></tr><tr><td>L2</td><td>lbfgs/newton-cg/sag</td><td>è¾ƒå¤§æ•°æ®é›†ï¼Œæ”¯æŒOvRå’ŒMvMä¸¤ç§å¤šå…ƒlogitå›å½’</td></tr><tr><td>L2</td><td>sagï¼saga</td><td>å¦‚æœæ ·æœ¬é‡éå¸¸å¤§ï¼Œsagï¼sgaæ˜¯ç¬¬ä¸€é€‰æ‹©</td></tr></tbody></table></div><p>å¯¹äºå¤§æ•°æ®é›†ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨SGDClassifierï¼Œå¹¶ä½¿ç”¨logloss</p><ul><li>ç±»åˆ«æƒé‡class_weight<ul><li>class_weightç”¨äºä¸åŒç±»åˆ«æ ·æœ¬æ•°ç›®ä¸å‡è¡¡çš„æƒ…å†µ</li></ul></li></ul><h5 id="4ã€ä¸å¹³è¡¡æ•°æ®åˆ†ç±»å­¦ä¹ "><a href="#4ã€ä¸å¹³è¡¡æ•°æ®åˆ†ç±»å­¦ä¹ " class="headerlink" title="4ã€ä¸å¹³è¡¡æ•°æ®åˆ†ç±»å­¦ä¹ "></a>4ã€ä¸å¹³è¡¡æ•°æ®åˆ†ç±»å­¦ä¹ </h5><ul><li>ä¸å¹³è¡¡æ•°æ®çš„å‡ºç°åœºæ™¯<ul><li>æœç´¢å¼•æ“çš„ç‚¹å‡»é¢„æµ‹<ul><li>ç‚¹å‡»çš„ç½‘é¡µå¾€å¾€å æ®å¾ˆå°çš„æ¯”ä¾‹</li></ul></li><li>ç”µå­å•†åŠ¡é¢†åŸŸçš„å•†å“æ¨è<ul><li>æ¨èçš„å•†å“è¢«è´­ä¹°çš„æ¯”ä¾‹å¾ˆä½</li></ul></li><li>ä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹</li><li>ä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹</li><li>â€¦</li></ul></li><li>è§£å†³æ–¹æ¡ˆ<ul><li>ä»æ•°æ®çš„è§’åº¦ï¼šæŠ½æ ·ï¼Œä»è€Œä½¿å¾—æ•°æ®ç›¸å¯¹å‡è¡¡</li><li>ä»ç®—æ³•çš„è§’åº¦ï¼šè€ƒè™‘ä¸åŒè¯¯åˆ†ç±»æƒ…å†µä»£ä»·çš„å·®å¼‚æ€§å¯¹ç®—æ³•è¿›è¡Œä¼˜åŒ–</li></ul></li><li>é‡‡æ ·<ul><li>éšæœºæ¬ é‡‡æ ·ï¼šä»å¤šæ•°ç±»ä¸­éšæœºé€‰æ‹©å°‘é‡æ ·æœ¬å†åˆå¹¶åŸæœ‰å°‘æ•°ç±»æ ·æœ¬ä½œä¸ºæ–°çš„è®­ç»ƒæ•°æ®é›†<ul><li>æœ‰æ”¾å›é‡‡æ ·</li><li>æ— æ”¾å›é‡‡æ ·</li><li>ä¼šé€ æˆä¸€äº›ä¿¡æ¯ç¼ºå¤±ï¼Œé€‰å–çš„æ ·æœ¬å¯èƒ½æœ‰åå·®</li></ul></li><li>éšæœºè¿‡é‡‡æ ·ï¼šéšæœºå¤åˆ¶å°‘æ•°ç±»æ¥æ ·æœ¬<ul><li>æ‰©å¤§äº†æ•°æ®é›†ï¼Œé€ æˆæ¨¡å‹è®­ç»ƒå¤æ‚åº¦åŠ å¤§ï¼Œå¦ä¸€æ–¹é¢ä¹Ÿå®¹æ˜“é€ æˆæ¨¡å‹çš„è¿‡æ‹Ÿåˆé—®é¢˜</li></ul></li></ul></li><li>é›†æˆå­¦ä¹ ç®—æ³•<ul><li>EasyEnsembleç®—æ³•ï¼š<ul><li>å¯¹äºå¤šæ•°ç±»æ ·æœ¬ï¼Œé€šè¿‡næ¬¡æœ‰æ”¾å›æŠ½æ ·ç”Ÿæˆnä»½å­é›†</li><li>å°‘æ•°ç±»æ ·æœ¬åˆ†åˆ«å’Œè¿™nä»½æ ·æœ¬åˆå¹¶è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼šnä¸ªæ¨¡å‹</li><li>æœ€ç»ˆæ¨¡å‹ï¼šnä¸ªæ¨¡å‹é¢„æµ‹ç»“æœçš„å¹³å‡å€¼</li></ul></li><li>BalanceCascadeï¼ˆçº§è”ï¼‰ç®—æ³•ï¼š<ul><li>ä»å¤šæ•°ç±»ä¸­æœ‰æ•ˆåœ°é€‰æ‹©ä¸€äº›æ ·æœ¬ä¸å°‘æ•°ç±»æ ·æœ¬åˆå¹¶ä¸ºæ–°çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒ</li><li>è®­ç»ƒå¥½çš„æ¨¡å‹æ¯ä¸ªå¤šæ•°ç±»æ ·æœ¬è¿›è¡Œé¢„æµ‹ã€‚è‹¥é¢„æµ‹æ­£ç¡®ï¼Œåˆ™ä¸è€ƒè™‘å°†å…¶ä½œä¸ºä¸‹ä¸€è½®çš„è®­ç»ƒæ ·æœ¬</li><li>ä¾æ¬¡è¿­ä»£ç›´åˆ°æ»¡è¶³æŸä¸€åœæ­¢æ¡ä»¶ï¼Œæœ€ç»ˆçš„æ¨¡å‹æ˜¯å¤šæ¬¡è¿­ä»£æ¨¡å‹çš„ç»„åˆ</li></ul></li></ul></li><li>SMOTE: Synthetic Minority Over-sampling Technique<ul><li>åŸºæœ¬æ€æƒ³ï¼šåŸºäºâ€œæ’å€¼â€æ¥ä¸ºå°‘æ•°ç±»åˆæˆæ–°çš„æ ·æœ¬</li><li>å¯¹å°‘æ•°ç±»çš„ä¸€ä¸ªæ ·æœ¬$i$ ï¼Œå…¶ç‰¹å¾å‘é‡ä¸º$x_i$,ï¼š<ul><li><ol><li>ä»å°‘æ•°ç±»çš„å…¨éƒ¨N ä¸ªæ ·æœ¬ä¸­æ‰¾åˆ°æ ·æœ¬$x_i$çš„Kä¸ªè¿‘é‚»ï¼ˆå¦‚æ¬§æ°è·ç¦»ï¼‰ï¼Œè®°ä¸º$x_{i(near)}, near \in \{1, â€¦, K\}$</li></ol></li><li><ol><li>ä»è¿™Kä¸ªè¿‘é‚»ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬$x_{i(nn)}$ï¼Œå†ç”Ÿæˆä¸€ä¸ª0åˆ°1ä¹‹é—´çš„éšæœºæ•°$\zeta$ ï¼Œä»è€Œåˆæˆä¸€ä¸ªæ–°æ ·æœ¬$x_{i1}$ï¼š<ul><li>$x_{i1} = (1-\zeta)x_i + \zeta x_{inn}$</li><li>æ–°æ ·æœ¬$x_{i1}$ç›¸å½“äºæ˜¯è¡¨ç¤ºæ ·æœ¬xiå’Œè¡¨ç¤ºæ ·æœ¬$x_{i(nn)}$ çš„ç‚¹ä¹‹é—´æ‰€è¿çº¿æ®µä¸Šçš„ä¸€ä¸ªç‚¹ï¼š æ’å€¼</li></ul></li></ol></li></ul></li><li>SMOTEç®—æ³•æ‘’å¼ƒäº†éšæœºè¿‡é‡‡æ ·å¤åˆ¶æ ·æœ¬çš„åšæ³•ï¼Œå¯ä»¥é˜²æ­¢éšæœºè¿‡é‡‡æ ·æ˜“è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚å®è·µè¯æ˜æ­¤æ–¹æ³•å¯ä»¥æé«˜åˆ†ç±»å™¨çš„æ€§èƒ½</li><li>SMOTE å¯¹é«˜ç»´æ•°æ®ä¸æ˜¯å¾ˆæœ‰æ•ˆ</li><li>å½“ç”Ÿæˆåˆæˆæ€§å®ä¾‹æ—¶ï¼ŒSMOTE å¹¶ä¸ä¼šæŠŠæ¥è‡ªå…¶ä»–ç±»çš„ç›¸é‚»å®ä¾‹è€ƒè™‘è¿›æ¥ï¼Œè¿™å¯¼è‡´äº†ç±»é‡å çš„å¢åŠ ï¼Œå¹¶ä¼šå¼•å…¥é¢å¤–çš„å™ªéŸ³ã€‚ä¸ºäº†è§£å†³SMOTEç®—æ³•çš„è¿™ä¸€ç¼ºç‚¹æå‡ºä¸€äº›æ”¹è¿›ç®—æ³•ï¼Œå¦‚Borderline-SMOTEç®—æ³•</li></ul></li><li>ä»£ä»·æ•æ„Ÿå­¦ä¹ <ul><li>åœ¨ç®—æ³•å±‚é¢ä¸Šè§£å†³ä¸å¹³è¡¡æ•°æ®å­¦ä¹ çš„æ–¹æ³•ä¸»è¦æ˜¯åŸºäºä»£ä»·æ•æ„Ÿå­¦ä¹ ç®—æ³•(Cost-Sensitive Learning)</li><li>ä»£ä»·æ•æ„Ÿå­¦ä¹ æ–¹æ³•çš„æ ¸å¿ƒè¦ç´ æ˜¯ä»£ä»·çŸ©é˜µï¼šä¸åŒç±»å‹çš„è¯¯åˆ†ç±»æƒ…å†µå¯¼è‡´çš„ä»£ä»·ä¸ä¸€æ ·</li><li>åŸºäºä»£ä»·çŸ©é˜µåˆ†æï¼Œä»£ä»·æ•æ„Ÿå­¦ä¹ æ–¹æ³•ä¸»è¦æœ‰ä»¥ä¸‹ä¸‰ç§å®ç°æ–¹å¼ï¼š</li><li>ä»è´å¶æ–¯é£é™©ç†è®ºå‡ºå‘ï¼ŒæŠŠä»£ä»·æ•æ„Ÿå­¦ä¹ çœ‹æˆæ˜¯åˆ†ç±»ç»“æœçš„ä¸€ç§åå¤„ç†ï¼ŒæŒ‰ç…§ä¼ ç»Ÿæ–¹æ³•å­¦ä¹ åˆ°ä¸€ä¸ªæ¨¡å‹ï¼Œä»¥å®ç°æŸå¤±æœ€å°ä¸ºç›®æ ‡å¯¹ç»“æœè¿›è¡Œè°ƒæ•´<ul><li>ä¸ä¾èµ–æ‰€ç”¨å…·ä½“çš„åˆ†ç±»å™¨</li><li>ä½†æ˜¯ç¼ºç‚¹è¦æ±‚åˆ†ç±»å™¨è¾“å‡ºå€¼ä¸ºæ¦‚ç‡</li></ul></li><li>ä»å­¦ä¹ æ¨¡å‹å‡ºå‘ï¼Œå¯¹å…·ä½“å­¦ä¹ æ–¹æ³•çš„æ”¹é€ ï¼Œä½¿ä¹‹èƒ½é€‚åº”ä¸å¹³è¡¡æ•°æ®ä¸‹çš„å­¦ä¹ <ul><li>ä»£ä»·æ•æ„Ÿçš„æ”¯æŒå‘é‡æœºï¼Œå†³ç­–æ ‘ï¼Œç¥ç»ç½‘ç»œ</li><li>ä»é¢„å¤„ç†çš„è§’åº¦å‡ºå‘ï¼Œå°†ä»£ä»·ç”¨äºæƒé‡çš„è°ƒæ•´ï¼Œä½¿å¾—åˆ†ç±»å™¨æ»¡è¶³ä»£ä»·æ•æ„Ÿçš„ç‰¹æ€§</li></ul></li></ul></li><li>Scikit learnä¸­çš„ä¸å‡è¡¡æ ·æœ¬åˆ†ç±»å¤„ç†<ul><li>ç±»åˆ«æƒé‡class_weight<ul><li>class_weightå‚æ•°ç”¨äºæ ‡ç¤ºåˆ†ç±»æ¨¡å‹ä¸­å„ç±»åˆ«æ ·æœ¬çš„æƒé‡</li><li><ol><li>ä¸è€ƒè™‘æƒé‡ï¼Œå³æ‰€æœ‰ç±»åˆ«çš„æƒé‡ç›¸åŒ</li></ol></li><li><ol><li>balancedï¼šè‡ªåŠ¨è®¡ç®—ç±»åˆ«æƒé‡<ul><li>æŸç±»åˆ«çš„æ ·æœ¬é‡è¶Šå¤šï¼Œå…¶æƒé‡è¶Šä½ï¼›æ ·æœ¬é‡è¶Šå°‘ï¼Œåˆ™æƒé‡è¶Šé«˜</li><li>ç±»æƒé‡è®¡ç®—æ–¹æ³•ä¸ºï¼šn_samples / (n_classes * np.bincount(y))<ul><li>n_samplesä¸ºæ ·æœ¬æ•°ï¼Œn_classesä¸ºç±»åˆ«æ•°é‡ï¼Œnp.bincount(y)è¾“å‡ºæ¯ä¸ªç±»çš„æ ·æœ¬æ•°</li></ul></li></ul></li></ol></li><li><ol><li>æ‰‹åŠ¨æŒ‡å®šå„ä¸ªç±»åˆ«çš„æƒé‡<ul><li>å¦‚å¯¹äº0,1äºŒç±»åˆ†ç±»é—®é¢˜ï¼Œå¯ä»¥å®šä¹‰class_weight={0:0.9, 1:0.1}ï¼Œå³ç±»åˆ«0çš„æƒé‡ä¸º90%ï¼Œè€Œç±»åˆ«1çš„æƒé‡ä¸º10%</li></ul></li></ol></li></ul></li><li>æ ·æœ¬æƒé‡sample_weight<ul><li>æ¨¡å‹è®­ç»ƒï¼š$fit(X, y, sample_weight=None)$<ul><li>å…¶ä¸­å‚æ•°sample_weightä¸ºæ ·æœ¬æƒé‡å‚æ•°</li></ul></li><li>å½“æ ·æœ¬é«˜åº¦å¤±è¡¡æ—¶ï¼Œæ ·æœ¬ä¸æ˜¯æ€»ä½“æ ·æœ¬çš„æ— åä¼°è®¡ï¼Œå¯èƒ½å¯¼è‡´æ¨¡å‹é¢„æµ‹èƒ½åŠ›ä¸‹é™</li><li>è§£å†³æ–¹æ¡ˆï¼šè°ƒèŠ‚æ ·æœ¬æƒé‡<ul><li>ä¸€ç§æ˜¯åœ¨class_weightä½¿ç”¨balanced</li><li>å¦ä¸€ç§æ˜¯åœ¨è°ƒç”¨fitå‡½æ•°æ—¶ï¼Œé€šè¿‡sample_weightæ¥è°ƒèŠ‚æ¯ä¸ªæ ·æœ¬æƒé‡</li><li>å¦‚æœä¸¤ç§æ–¹æ³•éƒ½ç”¨äº†ï¼Œé‚£ä¹ˆæ ·æœ¬çš„çœŸæ­£æƒé‡æ˜¯class_weight*sample_weight</li></ul></li></ul></li></ul></li><li>å°ç»“ï¼šLogisticå›å½’<ul><li>ä¸å‡è¡¡æ ·æœ¬åˆ†ç±»<ul><li>æ ·æœ¬é‡‡æ ·ï¼šè¿‡é‡‡æ ·ã€æ¬ é‡‡æ ·</li><li>åˆ†ç±»å™¨ï¼šä»£ä»·æ•æ„Ÿå‡½æ•°<ul><li>æ ·æœ¬æƒé‡ã€ç±»åˆ«æƒé‡</li></ul></li></ul></li></ul></li></ul><h5 id="5ã€åˆ†ç±»æ¨¡å‹çš„è¯„ä»·"><a href="#5ã€åˆ†ç±»æ¨¡å‹çš„è¯„ä»·" class="headerlink" title="5ã€åˆ†ç±»æ¨¡å‹çš„è¯„ä»·"></a>5ã€åˆ†ç±»æ¨¡å‹çš„è¯„ä»·</h5><ul><li>åˆ†ç±»æ¨¡å‹æ€§èƒ½è¯„ä»·<ul><li>æŸå¤±å‡½æ•°å¯ä»¥ä½œä¸ºè¯„ä»·æŒ‡æ ‡(log_lossã€zero_one_lossã€hinge_loss)</li><li>logisticï¼è´Ÿlogä¼¼ç„¶æŸå¤±ï¼ˆlog_lossï¼‰ï¼š<ul><li>logloss $=-\frac{1}{N} \sum_{i=0}^{N} \sum_{j=0}^{M} y_{i j} \log p_{i j}$<ul><li>Mä¸ºç±»åˆ«æ•°ï¼Œ$y_{ij}$ä¸ºäºŒå€¼ï¼Œå½“ç¬¬iä¸ªæ ·æœ¬ä¸ºç¬¬jç±»æ—¶$y_{ij}$ = 1ï¼Œå¦åˆ™å–0ï¼›$p_{ij}$ä¸ºæ¨¡å‹é¢„æµ‹çš„ç¬¬iä¸ªæ ·æœ¬ä¸ºç¬¬jç±»çš„æ¦‚ç‡</li><li>å½“M=2æ—¶, $\operatorname{logloss}=-\frac{1}{N} \sum_{i=0}^{N}\left(y_{i} \log p_{i}+\left(1-y_{i}\right) \log \left(1-p_{i}\right)\right)$<ul><li>$y_{i}$ä¸ºç¬¬iä¸ªæ ·æœ¬ç±»åˆ«ï¼Œ$p_{i}$ä¸ºæ¨¡å‹é¢„æµ‹çš„ç¬¬iä¸ªæ ·æœ¬ä¸ºç¬¬1ç±»çš„æ¦‚ç‡</li></ul></li></ul></li><li>0-1æŸå¤±(zero_one_loss) ï¼ˆé”™è¯¯ç‡ã€æ­£ç¡®ç‡è¯„ä»·æŒ‡æ ‡å‡ä¸æ­¤æœ‰å…³ï¼‰<ul><li>$\mathrm{MCE}=-\frac{1}{N} \sum_{\hat{y}_{i} \neq y_{i}} 1$</li></ul></li></ul></li></ul></li><li>ä¸¤ç±»åˆ†ç±»ä»»åŠ¡ä¸­æ›´å¤šè¯„ä»·æŒ‡æ ‡<ul><li>ROCï¼AUC</li><li>PRæ›²çº¿</li><li>MAP@n</li></ul></li><li>False Positive &amp; False Negative<ul><li>0-1æŸå¤±ï¼šå‡è®¾ä¸¤ç§é”™è¯¯çš„ä»£ä»·ç›¸ç­‰<ul><li>False Positive ï¼ˆFPï¼‰ &amp; False Negativeï¼ˆFNï¼‰</li></ul></li><li>æœ‰äº›ä»»åŠ¡ä¸­å¯èƒ½æŸä¸€ç±»é”™è¯¯çš„ä»£ä»·æ›´å¤§<ul><li>å¦‚åŒ»ç–—è¯Šæ–­ä¸­å°†ç—…ä¾‹è¯¯åˆ†ä¸ºæ­£å¸¸ï¼Œé”™è¿‡è¯Šç–—æ—¶æœº</li><li>å› æ­¤å•ç‹¬åˆ—å‡ºæ¯ç§é”™è¯¯çš„æ¯”ä¾‹ï¼šæ··æ·†çŸ©é˜µ</li></ul></li><li>æ··æ·†çŸ©é˜µï¼ˆconfusion matrixï¼‰<ul><li>çœŸæ­£çš„æ­£å€¼ï¼ˆtrue positivesï¼‰</li><li>å‡çš„æ­£å€¼ï¼ˆfalse positivesï¼‰</li><li>çœŸæ­£çš„è´Ÿå€¼ï¼ˆtrue negativesï¼‰</li><li>å‡çš„è´Ÿå€¼ï¼ˆfalse negatives ï¼‰</li><li>Scikit-learnå®ç°äº†å¤šç±»åˆ†ç±»ä»»åŠ¡çš„æ··æ·†çŸ©é˜µ</li><li>sklearn.metrics.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)<ul><li>y_trueï¼š Nä¸ªæ ·æœ¬çš„æ ‡ç­¾è§‚æµ‹å€¼ï¼çœŸå€¼</li><li>y_predï¼š Nä¸ªæ ·æœ¬çš„é¢„æµ‹æ ‡ç­¾å€¼</li><li>labelsï¼šCä¸ªç±»åˆ«åœ¨çŸ©é˜µçš„ç´¢å¼•é¡ºåº<ul><li>ç¼ºçœä¸ºy_trueæˆ–y_predç±»åˆ«å‡ºç°çš„é¡ºåº</li></ul></li><li>sample_weightï¼š Nä¸ªæ ·æœ¬çš„æƒé‡</li></ul></li></ul></li></ul></li></ul><div class="table-container"><table><thead><tr><th></th><th>$\hat y = 1$</th><th>$\hat y = 0$</th><th>$\Sigma$</th></tr></thead><tbody><tr><td>y = 1</td><td>#TP</td><td>#FN</td><td>$N_{+}$</td></tr><tr><td>y = 0</td><td>#FP</td><td>#TN</td><td>$N_{-}$</td></tr><tr><td>$\Sigma$</td><td>$\hat N_{+}$</td><td>$\hat N_{-}$</td></tr></tbody></table></div><ul><li>Receiver Operating Characteristic (ROC)<br>  $\operatorname{accuracy}=\frac{T P+T N}{N}$<br>  error rate $=\frac{F P+F N}{N}$<ul><li>PPV - positive predictive value, precision é¢„æµ‹ç»“æœä¸ºçœŸçš„æ ·æœ¬ä¸­çœŸæ­£ä¸ºçœŸçš„æ¯”ä¾‹</li><li>TPR - true positive rate, sensitivity, recall, hit rate é¢„æµ‹ç»“æœå¬å›äº†å¤šå°‘çœŸæ­£çš„çœŸæ ·æœ¬</li><li>FPR â€“ False positive rate, false alarm, fallout é¢„æµ‹ç»“æœå°†å¤šå°‘å‡çš„æ ·æœ¬é¢„æµ‹é¢„æµ‹æˆäº†çœŸ</li><li>ä¸‹é¢æˆ‘ä»¬è®¨è®ºç»™å®šé˜ˆå€¼Ï„çš„TPRå’ŒFPR</li><li>å¦‚æœä¸æ˜¯åªè€ƒè™‘ä¸€ä¸ªé˜ˆå€¼ï¼Œè€Œæ˜¯åœ¨ä¸€äº›åˆ—é˜ˆå€¼ä¸Šè¿è¡Œæ£€æµ‹å™¨ï¼Œå¹¶ç”»å‡ºTPRå’ŒFPRä¸ºé˜ˆå€¼Ï„çš„éšå¼å‡½æ•°ï¼Œå¾—åˆ°ROCæ›²çº¿ã€‚<br><img src="/2019/04/06/ç¬¬äºŒå‘¨ Logisticå›å½’ã€SVM/ROCæ›²çº¿.png" alt="ROCæ›²çº¿"><ul><li>$T P R=\frac{T P}{N_{+}}$</li><li>$F P R=\frac{F P}{N_{-}}$</li></ul></li></ul></li></ul><div class="table-container"><table><thead><tr><th></th><th>$\hat y = 1$</th><th>$\hat y = 0$</th><th>$\Sigma$</th></tr></thead><tbody><tr><td>y = 1</td><td>#TP</td><td>#FN</td><td>$N_{+}$</td></tr><tr><td>y = 0</td><td>#FP</td><td>#TN</td><td>$N_{-}$</td></tr><tr><td>$\Sigma$</td><td>$\hat N_{+}$</td><td>$\hat N_{-}$</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th></th><th>y = 1</th><th>y = 0</th><th>y = 1</th><th>y = 0</th></tr></thead><tbody><tr><td>$\hat y = 1$</td><td>$T P / \hat{N}_{+}=$ precision</td><td>$F P / \hat{N}_{+}=\mathrm{FDP}$</td><td>$T P / N_{+}=\mathrm{TPR}$</td><td>$F P / N_{-}=\mathrm{FPR}$</td></tr><tr><td>$\hat y = 0$</td><td>$F N / \hat{N}_{-}$</td><td>$T N / \hat{N}_{-}=\mathrm{NPV}$</td><td>$F N / N_{+}=\mathrm{FNR}$</td><td>$T N / N_{-}=\mathrm{TNR}$</td></tr></tbody></table></div><ul><li>PRæ›²çº¿<ul><li>Precision and Recall (PRæ›²çº¿)ï¼šç”¨äºç¨€æœ‰äº‹ä»¶æ£€æµ‹ï¼Œå¦‚ç›®æ ‡æ£€æµ‹ã€ä¿¡æ¯æ£€ç´¢<ul><li>è´Ÿæ ·æœ¬éå¸¸å¤šï¼Œå› æ­¤$F P R=F P / N_{-}$å¾ˆå°ï¼Œæ¯”è¾ƒTPRå’ŒFPRä¸æ˜¯å¾ˆæœ‰ä¿¡æ¯ï¼ˆROCæ›²çº¿ä¸­åªæœ‰å·¦è¾¹å¾ˆå°ä¸€éƒ¨åˆ†æœ‰æ„ä¹‰ï¼‰$\rightarrow$ åªè®¨è®ºæ­£æ ·æœ¬</li><li>Precisionï¼ˆç²¾åº¦ï¼ŒæŸ¥å‡†ç‡ï¼‰ï¼šä»¥ä¿¡æ¯æ£€ç´¢ä¸ºä¾‹ï¼Œå¯¹äºä¸€ä¸ªæŸ¥è¯¢ï¼Œè¿”å›äº†ä¸€ç³»åˆ—çš„æ–‡æ¡£ï¼Œæ­£ç¡®ç‡æŒ‡çš„æ˜¯è¿”å›ç»“æœä¸­ç›¸å…³æ–‡æ¡£å çš„æ¯”ä¾‹<ul><li>Precision=è¿”å›ç»“æœä¸­ç›¸å…³æ–‡æ¡£çš„æ•°ç›®/è¿”å›ç»“æœçš„æ•°ç›®</li></ul></li><li>Recallï¼ˆå¬å›ç‡ï¼ŒæŸ¥å…¨ç‡ï¼‰ï¼šè¿”å›ç»“æœä¸­ç›¸å…³æ–‡æ¡£å æ‰€æœ‰ç›¸å…³æ–‡æ¡£çš„æ¯”ä¾‹<ul><li>Recall=è¿”å›ç»“æœä¸­ç›¸å…³æ–‡æ¡£çš„æ•°ç›®/æ‰€æœ‰ç›¸å…³æ–‡æ¡£çš„æ•°ç›®</li></ul></li></ul></li><li>Precision and Recall (PRæ›²çº¿)<ul><li>é˜ˆå€¼å˜åŒ–æ—¶çš„På’ŒR</li><li>Precsion $=T P / \hat{N}_{+}$ ï¼šæ£€æµ‹ç»“æœçœŸæ­£ä¸ºæ­£çš„æ¯”ä¾‹</li><li>$\mathrm{Recall}=T P / N_{+}$ï¼šè¢«æ­£ç¡®æ£€æµ‹åˆ°çš„æ­£æ ·æœ¬çš„æ¯”ä¾‹<br><img src="/2019/04/06/ç¬¬äºŒå‘¨ Logisticå›å½’ã€SVM/PRæ›²çº¿.png" alt="PRæ›²çº¿"></li></ul></li></ul></li><li>AP<ul><li>Precisionåªè€ƒè™‘äº†è¿”å›ç»“æœä¸­ç›¸å…³æ–‡æ¡£çš„ä¸ªæ•°ï¼Œæ²¡æœ‰è€ƒè™‘æ–‡æ¡£ä¹‹é—´çš„åºã€‚</li><li>å¯¹ä¸€ä¸ªæœç´¢å¼•æ“æˆ–æ¨èç³»ç»Ÿè€Œè¨€ï¼Œè¿”å›çš„ç»“æœæ˜¯æœ‰åºçš„ï¼Œä¸”è¶Šç›¸å…³çš„æ–‡æ¡£è¶Šé å‰è¶Šå¥½ï¼Œäºæ˜¯æœ‰äº†APçš„æ¦‚å¿µã€‚</li><li>AP: Average Precisionï¼Œå¯¹ä¸åŒå¬å›ç‡ç‚¹ä¸Šçš„ç²¾åº¦è¿›è¡Œå¹³å‡<ul><li>$A P=\int_{0}^{1} p(k) d r=\sum_{k=0}^{n} p(k) \Delta r(k)$</li><li>å³PRæ›²çº¿ä¸‹çš„é¢ç§¯ï¼ˆRecallï¼š AUCä¸ºROCä¸‹çš„é¢ç§¯ï¼‰</li><li>å…¶ä¸­kä¸ºè¿”å›æ–‡æ¡£ä¸­çš„åºä½ï¼Œnä¸ºè¿”å›æ–‡æ¡£çš„æ•°ç›®ï¼Œ$p(k)$ ä¸ºåˆ—è¡¨ä¸­kæˆªæ­¢ç‚¹çš„precisionï¼Œ $\Delta r(k)$ è¡¨ç¤ºä»k-1åˆ°k Recallçš„å˜åŒ–ã€‚</li></ul></li><li>ä¸Šè¿°ç¦»æ•£æ±‚å’Œè¡¨ç¤ºç­‰ä»·äºï¼š$A P=\sum_{k=0}^{n} p(k) r e l(k) /$ ç›¸å…³æ–‡æ¡£æ•°ç›®ï¼Œå…¶ä¸­<br>$r e l(k)$ä¸ºç¤ºæ€§å‡½æ•°ï¼Œå³ç¬¬kä¸ªä½ç½®ä¸ºç›¸å…³æ–‡æ¡£å–1ï¼Œå¦åˆ™å–0.<ul><li>è®¡ç®—æ¯ä¸ªä½ç½®ä¸Šçš„precisionï¼Œå¦‚æœè¯¥ä½ç½®çš„æ–‡æ¡£æ˜¯ä¸ç›¸å…³çš„åˆ™è¯¥ä½ç½®precision=0</li><li>ç„¶åå¯¹æ‰€æœ‰çš„ä½ç½®çš„precisionå†æ±‚å¹³å‡</li></ul></li></ul></li><li>Mean Average Precision<ul><li>å¤šä¸ªæŸ¥è¯¢çš„APå¹³å‡ï¼š</li><li>$M A P=\left(\sum_{q=0}^{Q} A P(q)\right) /(Q)$</li><li>å…¶ä¸­Qä¸ºæŸ¥è¯¢çš„æ•°ç›®ï¼Œnä¸ºæ–‡æ¡£æ•°ç›®</li></ul></li><li>MAP@K ï¼ˆMAPKï¼‰<ul><li>åœ¨ç°ä»£webä¿¡æ¯æ£€ç´¢ä¸­ï¼Œrecallå…¶å®å·²ç»æ²¡æœ‰æ„ä¹‰ï¼Œå› ä¸ºç›¸å…³æ–‡æ¡£æœ‰æˆåƒä¸Šä¸‡ä¸ªï¼Œå¾ˆå°‘æœ‰äººä¼šå…³å¿ƒæ‰€æœ‰æ–‡æ¡£ã€‚</li><li>Precision@Kï¼šåœ¨ç¬¬Kä¸ªä½ç½®ä¸Šçš„Precision<ul><li>å¯¹äºæœç´¢å¼•æ“ï¼Œè€ƒè™‘åˆ°å¤§éƒ¨åˆ†ä½œè€…åªå…³æ³¨å‰ä¸€ã€ä¸¤é¡µçš„ç»“æœï¼Œæ‰€ä»¥Precision @10ï¼Œ Precision @20å¯¹å¤§è§„æ¨¡æœç´¢å¼•æ“éå¸¸æœ‰æ•ˆ</li></ul></li><li>MAP@Kï¼šå¤šä¸ªæŸ¥è¯¢Precision@Kçš„å¹³å‡</li></ul></li><li>F1 åˆ†æ•°<ul><li>äº¦è¢«ç§°ä¸ºF1 score, balanced F-score or F-measure</li><li>Precision å’ŒRecall è°ƒå’Œå¹³å‡ï¼š<br>$F 1=\frac{(2 \ast  Precision   \ast   Recall) }{ (Precision + Recall) }$<ul><li>æœ€å¥½ä¸º1ï¼Œæœ€å·®ä¸º0</li><li>å¤šç±»ï¼šæ¯ç±»çš„F1å¹³å‡å€¼</li></ul></li></ul></li><li>æ¨¡å‹æ€§èƒ½è¯„ä»·<ul><li>Scikit learn æä¾›3 ä¸åŒçš„APIï¼Œç”¨äºè¯„ä¼°æ¨¡å‹é¢„æµ‹çš„æ€§èƒ½ï¼š<ul><li>Estimator score method: æ¨¡å‹è‡ªå¸¦çš„åˆ†æ•°æ–¹æ³•ï¼ˆscoreå‡½æ•°ï¼‰æä¾›ä¸€ä¸ªç¼ºçœçš„è¯„ä¼°å‡†åˆ™ã€‚</li><li>Scoring parameter: é‡‡ç”¨äº¤å‰éªŒè¯çš„æ¨¡å‹è¯„ä¼°å·¥å…·ï¼ˆ model_selection.cross_val_score and model_selection.GridSearchCVã€ä»¥åŠä¸€äº›xxxCVç±»ï¼‰æœ‰scoring å‚æ•°ï¼ˆæœ€ä½³å‚æ•°ä¸ºæœ€å¤§scoringæ¨¡å‹å¯¹åº”çš„å‚æ•°ï¼‰</li><li>Metric functions: metricsæ¨¡å—æä¾›è¯„ä»·é¢„æµ‹æ€§èƒ½çš„åŠŸèƒ½<ul><li>Classification metrics,</li><li>Multilabel ranking metrics</li><li>Regression metrics</li><li>Clustering metrics</li></ul></li></ul></li></ul></li><li>åˆ†ç±»æ¨¡å‹æ€§èƒ½è¯„ä»·<ul><li>å¯¹åˆ†ç±»æ¨¡å‹ï¼Œç¼ºçœçš„scoreå‡½æ•°è¿”å›çš„æ˜¯æ­£ç¡®ç‡ï¼ˆMean accuracyï¼‰</li><li>scoringå‚æ•°<ul><li>äº¤å‰éªŒè¯ä¸­å¯è®¾ç½®scoringå‚æ•°ï¼Œè§„å®šæ¨¡å‹æ€§èƒ½çš„è¯„ä»·æŒ‡æ ‡</li><li>æ³¨æ„ï¼šscoringè¶Šå¤§çš„æ¨¡å‹æ€§èƒ½è¶Šå¥½ï¼Œæ‰€ä»¥å¦‚æœé‡‡ç”¨æŸå¤±ï¼è¯¯å·®ï¼Œéœ€è¦åŠ negï¼Œå¦‚â€˜neg_log_lossâ€™</li></ul></li><li>å¯ä»¥è‡ªå®šä¹‰è¯„ä»·å‡½æ•°<ul><li>æœ‰äº›æŒ‡æ ‡è¿˜éœ€è¦é¢å¤–çš„å‚æ•°ï¼Œè€Œæ²¡æœ‰åœ¨scoringå‡ºç°ï¼Œæˆ–è€…æŸä¸ªä»»åŠ¡éœ€è¦ç‰¹æ®Šçš„æŒ‡æ ‡ï¼Œscikit learnæ”¯æŒè‡ªå®šä¹‰scoringå‡½æ•°</li></ul></li><li>Scikit learnä¸­Classification metrics æ¨¡å—é’ˆå¯¹ä¸¤ç±»åˆ†ç±»é—®é¢˜æä¾›çš„æ€§èƒ½è¯„ä»·æŒ‡æ ‡æœ‰</li></ul></li></ul><h5 id="6ã€Logisticå›å½’ä¹‹æ¨¡å‹é€‰æ‹©-å‚æ•°è°ƒä¼˜"><a href="#6ã€Logisticå›å½’ä¹‹æ¨¡å‹é€‰æ‹©-å‚æ•°è°ƒä¼˜" class="headerlink" title="6ã€Logisticå›å½’ä¹‹æ¨¡å‹é€‰æ‹©_å‚æ•°è°ƒä¼˜"></a>6ã€Logisticå›å½’ä¹‹æ¨¡å‹é€‰æ‹©_å‚æ•°è°ƒä¼˜</h5><ul><li>ç½‘æ ¼æœç´¢ï¼ˆGrid Searchï¼‰<ul><li>ä¸åŒè¶…å‚æ•°ä¸‹çš„æ¨¡å‹æ€§èƒ½ä¸åŒã€‚</li><li>ä¸ºäº†æ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼Œé€šå¸¸å¯¹è¿™äº›è¶…å‚æ•°è®¾å®šæœç´¢èŒƒå›´</li><li>å¤šä¸ªè¶…å‚æ•°å¯ä»¥è”åˆä¸€èµ·ä¼˜åŒ–ï¼Œå¾—åˆ°è¶…å‚æ•°çš„æœç´¢ç½‘æ ¼<ul><li>å¦‚ï¼šLogisticRegressionä¸­çš„è¶…å‚æ•°penaltyå’ŒCä¸€èµ·ä¼˜åŒ–<ul><li>penaltyå¯å–â€˜l2â€™æˆ–â€˜l1â€™</li><li>Cå‡è®¾å–å€¼èŒƒå›´ä¸ºï¼š 0.001, 0.01, 0.1, 0, 1, 10, 100, 1000</li></ul></li><li>åˆ™æœç´¢ç½‘æ ¼ä¸ºï¼š</li></ul></li></ul></li></ul><div class="table-container"><table><thead><tr><th>â€˜l2â€™</th><th>0.001</th><th>0.01</th><th>0.1</th><th>1</th><th>10</th><th>100</th><th>1000</th></tr></thead><tbody><tr><td>â€˜l1â€™</td><td>0.001</td><td>0.01</td><td>0.1</td><td>1</td><td>10</td><td>100</td><td>1000</td></tr></tbody></table></div><ul><li>LogisticRegressionè¶…å‚æ•°è°ƒä¼˜<ul><li>è¶…å‚æ•°è°ƒä¼˜éœ€å…ˆç¡®å®šè¶…å‚æ•°çš„æœç´¢ç½‘æ ¼ï¼Œç„¶åå¯¹æ¯ä¸ªå¯èƒ½çš„è¶…å‚æ•°ç»„åˆè¯„ä¼°å…¶æ€§èƒ½</li><li>å¯¹LogisticRegressionçš„è¶…å‚æ•°è°ƒä¼˜ï¼Œscikit learnæä¾›ç»™ä¸¤ç§å®ç°æ–¹å¼ï¼š<ul><li><ol><li>åŒå…¶ä»–estimatorä¸€æ ·ï¼Œè°ƒç”¨GridSearchCV ï¼ˆé›†æˆäº†ç½‘æ ¼æœç´¢å’Œäº¤å‰éªŒè¯ï¼‰ï¼šè®¾ç½®å€™é€‰å‚æ•°é›†åˆã€æ ¹æ®å€™é€‰å‚æ•°é›†åˆæ„é€ GridSearchCVã€è°ƒç”¨GridSearchCV çš„fitå‡½æ•°ï¼›</li></ol></li><li><ol><li>LogisticRegressionCV ç±»å†…ç½®çš„LRçš„äº¤å‰éªŒè¯ï¼Œç”¨äºæ‰¾åˆ°æœ€ä¼˜çš„Cå‚æ•°</li></ol></li></ul></li></ul></li><li>LogisticRegressionCV<ul><li>LogisticRegressionCV ä½¿ç”¨äº†å†…ç½®çš„Logisticå›å½’çš„äº¤å‰éªŒè¯ï¼Œç”¨äºæ‰¾åˆ°æœ€ä¼˜çš„Cå‚æ•°ã€‚ï¼ˆæ­£åˆ™å‚æ•°penaltyå¯è®¾ä¸ºâ€˜l1â€™ æˆ–â€˜l2â€™ ï¼‰</li><li>å¯¹äºå¤šåˆ†ç±»é—®é¢˜<ul><li>å¦‚æœmulti_classå‚æ•°è®¾ç½®ä¸ºâ€œovrâ€ï¼Œå¯¹äºæ¯ä¸ªç±»éƒ½è·å¾—ä¸€ä¸ªæœ€ä¼˜çš„Cï¼›</li><li>å¦‚æœmulti_classè®¾ç½®ä¸ºâ€multinomialâ€, å°†è·å¾—ä¸€ä¸ªæœ€ä¼˜çš„Cï¼Œå®ƒä½¿å¾—äº¤å‰ç†µçš„lossï¼ˆcorss-entropy lossï¼‰æœ€å°ã€‚</li></ul></li></ul></li></ul><h5 id="7ã€Logisticå›å½’-Ottoå•†å“åˆ†ç±»ä»£ç "><a href="#7ã€Logisticå›å½’-Ottoå•†å“åˆ†ç±»ä»£ç " class="headerlink" title="7ã€Logisticå›å½’-Ottoå•†å“åˆ†ç±»ä»£ç "></a>7ã€Logisticå›å½’-Ottoå•†å“åˆ†ç±»ä»£ç </h5><h5 id="8ã€æ”¯æŒå‘é‡æœº"><a href="#8ã€æ”¯æŒå‘é‡æœº" class="headerlink" title="8ã€æ”¯æŒå‘é‡æœº"></a>8ã€æ”¯æŒå‘é‡æœº</h5><ul><li>SVMåŸºæœ¬åŸç†<ul><li>SVM as æœ€å¤§é—´éš”åˆ†ç±»å™¨<ul><li>æœ€å¤§é—´éš”åŸåˆ™ï¼šæœ€å¤§åŒ–ä¸¤ä¸ªç±»æœ€è¿‘ç‚¹ä¹‹é—´çš„è·ç¦»<ul><li>è¿™ä¸ªè·ç¦»è¢«ç§°ä¸ºé—´éš”(margin)</li><li>è¾¹ç¼˜ä¸Šçš„ç‚¹è¢«ç§°ä¸ºæ”¯æŒå‘é‡(support vectors)</li></ul></li><li>æˆ‘ä»¬å…ˆå‡è®¾åˆ†ç±»å™¨æ˜¯çº¿æ€§å¯åˆ†çš„</li></ul></li><li>é—´éš”<ul><li>çº¿æ€§åˆ†ç±»é¢ï¼š$f(\mathbf{x}) = \mathbf {w}^{\mathrm{T}} \mathbf {x}+w_{0}$</li><li>åˆ™æœ‰ $\mathbf{x}=\mathbf{x}_{\mathrm{p}}+r \frac{\mathbf{w}}{|\mathbf{w}|}$<ul><li>å…¶ä¸­xåˆ°åˆ†ç±»é¢çš„è·ç¦»r</li></ul></li><li>ä»£å…¥å¾—åˆ° $f(\mathbf{x})=\mathbf{w}^{\mathrm{T}} \mathbf{x}+w_{0}=\mathbf{w}^{\mathrm{T}}\left(x_{\mathrm{p}}+r \frac{\mathbf{w}}{|\mathbf{w}|}\right)+w_{0}$<br>$=\mathbf{w}^{\mathrm{T}} x_{\mathrm{p}}+r \frac{\mathbf{w}^{\mathrm{T}} \mathbf{w}}{|\mathbf{w}|}+w_{0}$<br>$\Rightarrow r=\frac{f(\mathbf{x})}{|\mathbf{w}|}$</li><li>å½“x=0æ—¶ï¼ŒåŸç‚¹åˆ°åˆ†ç±»é¢çš„è·ç¦»<br>$r_{0}=\frac{f(\mathbf{0})}{|\mathbf{w}|}=\frac{w_{0}}{|\mathbf{w}|}$</li></ul></li><li>çº¿æ€§åˆ¤åˆ«å‡½æ•°<ul><li>çº¿æ€§åˆ¤åˆ«å‡½æ•°åˆ©ç”¨ä¸€ä¸ªè¶…å¹³é¢æŠŠç‰¹å¾ç©ºé—´åˆ†éš”æˆä¸¤ä¸ªåŒºåŸŸã€‚</li><li>è¶…å¹³é¢çš„æ–¹å‘ç”±æ³•å‘é‡wç¡®å®šï¼Œå®ƒçš„ä½ç½®ç”±é˜ˆå€¼$w_{0}$ç¡®å®šã€‚</li><li>åˆ¤åˆ«å‡½æ•°f(x)æ­£æ¯”äºxç‚¹åˆ°è¶…å¹³é¢çš„ä»£æ•°è·ç¦»ï¼ˆå¸¦æ­£è´Ÿå·ï¼‰<ul><li>å½“xç‚¹åœ¨è¶…å¹³é¢çš„æ­£ä¾§æ—¶ï¼Œ f(x) &gt;0ï¼›</li><li>å½“xç‚¹åœ¨è¶…å¹³é¢çš„è´Ÿä¾§æ—¶ï¼Œ f(x) &lt;0</li><li>xç‚¹åˆ°è¶…å¹³é¢çš„è·ç¦»$r y_{i}=\frac{y_{i} f(\mathbf{x})}{|\mathbf{w}|}$å¯è§†ä¸ºå¯¹xåˆ¤åˆ«çš„â€œç½®ä¿¡åº¦â€<br>$y_{i} \in\{1,-1\}$</li></ul></li></ul></li><li>SVM ç¬¦å·è¡¨ç¤º</li><li>é—´éš”è®¡ç®—</li><li>SVMï¼šæœ€å¤§é—´éš”<ul><li>æœ€å¤§åŒ–é—´éš”çš„è¶…å¹³é¢ä¸º<br>$\max _{w_{0}, \mathbf{w}} \frac{2}{|\mathbf{w}|}, \quad$ subject to $\quad y_{i}\left(w_{0}+\mathbf{w}^{\mathrm{T}} \mathbf{x}_{i}\right) \geq 1, \quad \forall i$</li><li>ç­‰ä»·äº<br>$\min _{w_{0}, \mathbf{w}} \frac{1}{2}|\mathbf{w}|^{2}, \quad$ subject to $\quad y_{i}\left(w_{0}+\mathbf{w}^{\mathrm{T}} \mathbf{x}_{i}\right) \geq 1, \quad \forall i$<ul><li>äºŒæ¬¡è§„åˆ’é—®é¢˜(ç›®æ ‡å‡½æ•°ä¸ºäºŒæ¬¡å‡½æ•°ï¼Œçº¦æŸä¸ºçº¿æ€§çº¦æŸ)</li><li>å˜é‡æ•°ä¸ºD+1ï¼Œçº¦æŸé¡¹çš„æ•°ç›®ä¸ºN</li></ul></li></ul></li></ul></li><li>å¯¹å¶è¡¨ç¤º(Dual Representation)<ul><li>å‡¸ä¼˜åŒ–ç†è®ºå‘Šè¯‰æˆ‘ä»¬å¯ä»¥å°†è¯¥ä¼˜åŒ–é—®é¢˜ç­‰ä»·åœ°å†™æˆå…¶å¯¹å¶å½¢å¼(dual formulation) ã€‚</li><li>å®šä¹‰æ‹‰æ ¼æœ—æ—¥å‡½æ•°<br>$L\left(\boldsymbol{a}, w_{0}, \mathbf{w}\right)=\frac{1}{2} \mathbf{w}^{T} \mathbf{w}-\sum_{i=1}^{N} \alpha_{i}\left(y_{i}\left(w_{0}+\mathbf{w}^{\mathrm{T}} \mathbf{x}_{i}\right)-1\right), \quad \alpha_{i} \geq 0$</li><li>æ±‚ä½¿å¾—ç›®æ ‡$L\left(\boldsymbol{\alpha}, w_{0}, \mathbf{w}\right)$æœ€å°çš„å¯¹w0å’Œwï¼š<br>$\frac{\partial L}{\partial \mathbf{w}}=0 \Rightarrow \mathbf{w}=\sum_{i=1}^{N} \alpha_{i} y_{i} \mathbf{x}_{i}$<br>$\frac{\partial L}{\partial w_{0}}=0 \Rightarrow \sum_{i=1}^{N} \alpha_{i} y_{i}=0$</li><li>å°†$w_{0}, \mathbf{w}$ä»$L\left(\boldsymbol{\alpha}, w_{0}, \mathbf{w}\right)$æ¶ˆå»ï¼Œå¾—åˆ°å¯¹å¶è¡¨ç¤º</li></ul></li><li>Karush-Kuhn-Tucker (KKT) Conditions<ul><li>å¦‚æœå¼ºå¯¹å¶æ¡ä»¶æˆç«‹ï¼Œåˆ™å¯¹æœ€ä¼˜çš„  $\mathbf{x}^{ \ast } , \lambda^{ \ast } , \mathbf{\mu}^{ \ast } $ï¼Œå¿…é¡»æ»¡è¶³ä¸‹è¿°KKTæ¡ä»¶</li><li>åŸé—®é¢˜çš„å¯è¡ŒåŸŸï¼š$f_{i}\left(\mathbf{x}^{ \ast } \right) \leq 0, h_{j}\left(\mathbf{x}^{ \ast }\right)=0$</li><li>å¯¹å¶é—®é¢˜çš„å¯è¡ŒåŸŸï¼š$\lambda^{\ast } \geq 0$</li><li>å¹³ç¨³æ¡ä»¶ï¼š$\Delta_{x} L(\mathbf{x}, \lambda, \boldsymbol{\mu})=0$</li><li>äº’è¡¥æ¾å¼›æ¡ä»¶ï¼š$\lambda_{i}^{\ast } f_{i}\left(\mathbf{x}^{\ast }\right)=0$</li><li>å¦‚æœ$\mathbf{x}^{+}, \lambda^{+}, \mathbf{\mu}^{+}$æ»¡è¶³å‡¸é—®é¢˜çš„KKTæ¡ä»¶ï¼Œåˆ™å…¶æ˜¯æœ€ä¼˜çš„ã€‚</li></ul></li><li>SVM â€“ Duality<ul><li>åŸé—®é¢˜ï¼š$P=\min _{w} \frac{1}{2} \mathbf{w}^{T} \mathbf{w}$<br>s.t. $y_{i}\left(w_{0}+\mathbf{w}^{\mathrm{T}} \mathbf{x}_{i}\right) \geq 1$</li><li>æ‹‰æ ¼æœ—æ—¥å‡½æ•°:$L(\mathbf{x}, \boldsymbol{a})=\frac{1}{2} \mathbf{w}^{T} \mathbf{w}-\sum_{i} \alpha_{i}\left(y_{i}\left(w_{0}+\mathbf{w}^{\mathrm{T}} \mathbf{x}_{i}\right)-1\right)$</li><li>å¯¹å¶é—®é¢˜ï¼š$D=\max _{\alpha}\left(\mathbf{1}^{T} \boldsymbol{\alpha}-\boldsymbol{\alpha}^{T} \mathbf{y K y}\right),$ where $K_{i j}=\left\langle x_{i}, x_{j}\right\rangle$<br>S.t. $\alpha_{i} \geq 0$</li></ul></li><li>å¯¹å¶æ€§<ul><li>æ‹‰æ ¼æœ—æ—¥å¯¹å¶é€šå¸¸æ˜¯å‡¹çš„ï¼ˆå³ä½¿åŸé—®é¢˜éå‡¸ï¼‰ ï¼Œå¯èƒ½æ›´å®¹æ˜“ä¼˜åŒ–æ±‚è§£</li><li>å¼±å¯¹å¶æ€§ï¼š$\mathrm{P} \geq \mathrm{D}$<ul><li>æ€»æ˜¯æˆç«‹</li></ul></li><li>å¼ºå¯¹å¶æ€§ï¼šP = D<ul><li>å¹¶ä¸æ€»æ˜¯æˆç«‹</li><li>å¯¹å‡¸é—®é¢˜é€šå¸¸æˆç«‹</li><li>å¯¹SVM QPæˆç«‹</li></ul></li></ul></li><li>SVM â€“ KKT Conditions<ul><li>æ‹‰æ ¼æœ—æ—¥å‡½æ•°:$L(\mathbf{x}, \boldsymbol{\alpha})=\frac{1}{2} \mathbf{w}^{T} \mathbf{w}-\boldsymbol{\alpha}^{T}\left(\mathbf{y}\left(\mathbf{x}^{T} \mathbf{w}+w_{0} \mathbf{1}\right)-1\right)$</li><li>å¯¹å¶é—®é¢˜çš„å¯è¡ŒåŸŸï¼š$\alpha_{i}^{\ast } \geq 0$</li><li>åŸé—®é¢˜çš„å¯è¡ŒåŸŸï¼š$y_{i}\left(w_{0}^{\ast }+\mathbf{w}^{\ast_{T}} \mathbf{x}_{i}\right)-1 \geq 0$</li><li>äº’è¡¥æ¾å¼›æ¡ä»¶ï¼š$\alpha_{i}^{\ast }\left[y_{i}\left(w_{0}^{\ast }+\mathbf{w}^{\ast T} \mathbf{x}_{i}\right)-1\right]=0$</li><li>å¹³ç¨³æ¡ä»¶ï¼š$\begin{aligned} \Delta L_{\mathrm{w}} &amp;=0 \Rightarrow \mathbf{w}^{\ast }=\mathbf{x} y \boldsymbol{\alpha} \\ \Delta L_{w_{0}} &amp;=0 \Rightarrow \boldsymbol{\alpha}^{\ast } y \mathbf{1}=0 \end{aligned}$</li></ul></li><li>Î±çš„ç¨€ç–æ€§<ul><li>æ ¹æ®KKTæ¡ä»¶ï¼Œå¯¹æ¯ä¸ªç‚¹<br>$\alpha_{i}^{\ast}=0 \quad$ or $\quad y_{i}\left(w_{0}^{\ast }+\mathbf{w}^{\ast } x_{i}\right)=1$</li><li>å½“$\alpha_{i}^{\ast }=0$æ—¶ï¼Œè¯¥ç‚¹åœ¨å†³ç­–å‡½æ•°ä¸­ä¸èµ·ä½œç”¨<br>$f(\mathbf{x})=w_{0}+\mathbf{w}^{\mathrm{T}} \mathbf{x}=w_{0}+\sum_{i} \alpha_{i} y_{i}\left\langle\mathbf{x}, \mathbf{x}_{i}\right\rangle$</li><li>å…¶ä»–ç‚¹ç§°ä¸ºæ”¯æŒå‘é‡ï¼Œæ»¡è¶³$y_{i}\left(w_{0}^{\ast }+\mathbf{w}^{\ast T} \mathbf{x}_{i}\right)=1$</li><li>å¯¹åº”ä½äºæœ€å¤§é—´éš”è¶…å¹³é¢ä¸Šçš„ç‚¹<ul><li>æ¨¡å‹è®­ç»ƒå¥½åï¼Œå¤§å¤šæ•°ç‚¹å¯ä»¥æŠ›æ‰ï¼Œåªéœ€ä¿ç•™æ”¯æŒå‘é‡</li></ul></li></ul></li><li>w0çš„è®¡ç®—<ul><li>ç”±äºæ”¯æŒå‘é‡æ»¡è¶³ $y_{i}\left(w_{0}+\mathbf{w}^{T} \mathbf{x}_{i}\right)=1$</li><li>å°† $f(\mathbf{x})=w_{0}+\mathbf{w}^{\mathrm{T}} \mathbf{x}=w_{0}+\sum \alpha_{i} y_{i}\left\langle\mathbf{x}, \mathbf{x}_{i}\right\rangle$</li><li>ä»£å…¥ï¼Œå¾—åˆ°<br>$y_{i}\left[\sum_{m \in S} \alpha_{m} y_{m}\left\langle\mathbf{x}_{i}, \mathbf{x}_{m}\right\rangle+ w_{0}\right]=1$<ul><li>ç”¨ä»»æ„ä¸€ä¸ªæ”¯æŒå‘é‡å³å¯æ±‚å¾—$w_{0}$</li></ul></li><li>ä¸ºäº†å¾—åˆ°æ›´ç¨³å®šçš„è§£ï¼Œä¸¤è¾¹åŒä¹˜ä»¥$y_{i}, y_{i}^{2}=1$</li><li>å¹¶å¯¹æ‰€æœ‰çš„æ”¯æŒå‘é‡æ±‚å¹³å‡ï¼Œå¾—åˆ°<br>$w_{0}=\frac{1}{N_{S}} \sum_{m \in \mathcal{S}}\left[y_{i}-\sum_{m \in \mathcal{S}} \alpha_{m} y_{m}\left\langle\mathbf{x}_{i}, \mathbf{x}_{m}\right\rangle\right]$</li></ul></li><li>å°ç»“<ul><li>SVMåŸºæœ¬åŸç†<ul><li>æœ€å¤§é—´éš”åŸåˆ™</li><li>å¯¹å¶è¡¨ç¤º(Dual Representation)</li><li>KKTæ¡ä»¶<h5 id="9ã€å¸¦æ¾å¼›å› å­çš„C-SVM"><a href="#9ã€å¸¦æ¾å¼›å› å­çš„C-SVM" class="headerlink" title="9ã€å¸¦æ¾å¼›å› å­çš„C-SVM"></a>9ã€å¸¦æ¾å¼›å› å­çš„C-SVM</h5><h5 id="10ã€æ ¸æ–¹æ³•"><a href="#10ã€æ ¸æ–¹æ³•" class="headerlink" title="10ã€æ ¸æ–¹æ³•"></a>10ã€æ ¸æ–¹æ³•</h5><h5 id="11ã€æ”¯æŒå‘é‡å›å½’ï¼ˆSVRï¼‰"><a href="#11ã€æ”¯æŒå‘é‡å›å½’ï¼ˆSVRï¼‰" class="headerlink" title="11ã€æ”¯æŒå‘é‡å›å½’ï¼ˆSVRï¼‰"></a>11ã€æ”¯æŒå‘é‡å›å½’ï¼ˆSVRï¼‰</h5><h5 id="12ã€sklearnä¸­çš„SVMå®ç°"><a href="#12ã€sklearnä¸­çš„SVMå®ç°" class="headerlink" title="12ã€sklearnä¸­çš„SVMå®ç°"></a>12ã€sklearnä¸­çš„SVMå®ç°</h5><h5 id="13ã€SVM-Otto"><a href="#13ã€SVM-Otto" class="headerlink" title="13ã€SVM-Otto"></a>13ã€SVM-Otto</h5></li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;1ã€Logisticå›å½’åŸºæœ¬åŸç†&quot;&gt;&lt;a href=&quot;#1ã€Logisticå›å½’åŸºæœ¬åŸç†&quot; class=&quot;headerlink&quot; title=&quot;1ã€Logisticå›å½’åŸºæœ¬åŸç†&quot;&gt;&lt;/a&gt;1ã€Logisticå›å½’åŸºæœ¬åŸç†&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;åˆ†ç±»&lt;ul&gt;
&lt;li&gt;ç»™å®šè®­ç»ƒæ•°æ®$D =\{\mathbf x_i, y_i\}^N_{i=1}$ï¼Œåˆ†ç±»ä»»åŠ¡å­¦ä¹ ä¸€ä¸ªä»è¾“å…¥xåˆ°è¾“å‡ºyçš„æ˜ å°„f ï¼š&lt;br&gt;$\hat y = f(\mathbf x) = \underset{c}{arg\ max}\ p(y = c \mid \mathbf x, D)$&lt;/li&gt;
&lt;li&gt;å…¶ä¸­yä¸ºç¦»æ•£å€¼ï¼Œå…¶å–å€¼èŒƒå›´ç§°ä¸ºæ ‡ç­¾ç©ºé—´:$Y =\{1,2,â€¦,C\}$&lt;/li&gt;
&lt;li&gt;å½“C=2æ—¶ï¼Œä¸ºä¸¤ç±»åˆ†ç±»é—®é¢˜ï¼Œè®¡ç®—å‡º$p(y = 1 \mid \mathbf x)$å³å¯ã€‚æ­¤æ—¶åˆ†å¸ƒä¸ºBernoulliåˆ†å¸ƒ: &lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y \mid \mathbf x) = Ber(y \mid \mu (\mathbf x))&lt;/script&gt;å…¶ä¸­$\mu (\mathbf x) = \mathbb{E}(y \mid \mathbf x) = p(y = 1 \mid \mathbf x)$&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
      <category term="å­¦ä¹ ç¬”è®°" scheme="http://minhzou.top/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="å­¦ä¹ ç¬”è®°" scheme="http://minhzou.top/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="äººå·¥æ™ºèƒ½" scheme="http://minhzou.top/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="Logisticå›å½’" scheme="http://minhzou.top/tags/Logistic%E5%9B%9E%E5%BD%92/"/>
    
      <category term="SVM" scheme="http://minhzou.top/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>Hexo + GitHub Pages + Nextåœ¨windowsä¸‹æ­å»ºä¸ªäººåšå®¢</title>
    <link href="http://minhzou.top/2019/04/01/Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"/>
    <id>http://minhzou.top/2019/04/01/Hexoæ­å»ºåšå®¢/</id>
    <published>2019-04-01T03:43:22.257Z</published>
    <updated>2019-04-02T08:05:09.298Z</updated>
    
    <content type="html"><![CDATA[<p>æ‰æ­å¥½åšå®¢ï¼Œå‘ç°åœ¨åšå®¢å‘å¸ƒæ–‡ç« ç¡®å®æ¯”å¾®ä¿¡å…¬ä¼—å·æ–¹ä¾¿å¾ˆå¤šï¼Œè¿™é‡Œç®€ç•¥è¯´ä¸‹ç”¨ Hexo + GitHub Pages + Nextæ­å»ºä¸ªäººåšå®¢çš„è¯¾ç¨‹ï¼Œå¤§éƒ¨åˆ†ç»éªŒéƒ½æ˜¯æ¥è‡ªäºç½‘ç»œï¼Œæˆ‘ä¼šåœ¨æ•´ä¸ªè¿‡ç¨‹åé¢é™„ä¸Šå‚è€ƒçš„æ–‡ç« ï¼Œä¸€æ¥æ€»ç»“æ­å»ºåšå®¢çš„è¿‡ç¨‹ï¼ŒäºŒæ¥å‡å°‘åæ¥äººè¸©å‘ã€‚<br><a id="more"></a></p><h5 id="æ•´ä¸ªè¿‡ç¨‹ï¼š"><a href="#æ•´ä¸ªè¿‡ç¨‹ï¼š" class="headerlink" title="æ•´ä¸ªè¿‡ç¨‹ï¼š"></a>æ•´ä¸ªè¿‡ç¨‹ï¼š</h5><ul><li>1ã€æ³¨å†ŒGithubè´¦å·åŠåˆ›å»ºä»“åº“</li><li>2ã€å®‰è£…Git for Windows</li><li>3ã€é…ç½®Git</li><li>4ã€å®‰è£…node.js</li><li>5ã€å®‰è£…Hexo</li><li>6ã€ä½¿ç”¨nextè®¾è®¡ä¸ªæ€§åŒ–åšå®¢</li><li>7ã€è¿æ¥Hexoå’ŒGithub PagesåŠéƒ¨ç½²åšå®¢</li><li>8ã€è´­ä¹°åŸŸåå¹¶è§£æ<br>ä»¥ä¸Šå°±æ˜¯å…¨éƒ¨çš„è¿‡ç¨‹ï¼Œå½“ç„¶å…·ä½“è¿˜æœ‰å¾ˆå¤šç»†èŠ‚ï¼Œæ¯”å¦‚æ›´æ¢é…ç½®ã€è®¾ç½®æ–‡ç« å­—æ•°çš„å•ä½ï¼Œé˜…è¯»æ—¶å¸¸çš„å•ä½ï¼Œè®¾ç½®è¯„è®ºåŒºï¼Œå…·ä½“çš„ä¸œè¥¿è¿˜æ˜¯è¦ä¾æ®ä¸ªäººçš„å–œå¥½è°ƒæ•´ï¼Œä½†æ˜¯nextä¸»é¢˜é‡Œé¢åŸºæœ¬éƒ½é›†æˆäº†è¿™äº›åŠŸèƒ½ï¼Œåªè¦ç¨å¾®è°ƒæ•´ä¸‹å°±è¡Œã€‚</li></ul><h5 id="å‚è€ƒçš„æ–‡ç« ï¼š"><a href="#å‚è€ƒçš„æ–‡ç« ï¼š" class="headerlink" title="å‚è€ƒçš„æ–‡ç« ï¼š"></a>å‚è€ƒçš„æ–‡ç« ï¼š</h5><ul><li><a href="https://blog.csdn.net/wapchief/article/details/70801995" target="_blank" rel="noopener">å‚è€ƒçš„æ•´ä¸ªè¿‡ç¨‹</a></li><li><a href="https://blog.csdn.net/qq_33699981/article/details/72716951" target="_blank" rel="noopener">å„ç§ä¸ªæ€§åŒ–å°åŠŸèƒ½</a></li><li><a href="https://blog.csdn.net/wangxw725/article/details/71602256?utm_source=itdadao&amp;utm_medium=referral" target="_blank" rel="noopener">ç»™ç»Ÿè®¡é‡æ·»åŠ å•ä½</a></li><li><a href="https://www.jianshu.com/p/efbeddc5eb19?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation" target="_blank" rel="noopener">å„ç§ä¸ªæ€§åŒ–è®¾ç½®</a></li><li><a href="https://www.jianshu.com/p/35e197cb1273" target="_blank" rel="noopener">æ–‡ç« å‘å¸ƒ</a></li><li><a href="https://blog.csdn.net/weixin_41196185/article/details/79234078" target="_blank" rel="noopener">GitHub/CodingåŒçº¿éƒ¨ç½²</a></li><li><a href="https://www.jianshu.com/p/1edb4b42ff72" target="_blank" rel="noopener">å°ä¹¦åŒ Markdownä½¿ç”¨æ‰‹å†Œ</a></li><li><a href="https://www.jianshu.com/p/a0aa94ef8ab2" target="_blank" rel="noopener">åœ¨Markdownä¸­è¾“å…¥æ•°å­¦å…¬å¼(MathJax)</a></li><li><a href="https://blog.csdn.net/wgshun616/article/details/81019687" target="_blank" rel="noopener">Hexo çš„ Next ä¸»é¢˜ä¸­æ¸²æŸ“ MathJax æ•°å­¦å…¬å¼</a></li><li><a href="https://www.leiyawu.com/2018/02/28/hexo-fs-SyncWriteStream-is-deprecated/" target="_blank" rel="noopener">æŠ¥é”™ï¼šhexo fs.SyncWriteStream is deprecated</a></li><li><a href="https://www.jianshu.com/p/6f77c96b7eff" target="_blank" rel="noopener">Hexo Nextä¸»é¢˜åšå®¢åŠŸèƒ½å®Œå–„</a></li><li><a href="https://blog.csdn.net/luyaxige/article/details/80193409" target="_blank" rel="noopener">MathJaxè¯­æ³•</a></li><li><a href="https://www.cnblogs.com/linxd/p/4955530.html" target="_blank" rel="noopener">MathJaxä¸LaTexä»‹ç»</a></li><li><a href="http://wangwlj.com/2017/10/08/mathjax_basic/" target="_blank" rel="noopener">MathJax(Markdownä¸­çš„å…¬å¼)çš„åŸºæœ¬ä½¿ç”¨è¯­æ³•</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;æ‰æ­å¥½åšå®¢ï¼Œå‘ç°åœ¨åšå®¢å‘å¸ƒæ–‡ç« ç¡®å®æ¯”å¾®ä¿¡å…¬ä¼—å·æ–¹ä¾¿å¾ˆå¤šï¼Œè¿™é‡Œç®€ç•¥è¯´ä¸‹ç”¨ Hexo + GitHub Pages + Nextæ­å»ºä¸ªäººåšå®¢çš„è¯¾ç¨‹ï¼Œå¤§éƒ¨åˆ†ç»éªŒéƒ½æ˜¯æ¥è‡ªäºç½‘ç»œï¼Œæˆ‘ä¼šåœ¨æ•´ä¸ªè¿‡ç¨‹åé¢é™„ä¸Šå‚è€ƒçš„æ–‡ç« ï¼Œä¸€æ¥æ€»ç»“æ­å»ºåšå®¢çš„è¿‡ç¨‹ï¼ŒäºŒæ¥å‡å°‘åæ¥äººè¸©å‘ã€‚&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="æ€»ç»“" scheme="http://minhzou.top/categories/%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="Hexo" scheme="http://minhzou.top/tags/Hexo/"/>
    
      <category term="GitHub Pages" scheme="http://minhzou.top/tags/GitHub-Pages/"/>
    
  </entry>
  
  <entry>
    <title>ç¬¬ä¸€å‘¨ æœºå™¨å­¦ä¹ ç®€ä»‹ä¸çº¿æ€§å›å½’</title>
    <link href="http://minhzou.top/2019/03/31/%E7%AC%AC%E4%B8%80%E5%91%A8%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B%E5%92%8C%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>http://minhzou.top/2019/03/31/ç¬¬ä¸€å‘¨ æœºå™¨å­¦ä¹ ç®€ä»‹å’Œçº¿æ€§å›å½’/</id>
    <published>2019-03-31T12:37:15.065Z</published>
    <updated>2019-04-06T04:03:56.736Z</updated>
    
    <content type="html"><![CDATA[<h5 id="1-1-ä¸€ä¸ªKaggleç«èµ›ä¼˜èƒœè§£å†³æ–¹æ¡ˆ"><a href="#1-1-ä¸€ä¸ªKaggleç«èµ›ä¼˜èƒœè§£å†³æ–¹æ¡ˆ" class="headerlink" title="1.1 ä¸€ä¸ªKaggleç«èµ›ä¼˜èƒœè§£å†³æ–¹æ¡ˆ"></a>1.1 ä¸€ä¸ªKaggleç«èµ›ä¼˜èƒœè§£å†³æ–¹æ¡ˆ</h5><ul><li>ä¸€ä¸ªKaggleç«èµ›ä¼˜èƒœè§£å†³æ–¹æ¡ˆ<ul><li>ä»»åŠ¡ï¼šAvazuç‚¹å‡»ç‡é¢„ä¼°ç«èµ›</li><li>Rank 2nd Owen Zhangçš„è§£æ³•<a id="more"></a></li><li>ä¼˜èƒœç®—æ³•çš„ç‰¹ç‚¹<ul><li>ç‰¹å¾å·¥ç¨‹</li><li>èåˆå¤§æ³•<ul><li>å¤šå±‚</li><li>å¤šç§ä¸åŒæ¨¡å‹çš„ç»„åˆ</li></ul></li><li>æ‰€ä»¥ï¼š<ul><li>åŸºç¡€æ¨¡å‹å¾ˆé‡è¦ï¼ˆçº¿æ€§æ¨¡å‹ï¼‰</li><li>é›†æˆå­¦ä¹ æ¨¡å‹å•æ¨¡å‹æ€§èƒ½å¥½ï¼ˆGBDTï¼‰</li><li>ç‰¹å®šé—®é¢˜çš„æ¨¡å‹è´¡çŒ®å¤§ï¼ˆFMï¼‰</li><li>æ¨¡å‹èåˆå¾ˆé‡è¦</li></ul></li></ul></li></ul></li><li>è¯¾ç¨‹å†…å®¹å®‰æ’<ul><li>åŸºæœ¬æ¨¡å‹<ul><li>çº¿æ€§æ¨¡å‹ï¼š çº¿æ€§å›å½’ï¼Œ logisticå›å½’ï¼Œ SVM</li><li>éçº¿æ€§æ¨¡å‹ï¼š ï¼ˆçº¿æ€§æ¨¡å‹æ ¸åŒ–ï¼‰ã€åˆ†ç±»å›å½’æ ‘</li><li>é›†æˆå­¦ä¹ æ¨¡å‹ï¼ˆéšæœºæ£®æ—ã€GBDTï¼‰</li><li>æ•°æ®é¢„å¤„ç†ï¼šæ•°æ®æ¸…æ´—ï¼Œç‰¹å¾å·¥ç¨‹ï¼Œé™ç»´ï¼Œèšç±»</li></ul></li><li>æ¨¡å‹èåˆ</li><li>æ¨èç³»ç»Ÿ/ç‚¹å‡»ç‡é¢„ä¼°é—®é¢˜ç‰¹å®šè§£å†³æ–¹æ¡ˆ</li></ul></li></ul><h5 id="1-2-æœºå™¨å­¦ä¹ ä»»åŠ¡ç±»å‹"><a href="#1-2-æœºå™¨å­¦ä¹ ä»»åŠ¡ç±»å‹" class="headerlink" title="1.2  æœºå™¨å­¦ä¹ ä»»åŠ¡ç±»å‹"></a>1.2  æœºå™¨å­¦ä¹ ä»»åŠ¡ç±»å‹</h5><ul><li>å®šä¹‰</li><li>æ•°æ®<ul><li>æ•°æ®é€šå¸¸ä»¥äºŒç»´æ•°æ®è¡¨å½¢å¼ç»™å‡º<ul><li>æ¯ä¸€è¡Œï¼š ä¸€ä¸ªæ ·æœ¬</li><li>æ¯ä¸€åˆ—ï¼šä¸€ä¸ªå±æ€§/ç‰¹å¾</li></ul></li><li>ä¾‹ï¼šBostonæˆ¿ä»·é¢„æµ‹æ•°æ®ï¼Œæ ¹æ®æŸåœ°åŒºæˆ¿å±‹å±æ€§ï¼Œé¢„æµ‹è¯¥åœ°åŒºé¢„æµ‹æˆ¿ä»·<ul><li>506è¡Œï¼Œ 506ä¸ªæ ·æœ¬</li><li>14åˆ—</li></ul></li></ul></li><li>æœºå™¨å­¦ä¹ ä»»åŠ¡ç±»å‹<ul><li>ç›‘ç£å­¦ä¹ ï¼ˆSupervised Learningï¼‰<ul><li>åˆ†ç±»ï¼ˆclassficationï¼‰</li><li>å›å½’ï¼ˆregressionï¼‰</li><li>æ’åºï¼ˆrankingï¼‰</li></ul></li><li>éç›‘ç£å­¦ä¹ ï¼ˆunsupervised learningï¼‰<ul><li>èšç±»ï¼ˆclusteringï¼‰</li><li>é™ç»´ï¼ˆdimensionality reductionï¼‰</li><li>æ¦‚ç‡å¯†åº¦ä¼°è®¡ï¼ˆdensity estimationï¼‰</li></ul></li><li>å¢å¼ºå­¦ä¹ ï¼ˆreinforcement learningï¼‰</li><li>åŠç›‘ç£å­¦ä¹ ï¼ˆsemi-supervised learningï¼‰</li><li>è¿ç§»å­¦ä¹ ï¼ˆtransfer learningï¼‰</li><li>â€¦â€¦</li></ul></li><li>ç›‘ç£å­¦ä¹ <br>  å­¦ä¹ ä¸€ä¸ªx-&gt;y çš„æ˜ å°„f, ä»è€Œå¯¹æ–°è¾“å…¥çš„xè¿›è¡Œé¢„æµ‹fï¼ˆxï¼‰<script type="math/tex; mode=display">D = \{X_i,y_i\}^N_{i=1}</script>  Dï¼šè®­ç»ƒæ•°æ®é›†<br>  Nï¼šè®­ç»ƒæ ·æœ¬æ•°ç›®<br>  $X_i$: ç¬¬iä¸ªæ ·æœ¬çš„è¾“å…¥ï¼Œäº¦è¢«ç§°ä¸ºç‰¹å¾ã€å±æ€§æˆ–åå˜é‡<br>  $y_i$: ç¬¬iä¸ªè®­ç»ƒæ ·æœ¬çš„è¾“å‡ºï¼Œäº¦è¢«ç§°ä¸ºå“åº”ï¼Œå¦‚ç±»åˆ«æ ‡ç­¾ã€åºå·æˆ–æ•°å€¼<br>  ä¾‹ï¼šæ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹<ul><li>å›å½’<ul><li>è‹¥è¾“å‡ºyâˆˆRä¸ºè¿ç»­å€¼ï¼Œåˆ™æˆ‘ä»¬ç§°ä¹‹ä¸ºä¸€ä¸ªå›å½’ï¼ˆregressionï¼‰ä»»åŠ¡<br>ä¾‹ï¼š æˆ¿ä»·é¢„æµ‹ï¼Œé¢„æµ‹äºŒæ‰‹è½¦çš„ä»·æ ¼</li><li>å‡è®¾å›å½’æ¨¡å‹ï¼š$y = f(\mathbf x|\theta)$<ul><li>å¦‚åœ¨çº¿æ€§å›å½’ä¸­ï¼Œ$f(\mathbf x|w) = \mathbf w^T \mathbf x$</li></ul></li><li>è®­ç»ƒï¼šæ ¹æ®è®­ç»ƒæ•°æ® $D = \{\mathbf X_i,y_i\}^N_{i=1}$ å­¦ä¹ æ˜ å°„</li><li>é¢„æµ‹ï¼šå¯¹æ–°çš„æµ‹è¯•æ•°æ®xè¿›è¡Œé¢„æµ‹ï¼š$\hat f = f(x)$ yå¸¦å¸½è¡¨ç¤ºé¢„æµ‹</li><li>å­¦ä¹ ç›®æ ‡ï¼šè®­ç»ƒé›†ä¸Šé¢„æµ‹å€¼ä¸çœŸå€¼ä¹‹é—´çš„å·®å¼‚æœ€å°<ul><li>æŸå¤±å‡½æ•°ï¼šåº¦é‡æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå€¼ä¹‹é—´çš„å·®å¼‚ï¼Œå¦‚<script type="math/tex; mode=display">L(f(\mathbf x),y) = \frac 12(f(x) - y)^2</script></li><li>ç›®æ ‡å‡½æ•°ä¸ºï¼š$J(\mathbf \theta) = \frac1N \sum_{i = 1}^N L(f(\mathbf x_i|\mathbf \theta), y_i)$</li></ul></li></ul></li><li>åˆ†ç±»<br>   è‹¥è¾“å‡ºyä¸ºç¦»æ•£å€¼ï¼Œåˆ™æˆ‘ä»¬ç§°ä¹‹ä¸ºä¸€ä¸ªåˆ†ç±»ï¼Œæ ‡ç­¾ç©ºé—´y = {1,2, â€¦ C}<br>   ä¾‹ï¼šä¿¡ç”¨è¯„åˆ†<ul><li>åˆ†ç±»ï¼š å­¦ä¹ ä»è¾“å…¥xåˆ°è¾“å‡ºyçš„æ˜ å°„f:æ¦‚ç‡é—®é¢˜<br>$\hat y = f(\mathbf x) = \underset{c}  {arg\ max} \ p(y = c\mid \mathbf x, D)$</li><li>å­¦ä¹ ç›®æ ‡ï¼š<ul><li>æŸå¤±å‡½æ•°ï¼š01æŸå¤± <script type="math/tex; mode=display">l_{0/1}(y, \hat y) = \begin {cases} 0 & y = \hat y \\ 1 & otherwise \end{cases}</script></li></ul></li><li>éœ€è¦é¢„æµ‹çš„æ¦‚ç‡ï¼š</li><li>é¢„æµ‹ï¼šæœ€å¤§åéªŒä¼°è®¡ï¼ˆMaximum a Posteriori, MAPï¼‰<br>$\hat y = f(\mathbf x) = \underset{c} {arg\ max}\ p(y = c\mid \mathbf x, D)$</li></ul></li><li>æ’åºï¼ˆRankï¼‰<br>  æ’åºå­¦ä¹ æ˜¯æ¨èã€æœç´ ã€å¹¿å‘Šçš„æ ¸å¿ƒæ–¹æ³•<br>  æ’åºå­¦ä¹ ä¸­éœ€è¦é¦–å…ˆæ ¹æ®æŸ¥è¯¢qåŠå…¶æ–‡æ¡£é›†åˆè¿›è¡Œæ ‡æ³¨ï¼ˆdata labelingï¼‰ å’Œæå–ç‰¹å¾ï¼ˆfeature extractionï¼‰ æ‰èƒ½å¾—åˆ°D = {â€¦.}</li></ul></li><li>éç›‘ç£å­¦ä¹ <br>  å‘ç°æ•°æ®ä¸­çš„â€œæœ‰æ„ä¹‰çš„æ¨¡å¼â€ï¼Œ äº¦è¢«ç§°ä¸ºçŸ¥è¯†å‘ç°<br>  è®­ç»ƒæ•°æ®ä¸åŒ…å«æ ‡ç­¾<br>  æ ‡ç­¾åœ¨è®­ç»ƒæ•°æ®ä¸­ä¸ºéšå«å˜é‡<br>  $ D = \{ \bf X_i\}_{ i= 1}^ N $<ul><li>èšç±»<br>ä¾‹ï¼šäººçš„â€œç±»å‹â€<br>åˆ†å¤šå°‘ç±»ï¼Ÿ æ¨¡å‹é€‰æ‹©<br>$ K^* = arg\ max _K\ p(K \mid D)$<br>æŸä¸ªæ ·æœ¬å±äºå“ªä¸ªç±»ï¼Ÿ</li><li>é™ç»´<br>å¤šç»´ç‰¹å¾ï¼Œæœ‰äº›ç‰¹å¾ä¹‹é—´ä¼šç›¸å…³è€Œå­˜åœ¨å†—ä½™<br>å¾ˆå¤šç®—æ³•ä¸­ï¼Œé™ç»´ç®—æ³•æˆä¸ºäº†æ•°æ®é¢„å¤„ç†çš„ä¸€éƒ¨åˆ†ï¼Œ å¦‚ä¸»æˆåˆ†åˆ†æï¼ˆPrincipal Components Analysis, PCAï¼‰</li></ul></li><li>åŠç›‘ç£å­¦ä¹ <br>  å½“æ ‡æ³¨æ•°æ®â€œæ˜‚è´µâ€æ—¶æœ‰ç”¨<br>  ä¾‹ï¼šæ ‡æ³¨3Då§¿æ€ã€ è›‹ç™½è´¨åŠŸèƒ½ç­‰ç­‰</li><li>å¤šæ ‡ç­¾å­¦ä¹ </li><li>æœ‰æ­§ä¹‰æ ‡ç­¾å­¦ä¹ </li><li>å¤šå®ä¾‹å­¦ä¹ </li><li>å¢å¼ºå­¦ä¹ <br>ä»è¡Œä¸ºçš„åé¦ˆ(å¥–åŠ±æˆ–æƒ©ç½š)ä¸­å­¦ä¹ <ul><li>è®¾è®¡ä¸€ä¸ªå›æŠ¥å‡½æ•°ï¼ˆreward functionï¼‰ï¼Œ å¦‚æœlearning agent(å¦‚æœºå™¨äººã€å›´æ£‹aiç¨‹åº)ï¼Œåœ¨å†³å®šä¸€æ­¥ä¹‹åï¼Œè·å¾—äº†è¾ƒå¥½çš„ç»“æœï¼Œé‚£ä¹ˆæˆ‘ä»¬ç»™agentä¸€äº›å›æŠ¥ï¼ˆæ¯”å¦‚å›æŠ¥å‡½æ•°ç»“æœä¸ºæ­£ï¼‰ï¼Œå¾—åˆ°è¾ƒå·®çš„ç»“æœï¼Œé‚£ä¹ˆå›æŠ¥å‡½æ•°ä¸ºè´Ÿ</li><li>å¢å¼ºå­¦ä¹ çš„ä»»åŠ¡ï¼šæ‰¾åˆ°ä¸€æ¡å›æŠ¥å€¼æœ€å¤§çš„è·¯å¾„</li></ul></li></ul><h5 id="1-3-ä¸€ä¸ªå…¸å‹çš„æœºå™¨å­¦ä¹ æ¡ˆä¾‹-å¯¹é±¼è¿›è¡Œåˆ†ç±»"><a href="#1-3-ä¸€ä¸ªå…¸å‹çš„æœºå™¨å­¦ä¹ æ¡ˆä¾‹-å¯¹é±¼è¿›è¡Œåˆ†ç±»" class="headerlink" title="1.3 ä¸€ä¸ªå…¸å‹çš„æœºå™¨å­¦ä¹ æ¡ˆä¾‹-å¯¹é±¼è¿›è¡Œåˆ†ç±»"></a>1.3 ä¸€ä¸ªå…¸å‹çš„æœºå™¨å­¦ä¹ æ¡ˆä¾‹-å¯¹é±¼è¿›è¡Œåˆ†ç±»</h5><ul><li>æ ¹æ®ä¸€äº›å…‰å­¦ä¼ æ„Ÿå™¨å¯¹ä¼ é€å¸¦ä¸Šçš„é±¼è¿›è¡Œåˆ†ç±»</li><li>å½¢å¼åŒ–ä¸ºæœºå™¨å­¦ä¹ é—®é¢˜<ul><li>è®­ç»ƒæ•°æ®<ul><li>æ¯æ¡é±¼çš„æµ‹é‡å‘é‡</li><li>æ¯æ¡é±¼çš„æ ‡ç­¾</li></ul></li><li>æµ‹è¯•<ul><li>ç»™å®šä¸€ä¸ªæ–°çš„ç‰¹å¾å‘é‡x</li><li>é¢„æµ‹å¯¹åº”çš„æ ‡ç­¾y </li></ul></li><li>å°†é•¿åº¦ä½œä¸ºç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼ˆç›´æ–¹å›¾ï¼‰<ul><li>éœ€è¦å…ˆåšä¸€ä¸ªå†³ç­–è¾¹ç•Œ<ul><li>æœ€å°åŒ–å¹³å‡æŸå¤±</li></ul></li></ul></li><li>å°†äº®åº¦ä½œä¸ºç‰¹å¾è¿›è¡Œåˆ†ç±» ï¼ˆç›´æ–¹å›¾ï¼‰</li><li>å°†é•¿åº¦å’Œäº®åº¦ä¸€èµ·ä½œä¸ºç‰¹å¾ï¼ˆäºŒç»´æ•£ç‚¹å›¾ï¼‰<ul><li>çº¿æ€§å†³ç­–å‡½æ•°</li><li>äºŒæ¬¡å†³ç­–å‡½æ•°</li><li>æ›´å¤æ‚çš„å†³ç­–è¾¹ç•Œ<br>è®­ç»ƒé›†ä¸Šçš„è¯¯å·® â‰  æµ‹è¯•é›†ä¸Šçš„è¯¯å·®<br>æ•°æ®è¿‡æ‹Ÿåˆï¼ˆoverfittingï¼‰<br>æ¨å¹¿æ€§ï¼ˆgeneralizationï¼‰å·®</li></ul></li></ul></li><li>å°ç»“ï¼šè®¾è®¡ä¸€ä¸ªé±¼çš„åˆ†ç±»å™¨<ul><li>é€‰æ‹©ç‰¹å¾<ul><li>å¯èƒ½æ˜¯æœ€é‡è¦çš„æ­¥éª¤ï¼ï¼ˆæ”¶é›†è®­ç»ƒæ•°æ®ï¼‰</li></ul></li><li>é€‰æ‹©æ¨¡å‹ï¼ˆå¦‚å†³ç­–è¾¹ç•Œçš„å½¢çŠ¶ï¼‰</li><li>æ ¹æ®è®­ç»ƒæ•°æ®ä¼°è®¡æ¨¡å‹</li><li>åˆ©ç”¨æ¨¡å‹å¯¹æ–°æ ·æœ¬è¿›è¡Œåˆ†ç±»</li></ul></li></ul><h5 id="1-4-æœºå™¨å­¦ä¹ ç®—æ³•çš„ç»„æˆéƒ¨åˆ†"><a href="#1-4-æœºå™¨å­¦ä¹ ç®—æ³•çš„ç»„æˆéƒ¨åˆ†" class="headerlink" title="1.4 æœºå™¨å­¦ä¹ ç®—æ³•çš„ç»„æˆéƒ¨åˆ†"></a>1.4 æœºå™¨å­¦ä¹ ç®—æ³•çš„ç»„æˆéƒ¨åˆ†</h5><ul><li>æœºå™¨å­¦ä¹ ä»»åŠ¡çš„ä¸€èˆ¬æ­¥éª¤<ul><li>ç¡®å®šç‰¹å¾<ul><li>å¯èƒ½æ˜¯æœ€é‡è¦çš„æ­¥éª¤ï¼ï¼ˆæ”¶é›†è®­ç»ƒæ•°æ®ï¼‰</li></ul></li><li>ç¡®å®šæ¨¡å‹<ul><li>ç›®æ ‡å‡½æ•°/å†³ç­–è¾¹ç•Œå½¢çŠ¶</li></ul></li><li>æ¨¡å‹è®­ç»ƒï¼šæ ¹æ®è®­ç»ƒæ•°æ®ä¼°è®¡æ¨¡å‹å‚æ•°<ul><li>ä¼˜åŒ–è®¡ç®—</li></ul></li><li>æ¨¡å‹è¯„ä¼°ï¼šåœ¨æ ¡éªŒé›†ä¸Šè¯„ä¼°æ¨¡å‹é¢„æµ‹æ€§èƒ½</li><li>æ¨¡å‹åº”ç”¨/é¢„æµ‹ </li></ul></li><li>æ¨¡å‹<ul><li>ç›‘ç£å­¦ä¹ ä»»åŠ¡ï¼š$D = \{X_i, y_i\} _{i = 1} ^ N $</li><li>æ¨¡å‹ï¼šå¯¹ç»™å®šçš„è¾“å…¥x, å¦‚ä½•é¢„æµ‹å…¶æ ‡ç­¾$ \hat y$<ul><li>ä¸åŒæ¨¡å‹å¯¹æ•°æ®çš„å‡è®¾ä¸åŒ</li><li>æœ€ç®€å•çš„æ¨¡å‹ï¼šçº¿æ€§æ¨¡å‹$ f(x) = \sum_j w_j x_j = \bf w^T \bf x$</li></ul></li><li>ç¡®å®šæ¨¡å‹ç±»åˆ«åï¼Œæ¨¡å‹è®­ç»ƒè½¬åŒ–ä¸ºæ±‚è§£æ¨¡å‹å‚æ•°<ul><li>å¦‚å¯¹çº¿æ€§æ¨¡å‹å‚æ•°ä¸º$\theta = \{w_j \mid j = 1,â€¦, D\}$,å…¶ä¸­Dä¸ºç‰¹å¾ç»´æ•°</li></ul></li><li>æ±‚è§£æ¨¡å‹å‚æ•°ï¼šç›®æ ‡å‡½æ•°æœ€å°åŒ–</li></ul></li><li>éçº¿æ€§æ¨¡å‹<ul><li>åŸºå‡½æ•°ï¼š $x^2$, log, exp, æ ·æ¡å‡½æ•°ï¼Œå†³ç­–æ ‘â€¦.</li><li>æ ¸åŒ–ï¼šå°†åŸé—®é¢˜è½¬åŒ–ä¸ºå¯¹å¶é—®é¢˜ï¼Œå°†å¯¹å¶é—®é¢˜ä¸­çš„å‘é‡ç§¯$\langle x_i, x_j\rangle$ æ¢æˆæ ¸å‡½æ•°$k(x_i,x_j)$</li></ul></li><li>ç›®æ ‡å‡½æ•°ï¼šé€šå¸¸åŒ…å«ä¸¤é¡¹ï¼šæŸå¤±å‡½æ•°å’Œæ­£åˆ™é¡¹<script type="math/tex; mode=display">J(\theta) = \frac 1N \sum_{i=1}^N\ L(f(x_i; \theta), y_i) + R(\theta)</script><ul><li>æŸå¤±å‡½æ•°<ul><li>æŸå¤±å‡½æ•° - å›å½’<ul><li>æŸå¤±å‡½æ•°ï¼šåº¦é‡æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå€¼ä¹‹é—´çš„å·®å¼‚</li><li>å¯¹å›å½’é—®é¢˜ï¼šä»¤æ®‹å·® $r = f(\bf x) - y$<ul><li>L2æŸå¤±ï¼šè¿ç»­ï¼Œä½†å¯¹å™ªå£°æ•æ„Ÿ<script type="math/tex; mode=display">L_2 (r) = \frac 12 r ^2</script></li><li>L1æŸå¤±ï¼šä¸è¿ç»­ï¼Œå¯¹å™ªå£°ä¸æ•æ„Ÿ<script type="math/tex; mode=display">L_1(r) = |r|</script></li><li>Huber æŸå¤±ï¼š è¿ç»­ï¼Œå¯¹å™ªå£°ä¸æ•æ„Ÿ<script type="math/tex; mode=display">L_\delta (r) = \begin{cases}  \frac 12 r^2 & if|r| \le \delta\\ \delta |r| - \frac 12 \delta^2 & if|r| \ge \delta\end{cases}</script></li></ul></li></ul></li><li>æŸå¤±å‡½æ•° - åˆ†ç±»<ul><li>æŸå¤±å‡½æ•°ï¼šåº¦é‡æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå€¼ä¹‹é—´çš„å·®å¼‚</li><li>å¯¹åˆ†ç±»é—®é¢˜<ul><li>0-1æŸå¤±ï¼š$l_{0/1}(y,f(x)) = \begin{cases} 1 &amp; yf(x) \lt 0 \\ 0 &amp; othereise\end{cases}$</li><li>logisticæŸå¤±ï¼šäº¦ç§°è´Ÿlogä¼¼ç„¶æŸå¤±<br>  $l_{log}(y,f(x)) = log(1 + exp(-yf(x)))$</li><li>æŒ‡æ•°æŸå¤±ï¼š$l_{exp}(y,f(x)) = exp(-yf(x))$</li><li>åˆé¡µæŸå¤±ï¼š$l_{hinge}(y,f(x)) = max(0, 1 - yf(x))$</li></ul></li></ul></li></ul></li><li>æ­£åˆ™é¡¹<br>  å¤æ‚æ¨¡å‹ï¼ˆé¢„æµ‹ï¼‰ä¸ç¨³å®šï¼šæ–¹å·®å¤§<br>  æ­£åˆ™é¡¹å¯¹å¤æ‚æ¨¡å‹æ–½åŠ æƒ©ç½š<ul><li>æ­£åˆ™é¡¹çš„å¿…è¦æ€§<br>ä¾‹ï¼šsinæ›²çº¿æ‹Ÿåˆ</li><li>å¢åŠ L2æ­£åˆ™<br>å²­å›å½’ï¼šæœ€å°åŒ–RSS</li><li>æ¬ æ‹Ÿåˆï¼šæ¨¡å‹å¤ªç®€å•/å¯¹å¤æ‚æ€§æƒ©ç½šå¤ªå¤š</li><li>æ ·æœ¬æ•°ç›®å¢å¤šæ—¶ï¼Œå¯ä»¥è€ƒè™‘æ›´å¤æ‚çš„æ¨¡å‹</li><li>å¸¸è§æ­£åˆ™é¡¹<ul><li>L2æ­£åˆ™: $R(\theta) = \lambda ||\theta||^2_2 = \lambda \sum^D_{j=1} \theta_j^2$</li><li>L1æ­£åˆ™: $R(\theta) = \lambda |\theta| = \lambda \sum ^D_{j=1}|\theta_j|$</li><li>L0æ­£åˆ™: $R(\theta) = \lambda||\theta||_ 0$<ul><li>é0å‚æ•°çš„æ•°ç›®</li><li>ä¸å¥½ä¼˜åŒ–ï¼Œé€šå¸¸ç”¨L1æ­£åˆ™è¿‘ä¼¼</li></ul></li></ul></li><li>å¸¸è§çº¿æ€§æ¨¡å‹çš„æŸå¤±å’Œæ­£åˆ™é¡¹ç»„åˆ</li></ul></li></ul></li></ul><div class="table-container"><table><thead><tr><th></th><th>L2æŸå¤±</th><th>L1æŸå¤±</th><th>HuberæŸå¤±</th><th>LogisticæŸå¤±</th><th>åˆé¡µæŸå¤±</th><th>e-insensitiveæŸå¤±</th></tr></thead><tbody><tr><td>L2æ­£åˆ™</td><td>å²­å›å½’</td><td></td><td></td><td>L2æ­£åˆ™ Logisticå›å½’</td><td>SVM</td><td>SVR</td></tr><tr><td>L1æ­£åˆ™</td><td>LASSO</td><td></td><td></td><td>L1æ­£åˆ™ Logisticå›å½’</td><td></td><td></td></tr><tr><td>L2+L1æ­£åˆ™</td><td>Elastic</td><td></td><td></td><td></td><td></td></tr></tbody></table></div><ul><li>æ¨¡å‹è®­ç»ƒ<ul><li>åœ¨è®­ç»ƒæ•°æ®ä¸Šæ±‚ç›®æ ‡å‡½æ•°æå°å€¼ï¼šä¼˜åŒ–</li><li>ç®€å•ç›®æ ‡å‡½æ•°ç›´æ¥æ±‚è§£<ul><li>å¦‚å°æ•°æ®é›†ä¸Šçš„çº¿æ€§å›å½’</li></ul></li><li>æ›´å¤æ‚é—®é¢˜ï¼šå‡¸ä¼˜åŒ–<ul><li>ï¼ˆéšæœºï¼‰æ¢¯åº¦ä¸‹é™</li><li>ç‰›é¡¿æ³•/æ‹Ÿç‰›é¡¿æ³•</li><li>â€¦ </li></ul></li></ul></li><li>æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰ç®—æ³•<ul><li>æ¢¯åº¦ä¸‹é™/æœ€é€Ÿä¸‹é™ç®—æ³•ï¼šå¿«é€Ÿå¯»æ‰¾å‡½æ•°å±€éƒ¨æå°å€¼</li><li>æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼šæ±‚å‡½æ•°Jï¼ˆÎ¸ï¼‰çš„æœ€å°å€¼<ul><li>ç»™å®šåˆå§‹å€¼$Î¸^0$</li><li>æ›´æ–°Î¸ï¼Œä½¿å¾—Jï¼ˆÎ¸ï¼‰è¶Šæ¥è¶Šå°<ul><li>$Î¸^t = Î¸^{t-1} - \eta\nabla J(Î¸)$ ( $\eta$ : å­¦ä¹ ç‡ )</li></ul></li><li>ç›´åˆ°æ”¶æ•›åˆ° / è¾¾åˆ°é¢„å…ˆè®¾å®šçš„æœ€å¤§è¿­ä»£æ¬¡æ•°</li><li>ä¸‹é™çš„æ­¥ä¼å¤ªå°ï¼ˆå­¦ä¹ ç‡ï¼‰éå¸¸é‡è¦ï¼šå¦‚æœå¤ªå°ï¼Œæ”¶æ•›é€Ÿåº¦æ…¢ï¼› å¦‚æœå¤ªå¤§ï¼Œå¯èƒ½ä¼šå‡ºç°overshoot the minimumçš„ç°è±¡</li><li>æ¢¯åº¦ä¸‹é™æ±‚å¾—çš„åªæ˜¯å±€éƒ¨æœ€å°å€¼<ul><li>äºŒé˜¶å¯¼æ•° &gt; 0, åˆ™ç›®æ ‡å‡½æ•°ä¸ºå‡¸å‡½æ•°ï¼Œå±€éƒ¨æå°å€¼å³ä¸ºå…¨å±€æœ€å°å€¼</li><li>éšæœºé€‰æ‹©å¤šä¸ªåˆå§‹å€¼ï¼Œå¾—åˆ°å‡½æ•°çš„å¤šä¸ªå±€éƒ¨æå°å€¼ç‚¹ã€‚å¤šä¸ªå±€éƒ¨æå°å€¼ç‚¹çš„æœ€å°å€¼ä¸ºå‡½æ•°çš„å…¨å±€æœ€å°å€¼</li></ul></li><li>æ¢¯åº¦ä¸‹é™ç®—æ³•æ¯æ¬¡å­¦ä¹ éƒ½ä½¿ç”¨æ•´ä¸ªè®­ç»ƒé›†ï¼Œè¿™æ ·å¯¹å¤§çš„è®­ç»ƒæ•°æ®é›†åˆï¼Œæ¯æ¬¡å­¦ä¹ æ—¶é—´è¿‡é•¿ï¼Œå¯¹å¤§çš„è®­ç»ƒé›†éœ€è¦æ¶ˆè€—å¤§é‡çš„å†…å­˜ã€‚æ­¤æ—¶å¯é‡‡ç”¨éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆStochastic gradient descent, SGD), æ¯æ¬¡ä»è®­ç»ƒé›†ä¸­éšæœºé€‰æ‹©ä¸€éƒ¨åˆ†æ ·æœ¬è¿›è¡Œå­¦ä¹ ã€‚</li><li>æ›´å¤šï¼ˆéšæœºï¼‰æ¢¯åº¦ä¸‹é™ç®—æ³•çš„æ”¹è¿›ç‰ˆ<ul><li>åŠ¨é‡ï¼ˆMomentumï¼‰</li><li>Nesterov accelerated gradient (NAG)</li><li>Adagrad</li><li>RMSprop</li><li>Adaptive Moment Estimation (Adam)â€¦</li></ul></li></ul></li></ul></li><li>æ¨¡å‹é€‰æ‹©ä¸æ¨¡å‹è¯„ä¼°<ul><li>åŒä¸€ä¸ªé—®é¢˜æœ‰ä¸åŒçš„è§£å†³æ–¹æ¡ˆ<br>  å¦‚çº¿æ€§å›å½’ vs. å†³ç­–æ ‘</li><li>å“ªä¸ªæ›´å¥½ï¼Ÿ æ¨¡å‹è¯„ä¼°ä¸æ¨¡å‹é€‰æ‹©<ul><li>åœ¨æ–°æ•°æ®ç‚¹çš„é¢„æµ‹è¯¯å·®æœ€å°</li></ul></li><li>æ¨¡å‹è¯„ä¼°ï¼šå·²ç»é€‰å®šæœ€ç»ˆçš„æ¨¡å‹ï¼Œä¼°è®¡å®ƒåœ¨æ–°æ•°æ®ä¸Šçš„é¢„æµ‹è¯¯å·®</li><li>æ¨¡å‹é€‰æ‹©ï¼šä¼°è®¡ä¸åŒæ¨¡å‹çš„æ€§èƒ½ï¼Œé€‰å‡ºæœ€å¥½çš„æ¨¡å‹</li></ul></li><li>æ ·æœ¬è¶³å¤Ÿå¤šï¼šè®­ç»ƒé›†å’Œæ ¡éªŒé›†</li><li>æ ·æœ¬ä¸å¤Ÿå¤šï¼šé‡é‡‡æ ·æŠ€æœ¯æ¥æ¨¡æ‹Ÿæ ¡éªŒé›†ï¼šäº¤å‰éªŒè¯å’Œbootstrap<ul><li>K-æŠ˜äº¤å‰éªŒè¯<ul><li>äº¤å‰éªŒè¯ï¼ˆCross Validation, CVï¼‰ï¼š å°†è®­ç»ƒæ•°æ®åˆ†æˆå®¹é‡å¤§è‡´ç›¸ç­‰çš„Kä»½ï¼ˆé€šå¸¸K = 5/10ï¼‰</li><li>äº¤å‰éªŒè¯ä¼°è®¡çš„è¯¯å·®ä¸ºï¼š<script type="math/tex; mode=display">CV(M)= \frac1K \sum  ^K_{k = 1} E_k(M)</script></li></ul></li></ul></li><li>æ¨¡å‹é€‰æ‹©<ul><li>å¯¹å¤šä¸ªä¸åŒæ¨¡å‹ï¼Œè®¡ç®—å…¶å¯¹åº”çš„è¯¯å·®CVï¼ˆMï¼‰ï¼Œ æœ€ä½³æ¨¡å‹ä¸ºCVï¼ˆMï¼‰æœ€å°çš„æ¨¡å‹</li><li>æ¨¡å‹å¤æ‚åº¦å’Œæ³›åŒ–è¯¯å·®çš„å…³ç³»é€šå¸¸æ˜¯Uå½¢æ›²çº¿ï¼š</li></ul></li></ul><h5 id="1-5-å­¦ä¹ ç¯å¢ƒç®€ä»‹"><a href="#1-5-å­¦ä¹ ç¯å¢ƒç®€ä»‹" class="headerlink" title="1.5 å­¦ä¹ ç¯å¢ƒç®€ä»‹"></a>1.5 å­¦ä¹ ç¯å¢ƒç®€ä»‹</h5><ul><li>ç¼–ç¨‹è¯­è¨€ Python</li><li>æ•°æ®å¤„ç†å·¥å…·åŒ…<ul><li>Numpy</li><li>SciPy</li><li>pandas</li></ul></li><li>æ•°æ®å¯è§†åŒ–å·¥å…·åŒ…<ul><li>Matplotlib</li><li>Seaborn</li></ul></li><li>æœºå™¨å­¦ä¹ å·¥å…·åŒ…<ul><li>scikit learn</li></ul></li><li>ç¤ºä¾‹ä»£ç ï¼šINotebook </li><li>NumPy<ul><li>NumPy(Numeric Python)æ˜¯Pythonçš„å¼€æºæ•°å€¼è®¡ç®—æ‰©å±•ï¼Œå¯ç”¨æ¥å­˜å‚¨å’Œå¤„ç†å¤§å‹çŸ©é˜µ</li><li>NumpyåŒ…æ‹¬ï¼š<ul><li>Nç»´æ•°ç»„(ndarray)</li><li>å®ç”¨çš„çº¿æ€§ä»£æ•°ã€å‚…é‡Œå¶å˜æ¢å’Œéšæœºæ•°ç”Ÿæˆå‡½æ•°</li></ul></li><li>Numpyå’Œç¨€ç–çŸ©é˜µè¿ç®—åŒ…SciPyé…åˆä½¿ç”¨æ›´åŠ æ–¹ä¾¿</li></ul></li><li>SciPy<ul><li>SciPyæ˜¯å»ºç«‹åœ¨NumPyçš„åŸºç¡€ä¸Šã€æ˜¯ç§‘å­¦å’Œå·¥ç¨‹è®¾è®¡çš„Pythonå·¥å…·åŒ…ï¼Œæä¾›ç»Ÿè®¡ã€ä¼˜åŒ–å’Œæ•°å€¼å¾®ç§¯åˆ†è®¡ç®—ç­‰åŠŸèƒ½</li><li>NumPy å¤„ç†$10^6$çº§åˆ«çš„æ•°æ®é€šå¸¸æ²¡æœ‰å¤§é—®é¢˜ï¼Œä½†å½“æ•°æ®é‡è¾¾åˆ°$10^7$çº§åˆ«æ—¶é€Ÿåº¦å¼€å§‹å‘æ…¢ï¼Œå†…å­˜å—åˆ°é™åˆ¶ï¼ˆå…·ä½“æƒ…å†µå–å†³äºå®é™…å†…å­˜çš„å¤§å°ï¼‰</li><li>å½“å¤„ç†è¶…å¤§è§„æ¨¡æ•°æ®é›†ï¼Œæ¯”å¦‚$10^{10}$çº§åˆ«ï¼Œä¸”æ•°æ®ä¸­åŒ…å«å¤§é‡çš„0æ—¶ï¼Œå¯é‡‡ç”¨ç¨€ç–çŸ©é˜µå¯æ˜¾è‘—çš„æé«˜é€Ÿåº¦å’Œæ•ˆç‡</li></ul></li><li>Pandas(<strong>Pan</strong>del <strong>da</strong>ta structures)<ul><li>Pandasæ˜¯Pythonè¯­è¨€çš„â€œå…³ç³»å‹æ•°æ®åº“â€æ•°æ®ç»“æ„å’Œæ•°æ®åˆ†æå·¥å…·ï¼Œéå¸¸é«˜æ•ˆä¸”æ˜“äºä½¿ç”¨<ul><li>åŸºäºNumPyè¡¥å……äº†å¤§é‡æ•°æ®æ“ä½œåŠŸèƒ½ï¼Œèƒ½å®ç°ç»Ÿè®¡ã€åˆ†ç»„ã€æ’åºã€é€è§†è¡¨(SQLè¯­å¥çš„å¤§éƒ¨åˆ†åŠŸèƒ½)</li><li>Pandasä¸»è¦æœ‰2ç§é‡è¦çš„æ•°æ®ç±»å‹<ul><li>seriesï¼šä¸€ç»´åºåˆ—</li><li>DataFrameï¼šäºŒç»´è¡¨(æœºå™¨å­¦ä¹ æ•°æ®çš„å¸¸ç”¨æ•°æ®ç»“æ„)</li></ul></li></ul></li></ul></li><li>Matplotlib<ul><li>Matplotlibæ˜¯Pythonè¯­è¨€çš„2Då›¾å½¢ç»˜åˆ¶å·¥å…·</li></ul></li><li>Seaborn<ul><li>Seabornæ˜¯ä¸€ä¸ªåŸºäºMatplotlibçš„Pythonå¯è§†åŒ–å·¥å…·åŒ…ï¼Œæä¾›æ›´é«˜å±‚æ¬¡çš„ç”¨æˆ·æ¥å£ï¼Œå¯ä»¥ç»™å‡ºæ¼‚äº®çš„æ•°æ®ç»Ÿè®¡</li></ul></li><li>Scikit - Learn<ul><li>Machine Learning in Python</li><li>Scikit-Learnæ˜¯åŸºäºPythonçš„å¼€æºæœºå™¨å­¦ä¹ æ¨¡å—ï¼Œæœ€æ—©äº2007å¹´ç”±David Cournapeauå‘èµ·</li><li>åŸºæœ¬åŠŸèƒ½æœ‰å…­éƒ¨åˆ†ï¼šåˆ†ç±»ï¼ˆClassificationï¼‰ï¼Œå›å½’ï¼ˆRegressionï¼‰ï¼Œèšç±»ï¼ˆClusteringï¼‰ï¼Œæ•°æ®é™ç»´ï¼ˆDimensionality reductionï¼‰ï¼Œæ¨¡å‹é€‰æ‹©ï¼ˆModel Selectionï¼‰ï¼Œæ•°æ®é¢„å¤„ç†ï¼ˆPreprocessingï¼‰</li><li>å¯¹äºå…·ä½“çš„æœºå™¨å­¦ä¹ é—®é¢˜ï¼Œé€šå¸¸å¯ä»¥åˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤<ul><li>æ•°æ®å‡†å¤‡ä¸é¢„å¤„ç†ï¼ˆPreprocessing, Dimensionality reductionï¼‰</li><li>æ¨¡å‹é€‰æ‹©ä¸è®­ç»ƒï¼ˆClassification, Regression, Clusteringï¼‰</li><li>æ¨¡å‹éªŒè¯ä¸å‚æ•°è°ƒä¼˜ï¼ˆModel Selectionï¼‰</li></ul></li></ul></li><li>å„ç§æœºå™¨å­¦ä¹ æ¨¡å‹æœ‰ç»Ÿä¸€çš„æ¥å£</li><li>æ¨¡å‹æ—¢æœ‰é»˜è®¤å‚æ•°ï¼Œä¹Ÿæä¾›å¤šç§å‚æ•°è°ƒä¼˜æ–¹æ³•</li><li>å“è¶Šçš„æ–‡æ¡£</li><li>ä¸°å¯Œçš„éšé™„ä»»åŠ¡åŠŸèƒ½é›†åˆ</li><li>æ´»è·ƒçš„ç¤¾åŒºæä¾›å¼€å‘å’Œæ”¯æŒ</li></ul><h5 id="1-6-çº¿æ€§å›å½’æ¨¡å‹"><a href="#1-6-çº¿æ€§å›å½’æ¨¡å‹" class="headerlink" title="1.6 çº¿æ€§å›å½’æ¨¡å‹"></a>1.6 çº¿æ€§å›å½’æ¨¡å‹</h5><ul><li>ç›®æ ‡å‡½æ•°é€šå¸¸åŒ…å«ä¸¤é¡¹ï¼šæŸå¤±å‡½æ•°å’Œæ­£åˆ™é¡¹<script type="math/tex; mode=display">J(\bf \theta) = \frac1N \sum_{i = 1}^N L(f(\bf x_i|\bf \theta), y_i) + \lambda R(\bf \theta)</script></li><li>å¯¹å›å½’é—®é¢˜ï¼ŒæŸå¤±å‡½æ•°å¯ä»¥é‡‡ç”¨L2æŸå¤±ï¼Œå¾—åˆ°<script type="math/tex; mode=display">\begin{eqnarray}J(\theta)    &=&\sum_{i=1}^NL(y_i,\hat y_i) \\   &=&\sum_{i=1}^N(y_i - \hat y_i)^2\\   &=&\sum_{i=1}^N(y_i - \bf w^T \bf x_i)^2  \end{eqnarray}</script>  æ®‹å·®å¹³æ–¹å’Œï¼ˆresidual sum of squares, RSSï¼‰</li><li>ç”±äºçº¿æ€§æ¨¡å‹æ¯”è¾ƒç®€å•ï¼Œå®é™…åº”ç”¨ä¸­æœ‰æ—¶æ­£åˆ™é¡¹ä¸ºç©ºï¼Œå¾—åˆ°æœ€å°äºŒä¹˜çº¿æ€§å›å½’ï¼ˆOrdinary Least Square, OLSï¼‰<script type="math/tex; mode=display">\begin{eqnarray}J(\theta)   &=&\sum_{i=1}^NL(y_i,\hat y_i)   &=&\sum_{i=1}^N(y_i - \hat y_i)^2\\  &=&\sum_{i=1}^N(y_i - \bf w^T \bf x_i)^2  \end{eqnarray}</script></li><li>æ­£åˆ™é¡¹å¯ä»¥ä¸ºL2æ­£åˆ™ï¼Œå¾—åˆ°å²­å›å½’ï¼ˆRidge Regressionï¼‰<script type="math/tex; mode=display">J(\bf w) = \sum_{i=1}^N(y_i - \bf w^Tx_i)^2 + \lambda ||w||^2_2</script></li><li><p>æ­£åˆ™é¡¹ä¹Ÿå¯ä»¥é€‰L1æ­£åˆ™ï¼Œå¾—åˆ°Lassoæ¨¡å‹ï¼š</p><script type="math/tex; mode=display">J(\bf w) = \sum_{i=1}^N(y_i - \bf w^Tx_i)^2 + \lambda |w|</script><ul><li>å½“$\lambda$å–åˆé€‚å€¼æ—¶ï¼ŒLassoï¼ˆLeast absolute shrinkage and selection operatorï¼‰çš„ç»“æœæ˜¯ç¨€ç–çš„ï¼ˆwçš„æŸäº›å…ƒç´ ç³»æ•°ä¸º0ï¼‰ï¼Œèµ·åˆ°ç‰¹å¾é€‰æ‹©ä½œç”¨</li></ul></li><li><p>ä¸ºä»€ä¹ˆL1æ­£åˆ™çš„è§£æ˜¯ç¨€ç–çš„ï¼Ÿ</p></li><li>çº¿æ€§å›å½’æ¨¡å‹çš„æ¦‚ç‡è§£é‡Š<ul><li>æœ€å°äºŒä¹˜ï¼ˆçº¿æ€§ï¼‰å›å½’ç­‰ä»·äºæå¤§ä¼¼ç„¶ä¼°è®¡<ul><li>å‡è®¾ï¼š$ y = f(\bf x) + \epsilon = w^Tx + \epsilon $<br>å…¶ä¸­$\epsilon$ä¸ºçº¿æ€§é¢„æµ‹å’ŒçœŸå€¼ä¹‹é—´çš„æ®‹å·®<br>æˆ‘ä»¬é€šå¸¸å‡è®¾æ®‹å·®çš„åˆ†å¸ƒä¸º$\epsilon \sim N(0,\sigma ^2)$,å› æ­¤çº¿æ€§å›å½’å¯å†™æˆï¼š$p(y|x,\theta) \sim N(y| \bf w^T \bf x, \sigma^2)$,å…¶ä¸­$ \bf \theta = (\bf w, \sigma ^2)$</li></ul></li><li>æ­£åˆ™ï¼ˆçº¿æ€§ï¼‰å›å½’ç­‰ä»·äºé«˜æ–¯å…ˆéªŒï¼ˆL2æ­£åˆ™ï¼‰æˆ–Laplaceå…ˆéªŒä¸‹ï¼ˆL1æ­£åˆ™ï¼‰çš„è´å¶æ–¯ä¼°è®¡</li></ul></li><li>Recallï¼šæå¤§ä¼¼ç„¶ä¼°è®¡<ul><li>æå¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMaximize Likelihood Estimator, MLEï¼‰å®šä¹‰ä¸º<script type="math/tex; mode=display">\hat \theta = \underset {\theta}  {arg\ max}\ log\ p(D\mid \theta)</script></li><li>å…¶ä¸­ï¼ˆlogï¼‰ä¼¼ç„¶å‡½æ•°ä¸º<script type="math/tex; mode=display">l(\bf \theta) = log\ p(D\mid \bf \theta) = \sum_{i=1}^N log\ p(y_i \mid x_i, \bf \theta)</script></li><li>è¡¨ç¤ºåœ¨å‚æ•°ä¸º$\theta$çš„æƒ…å†µä¸‹ï¼Œæ•°æ®$D ={\bf x_i,y_i}^N_{i=1}$</li><li>æå¤§ä¼¼ç„¶ï¼šé€‰æ‹©æ•°æ®å‡ºç°æ¦‚ç‡æœ€å¤§çš„å‚æ•°</li></ul></li><li>çº¿æ€§å›å½’çš„MLE<script type="math/tex; mode=display">p(y_i|x_i,\bf w,\sigma ^2) \sim N(y_i\mid \bf w^T \bf x_i, \sigma^2) = \frac 1{\sqrt{2\pi}\sigma} exp(-\frac 1{2 \sigma ^2}((y_i - \bf w^T \bf x_i)^2))</script><ul><li>OLSçš„ä¼¼ç„¶å‡½æ•°ä¸º<script type="math/tex; mode=display">l(\bf \theta) = log\ p(D\mid \bf \theta) = \sum_{i=1}^N log\ p(y_i \mid x_i, \bf \theta)</script></li><li>æå¤§ä¼¼ç„¶å¯ç­‰ä»·åœ°å†™æˆæå°è´Ÿlogä¼¼ç„¶æŸå¤±ï¼ˆnegative log likelihood, NLLï¼‰</li></ul></li></ul><script type="math/tex; mode=display">\begin{eqnarray}{NLL(\bf \theta)}    &=& \sum_{i=1}^N log\ p(y_i \mid x_i, \bf \theta) \\    &=& - \sum_{i=1}^N log ((\frac 1{2 \pi \sigma^2})^ \frac 12 exp(- \frac 1{2 \sigma ^2}((y_i - \bf w^T \bf x_i)^2))) \\    &=& \frac N2 log(2\pi \sigma ^2) + \frac 1{2 \sigma^2} \sum_{i=1}^N(y_i - \bf w^T \bf x_i)^2    \end{eqnarray}</script><ul><li>æ­£åˆ™å›å½’ç­‰ä»·äºè´å¶æ–¯ä¼°è®¡<ul><li>å‡è®¾æ®‹å·®çš„åˆ†å¸ƒä¸º$\epsilon \sim N(0, \sigma ^2)$,çº¿æ€§å›å½’å¯å†™æˆï¼š<br>$p(y_i \mid \bf x_i, \theta) \sim N(y_i \mid \bf w^T \bf x_iï¼Œ\sigma ^2)$<br>$p(y\mid \bf X, \bf w, \sigma ^2) = N(\bf y \mid \bf X \bf w, \sigma ^2 \bf I_N) \propto exp(- \frac 1{2\sigma ^2}((\bf y - \bf X \bf w)^T(\bf y - \bf X \bf w)))$</li><li>è‹¥å‡è®¾å‚æ•°ä¸ºwçš„å…ˆéªŒåˆ†å¸ƒä¸º $w_j \sim N(0, \tau ^2)$<ul><li>åå‘è¾ƒå°çš„ç³»æ•°å€¼ï¼Œä»è€Œå¾—åˆ°çš„æ›²çº¿ä¹Ÿæ¯”è¾ƒå¹³æ»‘<br>$p(\bf w) =\prod_{j=1}^{D} N(w_j \mid 0, \tau ^2) \propto exp(- \frac 1{2\tau^2} \sum_{j=1}^D \bf w_j^2 = exp(- \frac 1{2\tau^2} ( \bf w^T \bf w ) )) $</li><li>å…¶ä¸­$1/\tau ^2$æ§åˆ¶å…ˆéªŒçš„å¼ºåº¦</li></ul></li><li>æ ¹æ®è´å¶æ–¯å…¬å¼ï¼Œå¾—åˆ°å‚æ•°çš„åéªŒåˆ†å¸ƒä¸º<br>$p(y\mid \bf X, \bf w, \sigma ^2) = \propto exp(- \frac 1{2\sigma ^2} ((\bf y - \bf X \bf w)^T(\bf y - \bf X \bf w) ) - \frac 1{2 \tau^2} ( w^Tw ) )$</li><li>åˆ™æœ€å¤§åéªŒä¼°è®¡(MAP)ç­‰ä»·äºæœ€å°ç›®æ ‡å‡½æ•°<br>$J(\bf w) = (\bf y - \bf X\bf w)^T(\bf y - \bf X\bf w) + \frac {\sigma ^2}{\tau^2} \bf w^T \bf w $</li><li>å¯¹æ¯”å²­å›å½’çš„ç›®æ ‡å‡½æ•°<br>$J(\bf w) = \sum_{i=1}^N(y_i -\bf w^T\bf x_i)^2 + \lambda \Vert \bf w\Vert ^2_2$</li></ul></li><li>å°ç»“<ul><li>çº¿æ€§å›å½’æ¨¡å‹å¯ä»¥æ”¾åˆ°æœºå™¨å­¦ä¹ ä¸€èˆ¬æ¡†æ¶<ul><li>æŸå¤±å‡½æ•°ï¼šL2æŸå¤±ï¼Œâ€¦</li><li>æ­£åˆ™ï¼šæ— æ­£åˆ™ï¼Œ L2æ­£åˆ™ï¼ŒL1æ­£åˆ™â€¦</li></ul></li><li>æ­£åˆ™å›å½’æ¨¡å‹å¯è§†ä¸ºå…ˆéªŒä¸ºæ­£åˆ™ã€ä¼¼ç„¶ä¸ºé«˜æ–¯åˆ†å¸ƒçš„è´å¶æ–¯ä¼°è®¡<ul><li>L2æ­£åˆ™ï¼šå…ˆéªŒåˆ†å¸ƒä¸ºé«˜æ–¯åˆ†å¸ƒ</li><li>L1æ­£åˆ™ï¼šå…ˆéªŒåˆ†å¸ƒä¸ºLaplaceåˆ†å¸ƒ</li></ul></li></ul></li></ul><h5 id="1-7-çº¿æ€§å›å½’æ¨¡å‹-ä¼˜åŒ–ç®—æ³•"><a href="#1-7-çº¿æ€§å›å½’æ¨¡å‹-ä¼˜åŒ–ç®—æ³•" class="headerlink" title="1.7 çº¿æ€§å›å½’æ¨¡å‹-ä¼˜åŒ–ç®—æ³•"></a>1.7 çº¿æ€§å›å½’æ¨¡å‹-ä¼˜åŒ–ç®—æ³•</h5><ul><li>çº¿æ€§å›å½’çš„ç›®æ ‡å‡½æ•°<ul><li>æ— æ­£åˆ™çš„æœ€å°äºŒä¹˜çº¿æ€§å›å½’ï¼ˆOrdinary Least Square, OLSï¼‰ï¼š<script type="math/tex; mode=display">J(w) = \sum_{i=1}^N(y_i - w^Tx_i)^2</script></li><li>L2æ­£åˆ™çš„å²­å›å½’ï¼ˆRidge Regressionï¼‰æ¨¡å‹ï¼š<script type="math/tex; mode=display">J(w; \lambda) = \sum_{i=1}^N(y_i - f(x_i))^2 + \lambda \sum_{j=1}^D w_j^2</script></li><li>L1æ­£åˆ™çš„Lassoæ¨¡å‹ï¼š<script type="math/tex; mode=display">J(w; \lambda) = \sum_{i=1}^N(y_i - f(x_i))^2 + \lambda \sum_{j=1}^D |w_j|</script></li></ul></li><li>æ¨¡å‹è®­ç»ƒï¼š<br>  æ ¹æ®è®­ç»ƒæ•°æ®æ±‚ç›®æ ‡å‡½æ•°å–æå°å€¼çš„å‚æ•°ï¼š<br>  $\hat w = \underset {w} {arg\ min} J(\bf w)$<ul><li>ç›®æ ‡å‡½æ•°çš„æœ€å°å€¼ï¼š<ul><li>ä¸€é˜¶çš„å¯¼æ•°ä¸º0ï¼š$\frac{\partial J(w)} {\partial w}$</li><li>äºŒé˜¶å¯¼æ•°&gt;0ï¼š$\frac{\partial J^2(w)} {\partial w^2}$</li></ul></li></ul></li><li>OLSçš„ä¼˜åŒ–æ±‚è§£ï¼š<ul><li>OLSçš„ä¼˜åŒ–æ±‚è§£<ul><li>OLSçš„ç›®æ ‡å‡½æ•°å†™æˆçŸ©é˜µå½¢å¼ï¼š<br>$J(w) = \sum ^N_{i=1}(y_i - w^Tx_i)^2 = (y - Xw)^T(y - Xw)$</li><li>åªå–ä¸wæœ‰å…³çš„é¡¹ï¼Œå¾—åˆ°<br>$J(w) = w^T(X^TX)w - 2w^T(X^Ty)$</li><li>æ±‚å¯¼  $\frac{\partial J(w)} {\partial w} = 2X^TXw - 2X^Ty = 0 \Rightarrow X^TXw = X^Ty$`<br>$\hat w_{OLS} = (X^TX)^{-1}X^Ty$</li></ul></li><li>OLSçš„ä¼˜åŒ–æ±‚è§£ â€”â€”SVD<ul><li>OLSç›®æ ‡å‡½æ•°ï¼š$J(w) = \Vert y - Xw\Vert_2^2$</li><li>ç›¸å½“äºæ±‚ $y = Xw$</li><li>å¦‚æœXä¸ºæ–¹é˜µï¼Œå¯æ±‚é€†ï¼š$w = X^{-1}y$</li><li>å¦‚æœğ—ä¸æ˜¯æ–¹é˜µï¼Œå¯æ±‚Moore-Penroseå¹¿ä¹‰é€†ï¼š$ğ° = ğ—^{\dagger }ğ²$ã€‚</li><li>Moore-Penroseå¹¿ä¹‰é€†å¯é‡‡ç”¨å¥‡å¼‚å€¼åˆ†è§£(Singular Value Decomposition)<br>å®ç°ï¼š<br>å¥‡å¼‚å€¼åˆ†è§£ï¼š$X = U \Sigma V^T$<br>$X^{\dagger } = V \Sigma ^{\dagger} U^T$<br>å…¶ä¸­ $\Sigma = \begin{pmatrix}<br>{\sigma_1}&amp;{0}&amp;{\cdots}&amp;{0}\\<br>{0}&amp;{\sigma_2}&amp;{\cdots}&amp;{0}\\<br>{\vdots}&amp;{\vdots}&amp;{\ddots}&amp;{\vdots}\\<br>{0}&amp;{0}&amp;{\cdots}&amp;{0}\\<br>\end{pmatrix}$,$\Sigma ^{\dagger} = \begin{pmatrix}<br>{\frac {1}{\sigma_1}}&amp;{0}&amp;{\cdots}&amp;{0}\\<br>{0}&amp;{\frac{1}{\sigma_2}}&amp;{\cdots}&amp;{0}\\<br>{\vdots}&amp;{\vdots}&amp;{\ddots}&amp;{\vdots}\\<br>{0}&amp;{0}&amp;{\cdots}&amp;{0}\\<br>\end{pmatrix}$</li></ul></li><li>OLSçš„ä¼˜åŒ–æ±‚è§£â€”â€”æ¢¯åº¦ä¸‹é™<ul><li>OLSç›®æ ‡å‡½æ•°ï¼š<br>$J(w) = (y - Xw)^T(y - Xw)$<br>æ¢¯åº¦ï¼š$\nabla_w = - 2X^T(y - Xw^t)$<br>å‚æ•°æ›´æ–°ï¼š<br>$w^{t+1} = w^t - \eta\nabla_w = w^t + 2\eta X^T(y - Xw^t)$</li></ul></li></ul></li><li>å²­å›å½’çš„ä¼˜åŒ–æ±‚è§£<ul><li>å²­å›å½’çš„ç›®æ ‡å‡½æ•°ä¸OLSåªç›¸å·®ä¸€ä¸ªæ­£åˆ™é¡¹ï¼ˆä¹Ÿæ˜¯wçš„äºŒæ¬¡å‡½æ•°ï¼‰</li><li>å²­å›å½’çš„ä¼˜åŒ–æ±‚è§£â€”â€”SVD</li></ul></li><li>Lassoçš„ä¼˜åŒ–æ¡ä»¶<ul><li>è½¯&amp; ç¡¬é˜ˆå€¼</li><li>Lassoçš„ä¼˜åŒ–æ±‚è§£â€”â€”åæ ‡è½´ä¸‹é™æ³•<ul><li>ä¸ºäº†æ‰¾åˆ°ä¸€ä¸ªå‡½æ•°çš„å±€éƒ¨æå°å€¼ï¼Œåœ¨æ¯æ¬¡è¿­ä»£ä¸­å¯ä»¥åœ¨å½“å‰ç‚¹å¤„æ²¿ä¸€ä¸ªåæ ‡æ–¹å‘è¿›è¡Œä¸€ç»´æœç´¢ã€‚</li></ul></li><li>æ•´ä¸ªè¿‡ç¨‹ä¸­å¾ªç¯ä½¿ç”¨ä¸åŒçš„åæ ‡æ–¹å‘ã€‚ä¸€ä¸ªå‘¨æœŸçš„ä¸€ç»´æœç´¢è¿­ä»£è¿‡ç¨‹ç›¸å½“äºä¸€ä¸ªæ¢¯åº¦è¿­ä»£ã€‚</li><li>æ³¨æ„ï¼š<ul><li>æ¢¯åº¦ä¸‹é™æ–¹æ³•æ˜¯åˆ©ç”¨ç›®æ ‡å‡½æ•°çš„å¯¼æ•°ï¼ˆæ¢¯åº¦ï¼‰æ¥ç¡®å®šæœç´¢æ–¹å‘çš„ï¼Œè€Œè¯¥æ¢¯åº¦æ–¹å‘å¯èƒ½ä¸ä¸ä»»ä½•åæ ‡è½´å¹³è¡Œã€‚</li><li>è€Œåæ ‡è½´ä¸‹é™æ³•æ˜¯åˆ©ç”¨å½“å‰åæ ‡ç³»ç»Ÿè¿›è¡Œæœç´¢ï¼Œä¸éœ€è¦æ±‚ç›®æ ‡å‡½æ•°çš„å¯¼æ•°ï¼ŒåªæŒ‰ç…§æŸä¸€åæ ‡æ–¹å‘è¿›è¡Œæœç´¢æœ€å°å€¼ã€‚ï¼ˆåœ¨ç¨€ç–çŸ©é˜µä¸Šçš„è®¡ç®—é€Ÿåº¦éå¸¸å¿«ï¼ŒåŒæ—¶ä¹Ÿæ˜¯Lassoå›å½’æœ€å¿«çš„è§£æ³•ï¼‰</li></ul></li></ul></li><li>å°ç»“<ul><li>çº¿æ€§å›å½’æ¨¡å‹æ¯”è¾ƒç®€å•<ul><li>å½“æ•°æ®è§„æ¨¡æ¯”è¾ƒå°æ—¶ï¼Œå¯ç›´æ¥è§£ææ±‚è§£<ul><li>scikit learnä¸­çš„å®ç°é‡‡ç”¨SVDåˆ†è§£å®ç°</li></ul></li><li>å½“æ•°æ®è§„æ¨¡è¾ƒå¤§æ—¶ï¼Œå¯é‡‡ç”¨éšæœºæ¢¯åº¦ä¸‹é™<ul><li>scikit learnæä¾›ä¸€ä¸ªSGDRegressionç±»</li></ul></li></ul></li><li>å²­å›å½’æ±‚è§£ç±»ä¼¼OLSï¼Œé‡‡ç”¨SVDåˆ†è§£å®ç°</li><li>Lassoä¼˜åŒ–æ±‚è§£é‡‡ç”¨åæ ‡è½´ä¸‹é™æ³•</li></ul></li></ul><h5 id="1-8-çº¿æ€§å›å½’æ¨¡å‹-æ¨¡å‹é€‰æ‹©"><a href="#1-8-çº¿æ€§å›å½’æ¨¡å‹-æ¨¡å‹é€‰æ‹©" class="headerlink" title="1.8 çº¿æ€§å›å½’æ¨¡å‹-æ¨¡å‹é€‰æ‹©"></a>1.8 çº¿æ€§å›å½’æ¨¡å‹-æ¨¡å‹é€‰æ‹©</h5><ul><li>æ¨¡å‹è¯„ä¼°ä¸æ¨¡å‹é€‰æ‹©<ul><li>æ¨¡å‹è®­ç»ƒå¥½åï¼Œéœ€è¦åœ¨æ ¡éªŒé›†ä¸Šé‡‡ç”¨ä¸€äº›åº¦é‡å‡†åˆ™æ£€æŸ¥æ¨¡å‹é¢„æµ‹çš„æ•ˆæœ<ul><li>æ ¡éªŒé›†åˆ’åˆ†ï¼ˆtrain_test_splitã€äº¤å‰éªŒè¯ï¼‰</li><li>è¯„ä»·æŒ‡æ ‡ï¼ˆsklearn.metricsï¼‰</li></ul></li><li>æ¨¡å‹é€‰æ‹©ï¼š<ul><li>æ¨¡å‹ä¸­é€šå¸¸æœ‰ä¸€äº›è¶…å‚æ•°ï¼Œéœ€è¦é€šè¿‡æ¨¡å‹é€‰æ‹©æ¥ç¡®å®š<ul><li>çº¿æ€§å›å½’æ¨¡å‹ä¸­çš„æ­£åˆ™å‚æ•°</li><li>OLSä¸­çš„ç‰¹å¾çš„æ•°ç›®</li></ul></li><li>å‚æ•°æœç´¢èŒƒå›´ï¼šç½‘æ ¼æœç´¢ï¼ˆGridSearchï¼‰</li></ul></li><li>Scikit learnå°†äº¤å‰éªŒè¯ä¸ç½‘æ ¼æœç´¢åˆå¹¶ä¸ºä¸€ä¸ªå‡½æ•°</li></ul></li><li>è¯„ä»·å‡†åˆ™<ul><li>æ¨¡å‹è®­ç»ƒå¥½åï¼Œå¯ç”¨ä¸€äº›åº¦é‡å‡†åˆ™æ£€æŸ¥æ¨¡å‹æ‹Ÿåˆçš„æ•ˆæœ<ul><li>å¼€æ–¹å‡æ–¹è¯¯å·®ï¼ˆrooted mean squared errorï¼ŒRMSEï¼‰:$RMSE = \sqrt{\frac 1N \sum_{i=1}^N(\hat y_i - y_i)^2}$`</li><li>å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆmean absolute errorï¼ŒMAEï¼‰ï¼š$MAE = \frac 1N \sum_{i=1}^N|\hat y_i - y_i|$</li><li>R2 scoreï¼šæ—¢è€ƒè™‘äº†é¢„æµ‹å€¼ä¸çœŸå€¼ä¹‹é—´çš„å·®å¼‚ï¼Œä¹Ÿè€ƒè™‘äº†é—®é¢˜æœ¬èº«çœŸå€¼ä¹‹<br>é—´çš„å·®å¼‚ï¼ˆ scikit learn çº¿æ€§å›å½’æ¨¡å‹çš„ç¼ºçœè¯„ä»·å‡†åˆ™ï¼‰$SS_{res} = \sum_{i=1}^N(\hat y_i - y_i)^2, SStot = \sum_{i=1}^N(y_i - \bar{y})^2, R^2 = 1 - \frac {SS_{res}}{SS_{tot}})$</li></ul></li><li>ä¹Ÿå¯ä»¥æ£€æŸ¥æ®‹å·®çš„åˆ†å¸ƒ</li><li>è¿˜å¯ä»¥æ‰“å°é¢„æµ‹å€¼ä¸çœŸå€¼çš„æ•£ç‚¹å›¾</li></ul></li><li>çº¿æ€§å›å½’ä¸­çš„æ¨¡å‹é€‰æ‹©<br>Scikit learnä¸­çš„model selectionæ¨¡å—æä¾›æ¨¡å‹é€‰æ‹©åŠŸèƒ½<ul><li>å¯¹äºçº¿æ€§æ¨¡å‹ï¼Œç•™ä¸€äº¤å‰éªŒè¯ï¼ˆNæŠ˜äº¤å‰éªŒè¯ï¼Œäº¦ç§°ä¸ºleave-oneout cross-validationï¼ŒLOOCVï¼‰æœ‰æ›´ç®€ä¾¿çš„è®¡ç®—æ–¹å¼ï¼Œå› æ­¤Scikit learnæä¾›äº†RidgeCVç±»å’ŒLassoCVç±»å®ç°äº†è¿™ç§æ–¹å¼</li><li>åç»­è¯¾ç¨‹å°†è®²è¿°ä¸€èˆ¬æ¨¡å‹çš„äº¤å‰éªŒè¯å’Œå‚æ•°è°ƒä¼˜GridSearchCV</li><li>RidgeCV<ul><li>RidgeCVä¸­è¶…å‚æ•°Î»ç”¨alphaè¡¨ç¤º</li><li>RidgeCV(alphas=(0.1, 1.0, 10.0), fit_intercept=True, normalize=False, scoring=None, cv=None, gcv_mode=None, store_c<br>v_values=False)</li></ul></li><li>LassoCV<ul><li>LassoCVçš„ä½¿ç”¨ä¸RidgeCVç±»ä¼¼</li><li>Scikit learnè¿˜æä¾›ä¸€ä¸ªä¸Lassoç±»ä¼¼çš„LARSï¼ˆleast angle regressionï¼Œæœ€å°è§’å›å½’ï¼‰ï¼ŒäºŒè€…ä»…ä»…æ˜¯ä¼˜åŒ–æ–¹æ³•ä¸åŒï¼Œç›®<br>æ ‡å‡½æ•°ç›¸åŒã€‚</li><li>å½“æ•°æ®é›†ä¸­ç‰¹å¾ç»´æ•°å¾ˆå¤šä¸”å­˜åœ¨å…±çº¿æ€§æ—¶ï¼ŒLassoCVæ›´åˆé€‚ã€‚</li></ul></li></ul></li><li>å°ç»“ï¼šçº¿æ€§å›å½’ä¹‹æ¨¡å‹é€‰æ‹©<ul><li>é‡‡ç”¨äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹é¢„æµ‹æ€§èƒ½ï¼Œä»è€Œé€‰æ‹©æœ€ä½³æ¨¡å‹<ul><li>å›å½’æ€§èƒ½çš„è¯„ä»·æŒ‡æ ‡</li><li>çº¿æ€§æ¨¡å‹çš„äº¤å‰éªŒè¯é€šå¸¸ç›´æ¥é‡‡ç”¨å¹¿ä¹‰çº¿æ€§æ¨¡å‹çš„ç•™ä¸€äº¤å‰éªŒè¯è¿›è¡Œå¿«é€Ÿæ¨¡å‹è¯„ä¼°<ul><li>Scikit learnä¸­å¯¹RidgeCVå’ŒLassoCVå®ç°è¯¥åŠŸèƒ½</li></ul></li></ul></li></ul></li></ul><h5 id="1-9-æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹è¯¦è§£â€”â€”æ•°æ®æ¢ç´¢"><a href="#1-9-æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹è¯¦è§£â€”â€”æ•°æ®æ¢ç´¢" class="headerlink" title="1.9 æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹è¯¦è§£â€”â€”æ•°æ®æ¢ç´¢"></a>1.9 æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹è¯¦è§£â€”â€”æ•°æ®æ¢ç´¢</h5><ul><li>ç¬¬ä¸€æ­¥ï¼šç†è§£ä»»åŠ¡ï¼Œå‡†å¤‡æ•°æ®<ul><li>æ•°æ®è¯»å–<ul><li>Pandasæ”¯æŒå¤šç§æ ¼å¼çš„æ•°æ®</li></ul></li><li>æ•°æ®æ¢ç´¢&amp;ç‰¹å¾å·¥ç¨‹<ul><li>æ•°æ®è§„æ¨¡</li><li>ç¡®å®šæ•°æ®ç±»å‹ï¼Œæ˜¯å¦éœ€è¦è¿›ä¸€æ­¥ç¼–ç <ul><li>ç‰¹å¾ç¼–ç </li></ul></li><li>æ•°æ®æ˜¯å¦æœ‰ç¼ºå¤±å€¼<ul><li>æ•°æ®å¡«è¡¥</li></ul></li><li>æŸ¥çœ‹æ•°æ®åˆ†å¸ƒï¼Œæ˜¯å¦æœ‰å¼‚å¸¸æ•°æ®ç‚¹<ul><li>ç¦»ç¾¤ç‚¹å¤„ç†</li></ul></li><li>æŸ¥çœ‹ä¸¤ä¸¤ç‰¹å¾ä¹‹é—´çš„å…³ç³»ï¼Œçœ‹æ•°æ®æ˜¯å¦æœ‰å†—ä½™/ç›¸å…³<ul><li>é™ç»´</li></ul></li></ul></li><li>æ•°æ®æ¦‚è§ˆ<ul><li>pandas:DataFrame<ul><li>Head():æ•°æ®å‰5è¡Œï¼Œå¯æŸ¥çœ‹æ¯ä¸€åˆ—çš„åå­—åŠæ•°æ®ç±»å‹</li><li>Info():<ul><li>æ•°æ®è§„æ¨¡ï¼šè¡Œæ•°&amp;åˆ—æ•°</li><li>æ¯åˆ—çš„æ•°æ®ç±»å‹ã€æ˜¯å¦æœ‰ç©ºå€¼</li><li>å ç”¨å­˜å‚¨é‡</li></ul></li><li>shape:è¡Œæ•°&amp;åˆ—æ•°</li></ul></li></ul></li><li>å„å±æ€§çš„ç»Ÿè®¡ç‰¹æ€§<ul><li>ç›´æ–¹å›¾<br>  æ¯ä¸ªå–å€¼åœ¨æ•°æ®é›†ä¸­å‡ºç°çš„æ ·æœ¬æ•°ç›® </li><li>ç¦»ç¾¤ç‚¹<ul><li>ç¦»ç¾¤ç‚¹ï¼šå¥‡å¼‚ç‚¹ï¼ˆoutlierï¼‰,æŒ‡è¿œç¦»å¤§å¤šæ•°æ ·æœ¬çš„æ ·æœ¬ç‚¹ã€‚é€šå¸¸è®¤ä¸ºè¿™äº›ç‚¹æ˜¯å™ªå£°ï¼Œå¯¹æ¨¡å‹æœ‰åå½±å“</li></ul></li><li>ç›¸å…³æ€§<ul><li>ç›¸å…³æ€§ï¼šç›¸å…³æ€§å¯ä»¥é€šè¿‡è®¡ç®—ç›¸å…³ç³»æ•°æˆ–æ‰“å°æ•£ç‚¹å›¾æ¥å‘ç°</li><li>ç›¸å…³ç³»æ•°ï¼š</li><li>æ•£ç‚¹å›¾<ul><li>å¯ä»¥é€šè¿‡ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„æ•£ç‚¹å›¾ç›´è§‚æ„Ÿå—äºŒè€…çš„ç›¸å…³æ€§</li></ul></li><li>æ•°æ®é¢„å¤„ç†<ul><li>æ•°æ®æ ‡å‡†åŒ–ï¼ˆ Standardization ï¼‰<ul><li>æŸä¸ªç‰¹å¾çš„æ‰€æœ‰æ ·æœ¬å–å€¼ä¸º0å‡å€¼ã€1æ–¹å·®</li></ul></li><li>æ•°æ®å½’ä¸€åŒ–ï¼ˆ Scaling ï¼‰<ul><li>æŸä¸ªç‰¹å¾çš„æ‰€æœ‰æ ·æœ¬å–å€¼åœ¨è§„å®šèŒƒå›´å†…</li></ul></li><li>æ•°æ®æ­£è§„åŒ–ï¼ˆ Normalization ï¼‰<ul><li>æ¯ä¸ªæ ·æœ¬æ¨¡é•¿ä¸º1</li></ul></li><li>æ•°æ®äºŒå€¼åŒ–<ul><li>æ ¹æ®ç‰¹å¾å€¼å–å€¼æ˜¯å¦å¤§äºé˜ˆå€¼å°†ç‰¹å¾å€¼å˜ä¸º0æˆ–1ï¼Œå¯ç”¨ç±»Binarizer å®ç°</li></ul></li><li>æ•°æ®ç¼ºå¤±</li><li>æ•°æ®ç±»å‹å˜æ¢<ul><li>æœ‰äº›æ¨¡å‹åªèƒ½å¤„ç†æ•°å€¼å‹æ•°æ®ã€‚å¦‚æœç»™å®šçš„æ•°æ®æ˜¯ä¸åŒçš„ç±»å‹ï¼Œå¿…é¡»å…ˆå°†æ•°æ®<br>å˜æˆæ•°å€¼å‹ã€‚</li></ul></li></ul></li></ul></li></ul></li></ul></li><li>ç¬¬äºŒæ­¥ï¼šæ¨¡å‹ç¡®å®šå’Œæ¨¡å‹è®­ç»ƒ<ul><li>1ã€ç¡®å®šæ¨¡å‹ç±»å‹<ul><li>ç›®æ ‡å‡½æ•°ï¼ˆæŸå¤±å‡½æ•°ã€æ­£åˆ™ï¼‰</li></ul></li><li>2ã€æ¨¡å‹è®­ç»ƒ<ul><li>ä¼˜åŒ–ç®—æ³•ï¼ˆè§£ææ³•ï¼Œæ¢¯åº¦ä¸‹é™ã€éšæœºæ¢¯åº¦ä¸‹é™â€¦ï¼‰</li></ul></li></ul></li><li>ç¬¬ä¸‰æ­¥ï¼šæ¨¡å‹è¯„ä¼°ä¸æ¨¡å‹é€‰æ‹©<ul><li>æ¨¡å‹è®­ç»ƒå¥½åï¼Œéœ€è¦åœ¨æ ¡éªŒé›†ä¸Šé‡‡ç”¨ä¸€äº›åº¦é‡å‡†åˆ™æ£€æŸ¥æ¨¡å‹é¢„æµ‹çš„æ•ˆæœ<ul><li>æ ¡éªŒé›†åˆ’åˆ†ï¼ˆtrain_test_splitã€äº¤å‰éªŒè¯ï¼‰</li><li>è¯„ä»·æŒ‡æ ‡ ï¼ˆsklearn.meticsï¼‰</li><li>ä¹Ÿå¯ä»¥æ£€æŸ¥æ®‹å·®çš„åˆ†å¸ƒ</li><li>è¿˜å¯ä»¥æ‰“å°é¢„æµ‹å€¼ä¸çœŸå€¼çš„æ•£ç‚¹å›¾</li></ul></li><li>æ¨¡å‹é€‰æ‹©ï¼šé€‰æ‹©é¢„æµ‹æ€§èƒ½æœ€å¥½çš„æ¨¡å‹<ul><li>æ¨¡å‹ä¸­é€šå¸¸æœ‰ä¸€äº›è¶…å‚æ•°ï¼Œéœ€è¦é€šè¿‡æ¨¡å‹é€‰æ‹©æ¥ç¡®å®š</li><li>å‚æ•°æœç´¢èŒƒå›´ï¼šç½‘æ ¼æœç´¢ï¼ˆGridSearchï¼‰</li></ul></li></ul></li></ul><h5 id="1-10-æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹-æ•°æ®æ¢ç´¢ä»£ç "><a href="#1-10-æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹-æ•°æ®æ¢ç´¢ä»£ç " class="headerlink" title="1.10 æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹-æ•°æ®æ¢ç´¢ä»£ç "></a>1.10 æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹-æ•°æ®æ¢ç´¢ä»£ç </h5><figure class="highlight python"><figcaption><span>python 3.7</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¯»å…¥æ•°æ®</span></span><br><span class="line">data = pd.read_csv(<span class="string">"boston_housing.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ•°æ®æ¢ç´¢</span></span><br><span class="line">print(data.head())</span><br><span class="line">data.info()</span><br><span class="line">print(data.isnull().sum())</span><br><span class="line">print(data.describe())</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç›®æ ‡y(æˆ¿å±‹ä»·æ ¼)çš„ç›´æ–¹å›¾/åˆ†å¸ƒ</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">sns.distplot(data.MEDV.values, bins=<span class="number">30</span>, kde=<span class="literal">True</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Median value of owner_occupied homes'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># å•ä¸ªç‰¹å¾æ•£ç‚¹å›¾</span></span><br><span class="line">plt.scatter(range(data.shape[<span class="number">0</span>]), data[<span class="string">"MEDV"</span>].values, color=<span class="string">'purple'</span>)</span><br><span class="line">plt.title(<span class="string">"Distribution of Price"</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ é™¤yå¤§äº50çš„æ ·æœ¬</span></span><br><span class="line">data = data[data.MEDV &lt; <span class="number">50</span>]</span><br><span class="line">print(data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å…¥å±æ€§çš„ç›´æ–¹å›¾ï¼åˆ†å¸ƒ</span></span><br><span class="line"><span class="comment"># çŠ¯ç½ªç‡ç‰¹å¾</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">sns.distplot(data.CRIM.values, bins=<span class="number">30</span>, kde=<span class="literal">False</span>)</span><br><span class="line">plt.xlabel(<span class="string">'crime rate'</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ˜¯å¦é è¿‘charles river</span></span><br><span class="line">sns.countplot(data.CHAS, order=[<span class="number">0</span>, <span class="number">1</span>]);</span><br><span class="line">plt.xlabel(<span class="string">'Charles River'</span>);</span><br><span class="line">plt.ylabel(<span class="string">'Number of occurrences'</span>);</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># é è¿‘é«˜é€Ÿ</span></span><br><span class="line">sns.countplot(data.RAD)</span><br><span class="line">plt.xlabel(<span class="string">'index of accessibility to radial highways'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸¤ä¸¤ç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§</span></span><br><span class="line"><span class="comment"># è·å¾—æ‰€æœ‰åˆ—çš„åå­—</span></span><br><span class="line">cols = data.columns</span><br><span class="line"><span class="comment"># è®¡ç®—ç›¸å…³æ€§</span></span><br><span class="line">data_corr = data.corr().abs()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç›¸å…³æ€§çƒ­å›¾</span></span><br><span class="line">plt.subplots(figsize=(<span class="number">13</span>, <span class="number">9</span>))</span><br><span class="line">sns.heatmap(data_corr, annot=<span class="literal">True</span>)</span><br><span class="line">sns.heatmap(data_corr, mask=data_corr &lt; <span class="number">1</span>, cbar=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">plt.savefig(<span class="string">'house_coor.png'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å‡ºå¼ºç›¸å…³å¯¹</span></span><br><span class="line">threshold = <span class="number">0.5</span></span><br><span class="line">corr_list = []</span><br><span class="line">size = data_corr.shape[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, size):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, size):</span><br><span class="line">        <span class="keyword">if</span> (data_corr.iloc[i,j] &gt;= threshold <span class="keyword">and</span> data_corr.iloc[i, j] &lt; <span class="number">1</span>) <span class="keyword">or</span> (data_corr.iloc[i, j] &lt; <span class="number">0</span> <span class="keyword">and</span> data_corr.iloc &lt;= -threshold):</span><br><span class="line">            corr_list.append([data_corr.iloc[i, j], i, j])</span><br><span class="line">s_corr_list = sorted(corr_list, key=<span class="keyword">lambda</span> x: -abs(x[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> v, i, j <span class="keyword">in</span> s_corr_list:</span><br><span class="line">    print(<span class="string">"%s and %s = %.2f"</span> % (cols[i], cols[j], v))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> v, i, j <span class="keyword">in</span> s_corr_list:</span><br><span class="line">    sns.pairplot(data, height=<span class="number">6</span>, x_vars=cols[i], y_vars=cols[j])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><h5 id="1-11-æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹è¯¦è§£"><a href="#1-11-æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹è¯¦è§£" class="headerlink" title="1.11 æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹è¯¦è§£"></a>1.11 æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹è¯¦è§£</h5><h5 id="1-12-æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹è¯¦è§£-ä»£ç è®²è§£"><a href="#1-12-æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹è¯¦è§£-ä»£ç è®²è§£" class="headerlink" title="1.12 æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹è¯¦è§£-ä»£ç è®²è§£"></a>1.12 æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹è¯¦è§£-ä»£ç è®²è§£</h5><figure class="highlight python"><figcaption><span>python 3.7</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹æ¡ˆä¾‹â€”â€”çº¿æ€§å›å½’åˆ†æ</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># çŸ©é˜µæ“ä½œ</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># SQLæ•°æ®å¤„ç†</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score <span class="comment"># è¯„ä»·å›å½’é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># ç”»å›¾</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¯»å…¥æ•°æ®</span></span><br><span class="line">data = pd.read_csv(<span class="string">"boston_housing.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1ã€æ•°æ®å‡†å¤‡</span></span><br><span class="line"><span class="comment"># ä»åŸå§‹æ•°æ®ä¸­åˆ†ç¦»è¾“å…¥ç‰¹å¾xå’Œè¾“å‡ºy</span></span><br><span class="line">y = data[<span class="string">'MEDV'</span>].values</span><br><span class="line">X = data.drop(<span class="string">'MEDV'</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç”¨äºåç»­æ˜¾ç¤ºæƒé‡ç³»æ•°å¯¹åº”çš„ç‰¹å¾</span></span><br><span class="line">columns = X.columns</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ•°æ®è¾ƒå°‘ï¼Œå°†æ•°æ®åˆ†å‰²è®­ç»ƒæ•°æ®</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># éšæœºé‡‡æ ·20%çš„æ•°æ®æ„å»ºæµ‹è¯•æ ·æœ¬ï¼Œå…¶ä½™ä½œä¸ºè®­ç»ƒæ ·æœ¬</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=<span class="number">33</span>,test_size=<span class="number">0.2</span>)</span><br><span class="line"><span class="comment"># print(X_train.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2ã€æ•°æ®é¢„å¤„ç†/ç‰¹å¾å·¥ç¨‹</span></span><br><span class="line"><span class="comment"># æ•°æ®æ ‡å‡†åŒ–</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ†åˆ«åˆå§‹åŒ–å¯¹ç‰¹å¾å’Œç›®æ ‡å€¼çš„æ ‡å‡†åŒ–å™¨</span></span><br><span class="line">ss_X = StandardScaler()</span><br><span class="line">ss_y = StandardScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ†åˆ«å¯¹è®­ç»ƒå’Œæµ‹è¯•æ•°æ®çš„ç‰¹å¾ä»¥åŠç›®æ ‡å€¼è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†</span></span><br><span class="line">X_train = ss_X.fit_transform(X_train)</span><br><span class="line">X_test = ss_X.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯¹yæ ‡å‡†åŒ–ä¸æ˜¯å¿…é¡»</span></span><br><span class="line"><span class="comment"># å¯¹yæ ‡å‡†åŒ–çš„å¥½å¤„æ˜¯ä¸åŒçš„é—®é¢˜çš„wå·®å¼‚ä¸å¤ªå¤§ï¼ŒåŒæ—¶æ­£åˆ™å‚æ•°çš„èŒƒå›´ä¹Ÿæœ‰é™</span></span><br><span class="line">y_train = ss_y.fit_transform(y_train.reshape(<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line">y_test = ss_y.transform(y_test.reshape(<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3ã€ç¡®å®šæ¨¡å‹ç±»å‹</span></span><br><span class="line"><span class="comment"># 3.1 å°è¯•ç¼ºçœå‚æ•°çš„çº¿æ€§å›å½’</span></span><br><span class="line"><span class="comment"># çº¿æ€§å›å½’</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–</span></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒæ¨¡å‹å‚æ•°</span></span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># é¢„æµ‹</span></span><br><span class="line">y_test_pred_lr = lr.predict(X_test)</span><br><span class="line">y_train_pred_lr = lr.predict(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># çœ‹çœ‹å„ç‰¹å¾çš„æƒé‡ç³»æ•°ï¼Œç³»æ•°çš„ç»å¯¹å€¼å¤§å°å¯è§†ä¸ºè¯¥ç‰¹å¾çš„é‡è¦æ€§</span></span><br><span class="line">fs = pd.DataFrame(&#123;<span class="string">"columns"</span>: list(columns), <span class="string">"coef"</span>: list((lr.coef_.T))&#125;)</span><br><span class="line">fs.sort_values(by=[<span class="string">'coef'</span>], ascending=<span class="literal">False</span>)</span><br><span class="line">print(fs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ¨¡å‹è¯„ä»·</span></span><br><span class="line"><span class="comment"># æµ‹è¯•é›†</span></span><br><span class="line">print(<span class="string">'The r2 score of LinearRegression on test is'</span>, r2_score(y_test, y_test_pred_lr))</span><br><span class="line"><span class="comment"># è®­ç»ƒé›†</span></span><br><span class="line">print(<span class="string">'The r2 score of LinearRegression on train is'</span>, r2_score(y_train, y_train_pred_lr))</span><br><span class="line"></span><br><span class="line"><span class="comment"># åœ¨è®­ç»ƒé›†ä¸Šè§‚å¯Ÿæ®‹å·®çš„åˆ†å¸ƒï¼Œçœ‹æ˜¯å¦ç¬¦åˆæ¨¡å‹å‡è®¾ï¼šå™ªå£°ä¸º0å‡å€¼çš„é«˜æ–¯å™ªå£°</span></span><br><span class="line">f, ax = plt.subplots(figsize=(<span class="number">7</span>, <span class="number">5</span>))</span><br><span class="line">f.tight_layout()</span><br><span class="line">ax.hist(y_train - y_train_pred_lr, bins=<span class="number">40</span>, label=<span class="string">'Residuals Linear'</span>, color=<span class="string">'b'</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">ax.set_title(<span class="string">"Histogram of Residuals"</span>)</span><br><span class="line">ax.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿˜å¯ä»¥è§‚å¯Ÿé¢„æµ‹å€¼ä¸çœŸå€¼çš„æ•£ç‚¹å›¾</span></span><br><span class="line">plt.figure(figsize=(<span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line">plt.scatter(y_train, y_train_pred_lr)</span><br><span class="line">plt.plot([<span class="number">-3</span>, <span class="number">3</span>],[<span class="number">-3</span>, <span class="number">3</span>], <span class="string">'--k'</span>)</span><br><span class="line">plt.axis(<span class="string">'tight'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'True price'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Predicted price'</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># çº¿æ€§æ¨¡å‹ï¼Œéšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–æ¨¡å‹å‚æ•°</span></span><br><span class="line"><span class="comment"># éšæœºæ¢¯åº¦ä¸‹é™ä¸€èˆ¬åœ¨å¤§æ•°æ®é›†ä¸Šåº”ç”¨ï¼Œå…¶å®æœ¬é¡¹ç›®ä¸é€‚åˆç”¨</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line"></span><br><span class="line"><span class="comment">#  ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ–çº¿</span></span><br><span class="line">sgdr = SGDRegressor(max_iter=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒï¼šå‚æ•°ä¼°è®¡</span></span><br><span class="line">sgdr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># é¢„æµ‹</span></span><br><span class="line">sgdr.coef_</span><br><span class="line">print(<span class="string">'The value of default measurement of SGDRegressor on test is'</span>, sgdr.score(X_test, y_test))</span><br><span class="line">print(<span class="string">'The value of default measurement of SGDRegressor on train is'</span>, sgdr.score(X_train, y_train))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.2 æ­£åˆ™åŒ–çš„çº¿æ€§å›å½’ï¼ˆL2æ­£åˆ™--&gt;å²­å›å½’ï¼‰</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RidgeCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¾ç½®è¶…å‚æ•°ï¼ˆæ­£åˆ™å‚æ•°ï¼‰èŒƒå›´</span></span><br><span class="line">alphas = [<span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç”Ÿæˆä¸€ä¸ªRidgeCV</span></span><br><span class="line">ridge = RidgeCV(alphas=alphas, store_cv_values=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ¨¡å‹è®­ç»ƒ</span></span><br><span class="line">ridge.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># é¢„æµ‹</span></span><br><span class="line">y_test_pred_ridge = ridge.predict(X_test)</span><br><span class="line">y_train_pred_ridge = ridge.predict(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¯„ä¼°ï¼Œä½¿ç”¨r2_scoreè¯„ä»·æ¨¡å‹åœ¨æµ‹è¯•é›†å’Œè®­ç»ƒé›†ä¸Šçš„æ€§èƒ½</span></span><br><span class="line">print(<span class="string">'The r2 score of RidgeCV on test is'</span>, r2_score(y_test, y_test_pred_ridge))</span><br><span class="line">print(<span class="string">'The r2 score of RidgeCV on test is'</span>, r2_score(y_train, y_train_pred_ridge))</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯è§†åŒ–</span></span><br><span class="line">mse_mean = np.mean(ridge.cv_values_, axis=<span class="number">0</span>)</span><br><span class="line">plt.plot(np.log10(alphas), mse_mean.reshape(len(alphas), <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.plot(np.log10(ridge.alpha_)*np.ones(3), [0.28, 0.29, 0.30])</span></span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">'log(alpha)'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'mse'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'alpha is:'</span>, ridge.alpha_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># çœ‹çœ‹å„ç‰¹å¾çš„æƒé‡ç³»æ•°ï¼Œç³»æ•°çš„ç»å¯¹å€¼å¤§å°å¯è§†ä¸ºè¯¥ç‰¹åˆ¶çš„é‡è¦æ€§</span></span><br><span class="line">fs = pd.DataFrame(&#123;<span class="string">"columns"</span>: list(columns), <span class="string">"coef_lr"</span>: list(lr.coef_.T), <span class="string">"coef_ridge"</span>: list(ridge.coef_.T)&#125;)</span><br><span class="line">fs.sort_values(by=[<span class="string">'coef_lr'</span>], ascending=<span class="literal">False</span>)</span><br><span class="line">print(fs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.3 æ­£åˆ™åŒ–çš„çº¿æ€§å›å½’ï¼ˆL1æ­£åˆ™--&gt;Lassoï¼‰</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LassoCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç”Ÿæˆä¸€ä¸ªLassoCVå®ä¾‹</span></span><br><span class="line">lasso = LassoCV()</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒï¼ˆå†…å«CVï¼‰</span></span><br><span class="line">lasso.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æµ‹è¯•</span></span><br><span class="line">y_test_pred_lasso = lasso.predict(X_test)</span><br><span class="line">y_train_pred_lasso = lasso.predict(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¯„ä¼°ï¼Œ ä½¿ç”¨r2_scoreè¯„ä»·æ¨¡å‹åœ¨æµ‹è¯•é›†å’Œè®­ç»ƒé›†ä¸Šçš„æ€§èƒ½</span></span><br><span class="line">print(<span class="string">'The r2 score of LassoCV on test is'</span>, r2_score(y_test, y_test_pred_lasso))</span><br><span class="line">print(<span class="string">'The r2 score of LassoCV on train is'</span>, r2_score(y_train, y_train_pred_lasso))</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯è§†åŒ–</span></span><br><span class="line">mses = np.mean(lasso.mse_path_, axis=<span class="number">1</span>)</span><br><span class="line">plt.plot(np.log10(lasso.alphas_), mses)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.plot(np.log10(ridge.alpha_)*np.ones(3), [0.28, 0.29, 0.30])</span></span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">'log(alpha)'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'mse'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'alpha is:'</span>, lasso.alpha_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># çœ‹çœ‹å„ç‰¹å¾çš„æƒé‡ç³»æ•°ï¼Œç³»æ•°çš„ç»å¯¹å€¼å¤§å°å¯è§†ä¸ºè¯¥ç‰¹åˆ¶çš„é‡è¦æ€§</span></span><br><span class="line">fs = pd.DataFrame(&#123;<span class="string">"columns"</span>: list(columns), <span class="string">"coef_lr"</span>: list(lr.coef_.T), <span class="string">"coef_ridge"</span>: list(lasso.coef_.T)&#125;)</span><br><span class="line">fs.sort_values(by=[<span class="string">'coef_lr'</span>], ascending=<span class="literal">False</span>)</span><br><span class="line">print(fs)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;1-1-ä¸€ä¸ªKaggleç«èµ›ä¼˜èƒœè§£å†³æ–¹æ¡ˆ&quot;&gt;&lt;a href=&quot;#1-1-ä¸€ä¸ªKaggleç«èµ›ä¼˜èƒœè§£å†³æ–¹æ¡ˆ&quot; class=&quot;headerlink&quot; title=&quot;1.1 ä¸€ä¸ªKaggleç«èµ›ä¼˜èƒœè§£å†³æ–¹æ¡ˆ&quot;&gt;&lt;/a&gt;1.1 ä¸€ä¸ªKaggleç«èµ›ä¼˜èƒœè§£å†³æ–¹æ¡ˆ&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;ä¸€ä¸ªKaggleç«èµ›ä¼˜èƒœè§£å†³æ–¹æ¡ˆ&lt;ul&gt;
&lt;li&gt;ä»»åŠ¡ï¼šAvazuç‚¹å‡»ç‡é¢„ä¼°ç«èµ›&lt;/li&gt;
&lt;li&gt;Rank 2nd Owen Zhangçš„è§£æ³•&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
      <category term="å­¦ä¹ ç¬”è®°" scheme="http://minhzou.top/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="å­¦ä¹ ç¬”è®°" scheme="http://minhzou.top/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="æœºå™¨å­¦ä¹ " scheme="http://minhzou.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="äººå·¥æ™ºèƒ½" scheme="http://minhzou.top/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="çº¿æ€§å›å½’" scheme="http://minhzou.top/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>è®¡ç®—æœºè§†è§‰åŸºç¡€å…¥é—¨ å­¦ä¹ ç¬”è®°</title>
    <link href="http://minhzou.top/2019/03/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"/>
    <id>http://minhzou.top/2019/03/30/è®¡ç®—æœºè§†è§‰åŸºç¡€å…¥é—¨/</id>
    <published>2019-03-30T11:22:46.082Z</published>
    <updated>2019-04-04T15:45:41.583Z</updated>
    
    <content type="html"><![CDATA[<h5 id="ä¸€ã€-è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ æ¦‚è¿°"><a href="#ä¸€ã€-è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ æ¦‚è¿°" class="headerlink" title="ä¸€ã€ è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ æ¦‚è¿°"></a>ä¸€ã€ è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ æ¦‚è¿°</h5><ol><li>è®¡ç®—æœºè§†è§‰å›é¡¾<ol><li>è®¡ç®—æœºè§†è§‰ï¼ˆcomputer visionï¼‰å®šä¹‰<ul><li>æ•°æ®ï¼ˆé™æ€å›¾ç‰‡ï¼Œè§†é¢‘ï¼‰</li><li>ç®—æ³•ï¼ˆæœºå™¨å­¦ä¹ ç®—æ³•ï¼Œç¥ç»ç½‘ç»œï¼‰æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå›å½’+åˆ†ç±»</li></ul></li><li>è®¡ç®—æœºè§†è§‰çš„é‡è¦æ€§<a id="more"></a><ul><li>ä¸‰å¤§ä»»åŠ¡ï¼šå›¾åƒè¯†åˆ«ï¼ˆimage classificationï¼‰<br>è½¦ç‰Œè¯†åˆ«ï¼Œäººè„¸è¯†åˆ«</li><li>ä¸‰å¤§ä»»åŠ¡ï¼šç›®æ ‡æ£€æµ‹ï¼ˆobject detection = classification + localizationï¼‰<br>è¡Œäººæ£€æµ‹å’Œè½¦è¾†æ£€æµ‹</li><li>ä¸‰å¤§ä»»åŠ¡ï¼šå›¾åƒåˆ†å‰²<br>å›¾åƒè¯­ä¹‰åˆ†å‰²<br>ä¸ªä½“åˆ†å‰² = æ£€æµ‹ + åˆ†å‰²</li><li>è§†è§‰ç›®æ ‡è·Ÿè¸ªï¼ˆtrackingï¼‰</li><li>è§†é¢‘åˆ†å‰²</li><li>å›¾åƒé£æ ¼è¿ç§»</li><li>ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰</li><li>è§†é¢‘ç”Ÿæˆ</li></ul></li></ol></li><li>æ·±åº¦å­¦ä¹ ä»‹ç»<br> 2006 Hinton bp(åå‘ä¼ æ’­)<br> 2012 Krizhevsky A æ·±åº¦å­¦ä¹  æ·±åº¦å·ç§¯<br> RNN<br> LSTM æŒç»­ä¿¡æ¯<br> è§†è§‰è¯†åˆ«ï¼Œè¯­éŸ³è¯†åˆ«ï¼ŒDeepMind, AlphaGo<br> äººè„¸è¯†åˆ«ï¼šLFW é”™è¯¯ç‡5% -&gt; 0.5%<br> å›¾åƒåˆ†å‰²<br> VGGNet, GoogleNet, ResNet, DenseNet<ul><li>å¸¸è§çš„æ·±åº¦å­¦ä¹ å¼€å‘å¹³å°<br>  Torch, TensorFlow, MatConvNetTheano, Caffe</li></ul></li><li>è¯¾ç¨‹ä»‹ç»<ul><li>å›¾åƒè¯†åˆ«ï¼š<br>Alexnet, VGGnet, GoogleNet, ResNet, DenseNet</li><li>ç›®æ ‡æ£€æµ‹<br>Fast-rcnn, faster-rcnn, Yolo, Retina-Net</li><li>å›¾åƒåˆ†å‰²<br>FCN, Mask-Rcnn</li><li>ç›®æ ‡è·Ÿè¸ª<br>GORURNï¼Œ ECO</li><li>å›¾åƒç”Ÿæˆ<br>GANï¼Œ WGAN</li><li>å…‰æµ<br>FlowNet</li><li>è§†é¢‘åˆ†å‰²<br>Segnet <h5 id="äºŒã€-å›¾åƒåˆ†ç±»ä¸æ·±åº¦å·ç§¯ç½‘ç»œçš„æ¨¡å‹"><a href="#äºŒã€-å›¾åƒåˆ†ç±»ä¸æ·±åº¦å·ç§¯ç½‘ç»œçš„æ¨¡å‹" class="headerlink" title="äºŒã€ å›¾åƒåˆ†ç±»ä¸æ·±åº¦å·ç§¯ç½‘ç»œçš„æ¨¡å‹"></a>äºŒã€ å›¾åƒåˆ†ç±»ä¸æ·±åº¦å·ç§¯ç½‘ç»œçš„æ¨¡å‹</h5></li></ul></li><li>å›¾åƒåˆ†ç±»<ul><li>å›¾åƒåˆ†ç±»çš„æŒ‘æˆ˜<br>å…‰ç…§å˜åŒ–<br>å½¢å˜<br>ç±»å†…å˜åŒ–</li><li>å›¾åƒåˆ†ç±»å®šä¹‰</li><li>ç›®æ ‡åˆ†ç±»æ¡†æ¶</li><li>æ³›åŒ–èƒ½åŠ›<br>å¦‚ä½•æé«˜æ³›åŒ–èƒ½åŠ›ï¼Ÿ éœ€è¦ç”¨å›¾åƒç‰¹å¾æ¥æè¿°å›¾åƒ</li><li>è®­ç»ƒå’Œæµ‹è¯•çš„æµç¨‹</li><li>å›¾åƒç‰¹å¾<br>  color: Qutantize RGB values<br>  global shape: PCA space<br>  local shape: shape context<br>  texture: Filter banks<br>  SIFT, Hog, LBP, Harr</li><li>æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰<br>   è¶…å¹³é¢ä¸æ”¯æŒå‘é‡<br>   æœ€å¤§åŒ–é—´éš”<br>   svmåˆ†ç±»ï¼ˆpythonï¼‰ä»¥lriså…°èŠ±åˆ†ç±»ä¸ºä¾‹<br>   ç¨‹åºå®ç°</li><li>æ›´å¥½çš„ç‰¹å¾<br>  CNNç‰¹å¾<br>  å­¦ä¹ å‡ºæ¥çš„<br>  å¦‚ä½•å­¦ä¹ ï¼Ÿ æ„é€ ç¥ç»ç½‘ç»œ</li></ul></li><li>ç¥ç»ç½‘ç»œåŸç†<ul><li>ç¥ç»ç½‘ç»œåšå›¾åƒåˆ†ç±»</li><li>ç¥ç»ç½‘ç»œæ­å»º</li><li>ç¥ç»ç½‘ç»œçš„åŸºæœ¬å•å…ƒï¼šç¥ç»å…ƒ</li><li>æ¿€åŠ±å‡½æ•°<br>  Sigmoidã€tanhã€ReLUã€Leaky ReLUã€Maxoutã€ELU</li><li>å·ç§¯å±‚</li><li>å·ç§¯æ»¤æ³¢çš„è®¡ç®—</li><li>å·ç§¯å±‚å¯è§†åŒ–</li><li>æ± åŒ–å±‚ï¼ˆpooling layerï¼‰<br>  ç‰¹å¾è¡¨è¾¾æ›´åŠ ç´§å‡‘ï¼ŒåŒæ—¶å…·æœ‰ä½ç§»ä¸å˜æ€§</li><li>å…¨è¿æ¥å±‚</li><li>æŸå¤±å‡½æ•°<br>  äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ˆSIGMOID_CROSS_ENTROPY_LOSS) åº”ç”¨äºäºŒåˆ†ç±»é—®é¢˜<br>  Softmax æŸå¤±å‡½æ•°ï¼ˆSOFTMAX_LOSS)  å¤šåˆ†ç±»é—®é¢˜<br>  æ¬§å¼è·ç¦»æŸå¤±å‡½æ•°ï¼ˆEUCLIDEAN_LOSSï¼‰å›å½’é—®é¢˜<br>  å¯¹æ¯”æŸå¤±å‡½æ•°ï¼ˆContrastive lossï¼‰ç”¨æ¥è®¡ç®—ä¸¤ä¸ªå›¾åƒä¹‹é—´çš„ç›¸ä¼¼åº¦<br>  Triplet loss</li><li>è®­ç»ƒç½‘ç»œ</li><li>ç½‘ç»œè®­ç»ƒå’Œæµ‹è¯•</li></ul></li><li>å·ç§¯ç¥ç»ç½‘ç»œä»‹ç»<br> Alexnet, VGGnet, GoogleNet, ResNet, DenseNet<ul><li>è®­ç»ƒæŠ€å·§ï¼Œ é˜²æ­¢è¿‡æ‹Ÿåˆï¼ˆæ³›åŒ–èƒ½åŠ›ä¸å¼ºï¼‰<ul><li>æ•°æ®å¢å¼ºï¼ˆData augmentationï¼‰<br>  æ°´å¹³ç¿»è½¬ï¼Œ éšæœºè£å‰ªå’Œå¹³ç§»å˜æ¢ï¼Œé¢œè‰²ã€å…‰ç…§å˜æ¢</li><li>Dropout</li></ul></li><li>å…¶ä»–æœ‰åŠ©äºè®­ç»ƒçš„æ‰‹æ®µ<ul><li>L1ï¼Œ L2æ­£åˆ™åŒ–</li><li>Batch Normalization</li></ul></li></ul></li><li>åˆ©ç”¨caffeæ­å»ºæ·±åº¦ç½‘ç»œåšå›¾åƒåˆ†ç±»</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;ä¸€ã€-è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ æ¦‚è¿°&quot;&gt;&lt;a href=&quot;#ä¸€ã€-è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ æ¦‚è¿°&quot; class=&quot;headerlink&quot; title=&quot;ä¸€ã€ è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ æ¦‚è¿°&quot;&gt;&lt;/a&gt;ä¸€ã€ è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ æ¦‚è¿°&lt;/h5&gt;&lt;ol&gt;
&lt;li&gt;è®¡ç®—æœºè§†è§‰å›é¡¾&lt;ol&gt;
&lt;li&gt;è®¡ç®—æœºè§†è§‰ï¼ˆcomputer visionï¼‰å®šä¹‰&lt;ul&gt;
&lt;li&gt;æ•°æ®ï¼ˆé™æ€å›¾ç‰‡ï¼Œè§†é¢‘ï¼‰&lt;/li&gt;
&lt;li&gt;ç®—æ³•ï¼ˆæœºå™¨å­¦ä¹ ç®—æ³•ï¼Œç¥ç»ç½‘ç»œï¼‰æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå›å½’+åˆ†ç±»&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;è®¡ç®—æœºè§†è§‰çš„é‡è¦æ€§&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
    
    </summary>
    
      <category term="å­¦ä¹ ç¬”è®°" scheme="http://minhzou.top/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="è®¡ç®—æœºè§†è§‰" scheme="http://minhzou.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="åŸºç¡€" scheme="http://minhzou.top/tags/%E5%9F%BA%E7%A1%80/"/>
    
      <category term="å­¦ä¹ ç¬”è®°" scheme="http://minhzou.top/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
</feed>
